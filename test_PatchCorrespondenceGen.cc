//
//        Program to test PatchCorrespondenceGen class
//        Graham Thomas, Jan 2007

//        Modified by Mark Mann & Robert Dawes May-Dec 2011 for diving segmentation
//
//
//

#include        <stdlib.h>
#include        <math.h>
#include        <sys/time.h>                          // for measuring time of various bits

#include        "test_PatchCorrespondenceGen.h"       // generated by command-line parser gen
#include        "PitchModelFile.h"                    // for lines that can optionally be used for tracking
#include        "FittedLine.h"
#include        "ChromaKeyer.h"                       // chromakeyer needed for line-based tracking
#include        "KeyerParams.h"
#include        "InitialPoseEstLines.h"               // for the method for finding pixels on lines (not used for initialisation despite its name!)
#include        "PatchCorrespondenceGen.h"            // NB includes PoseEstimator.h which #define's X, Y Z (bad practice!) which messes up thigs in PitchModel so must be after it
#include        "skin_detect.cpp"

#include        <stdlib.h>
#include        "o_Picture.h"
#include        "o_PicReadFileSeq.h"
#include	"region_test.h"       // generated by command-line parser gen
#include        "RegionFinder.h"     // for Region calss and RegionFinder class
#include        "ContourFollower.h"  // for contour follower class
#include        "ReadImage.h"
#include        "WriteImage.h"
#include        "objectDetect.cc"
#include        "Region.h"
#include        "test_PatchCorrespondenceGen_functions.cc"
#include        "HoughTransform.h"
#include        "Gaussian.h"
#include	"test_houghTransform.h"       // generated by command-line parser gen
#include	"BicubicInterpolator.h"
#include	"BilinearInterpolator.h"
#include	"erode.h"
#include	"Dilate.h"
#include	"EdgeFinder.h"

#include "ptr_to_ogl.h"

#include        "dilate.cc"
#include        "posProject.h"
#include        "posProject.cc"


using namespace bbcvp;
using namespace std;

#define MAX(a,b) ((a) > (b) ? (a) : (b))
#define MIN(a,b) ((a) < (b) ? (a) : (b))

// comment out line below to stop it trying to open a DVS card and instead read images using oGeM library
//#define USING_DVS

#define REF_REATURES_100M_HD

//#define REF_FEATURES_sprint_17_46_49_06

//#define REF_REATURES_60M
//#define REF_REATURES_200M
// PALINSEQ1 is a palindromed version of windows/D/bham09-day1-longjump-00-36-38-00/ that plays backwards from image 400
//#define REF_FEATURES_PALINSEQ1
// PALINSEQ2 is a palindromed version of windows/D/bham09-day1-training-01-03-32-17/ that plays backwards from image 400
//#define REF_FEATURES_PALINSEQ2

// define this to test using a triangle strip to define a region to set a chromakeyer from
//#define TEST_TRISTRIP_KEY

// define this to have a triangle strip ignore region along the 60m running track
//#define TEST_TRISTRIP_IGNORE
#define TRACK_TRISTRIP_IGNORE

#ifdef USING_DVS

// comment out line below to stop it trying to send out free-d messages (which needs the VPdataDevice lib)
// (can't do free-d output if not using DVS as it needs the DVS card for timing info)
#define FREED_OUTPUT

#include "DVSClasses.h"
#include "UnixTerminal.h"  // allow interactive keyboard input when using DVS
#ifdef FREED_OUTPUT
#include        "FreedSender.h"
#endif

#else  // if not using DVS output....

#include        "o_Picture.h"
#include        "o_PicReadFileSeq.h"
#include        "ReadImage.h"
#include        "WriteImage.h"

#endif

bool writeOutCam(char *camFileName, int frame, double pos_x, double pos_y, double pos_z,
                                                                  double pan, double tilt, double roll,
                                                                   double focalLength, int widthPixels, int heightPixels, double notionalPixHeight, double notionalPixWidth)
{
   FILE *fp;


   if((fp = fopen(camFileName, "w")) == NULL)
   {
    printf("Cannot create file %s\n", camFileName);
    return 0;
   }


   double view_x, view_y, view_z, up_x, up_y, up_z;
   ptr_to_viewvec_upvec_deg(pan, tilt, roll, &view_x, &view_y, &view_z, &up_x, &up_y, &up_z);



 //  double centreX, centreY;
 //  myPoseEst->getCamPixelsSize(&centreX, &centreY);

   notionalPixWidth =  (((notionalPixHeight*576)/9)*16)/720; // notionalPixHeight;//


 //  fprintf(fp, "%s\n", camFileName.c_str());

   fprintf(fp, "#SOGEM V1.1 ascii\n");
   fprintf(fp, "o_Camera {\n");
   fprintf(fp, "\tIdent\t%d\n", int(frame));
   fprintf(fp, "\tCVec\t%f\t%f\t%f\n", pos_x, pos_y, pos_z);
   //fprintf(fp, "\tCVec\t%f\t%f\t%f\n", 0.0, 0.0, 0.0);
   fprintf(fp, "\tAVec\t%f\t%f\t%f\n", view_x, view_y, view_z);
   fprintf(fp, "\tUpVec\t%f\t%f\t%f\n", up_x, up_y, up_z);
   fprintf(fp, "\tWidth\t%d\n", widthPixels);
   fprintf(fp, "\tHeight\t%d\n", heightPixels);
   fprintf(fp, "\tPixelSizeX\t%g\n", notionalPixWidth);
   fprintf(fp, "\tPixelSizeY\t%g\n", notionalPixHeight);
   fprintf(fp, "\tCenterPointShiftX\t%d\n", int(0));
   fprintf(fp, "\tCenterPointShiftY\t%d\n", int(0));
   fprintf(fp, "\tFocalLength\t%f\n", focalLength);
   fprintf(fp, "\tIris\t%d\n", int(1));
   fprintf(fp, "\tReciprocalFocus\t%d\n", int(0));
   fprintf(fp, "\tExposureTime\t%d\n", int(0));
   fprintf(fp, "}\n");

   fclose(fp);
   return 0;
}




int
ltest_PatchCorrespondenceGen( _test_PatchCorrespondenceGen_parameter &para)
{
    printf("Test program for PatchCorrespondenceGen class   BBC R&D\n");

  int orig_x = 0;
  int orig_y = 0;


  int new_x = 720;  //orig_x ;//
  int new_y = 405; //orig_y;//

  int maxCameras = 200;              // max number of images used when calibrating one camera (not the number of actual cameras)
  int maxPoints = para.maxFeatures;  // max number of texture patches to store
  int maxPatches = para.maxFeatures; // as above
  int maxRefParallelLines = 5;      // max number of reference lines whose direction is known but whose absolute position is not
  int maxRefWorldPoints = 0;       // max number of fixed world points we'll use when specifying the calibration
  int maxRefWorldLines = 50;       // max number of lines - in this case, all will be on the ref object but PatchCorGen will allocate space on all obejcts
  int weightR = 76;                  // If you really want luminance: Y=0.299R + 0.587G + 0.114B; multiply these by 255:
  int weightG = 150;
  int weightB = 29;
  bool isGaussian = para.gaussian;

  cout << "isGaussian " << isGaussian << endl;


  int gapsize_final = 0;

  int maxPointsPerLine = 2;        // only two points will be observed per line if fitting a straight line through them....
  if (para.useAllLinePoints) maxPointsPerLine=700;  // ... but need more (potentially up to longest image dim) if using 'raw' point observations

#ifdef BUILD_FOREST                 // define this to make PatchCorrespondenceGen allocate storage for classifier-based init
  int forestSize = 30;
  int maxdepth = 8;
  int threshold = 10;
  int degree = 3;
#else
  int forestSize = 0;
  int maxdepth = 0;
  int threshold = 0;
  int degree = 0;
#endif

  int sideBorder= 0;//12;     // was 12 // ignore this number of pixels on left and right (blanking)
  int topBorder =  0;//2;    // was 2  // and this number at top (for half-line of vertical blanking)
  int bottomBorder =  0;//2; // was 2  // and this number at bottom  (for half-line of vertical blanking)

  // these now set as parameters from the command line:
  int patchLenX = para.patchLenX;  // sizes used in KLT
  int patchLenY = para.patchLenY;
  int spacingX = para.spacingX;   // size of regions we look for features in, so equates to average feature spacing
  int spacingY = para.spacingY;
  int nResolutions = para.nResolutions;  //number of levels in image pyramid
  int motionDiffResolution = nResolutions > para.motionDiffRes ? para.motionDiffRes : nResolutions - 1; // resolution at which to perform non-camera motion differencing
  double camX=para.initX, camY=para.initY, camZ=para.initZ;
  double camPan= para.initPan,  camTilt= para.initTilt,  camRoll= para.initRoll, camFOV=para.initLensAngle;
  double panOffset=para.initPanOffset;

  int lenX, lenY, incX, incY;  // dims & packing of input sequence
  int lenYFullFrameField;      // the full number of lines in a frame or field
  int field1Offset, field2Offset; // offset from start of buffer to start of searched video
  double aspect;
  unsigned char *imageR, *imageG, *imageB;
  unsigned char *lineDiagnosticImage, *hGrad, *vGrad;  // for line features
  bool bottom2top = para.bottom2top;

  bool ignoreNonCamMotion = para.ignoreNonCameraMotion;
  unsigned char motionThresh = para.motionThresh;
  bool motionDilate = para.motionDilate;
  int motionDilateHalfWin = para.motionDilateHalfWin;

  bool drawCuboid = false;//true; //para.drawCuboid;  // big cuboid centred on camera
  bool drawPoints = false;//true;
  bool draw60mTrack=para.draw60mTrack;  // ground plane for a 60m track, lanes 1.22m wide
  //bool draw100mTrack=para.draw100mTrack;  // ground plane for a 100m track, lanes 1.25m wide
  bool drawMotionMask = para.drawMotionMask; // black mask area showing regions ignored due to non-camera motion

  bool testMultipleImageSolving = para.multiIm > 0;  // to test saving features & optimising across multiple images, set this true (it keeps one in 10)

  double drawDirScale = para.pointWeightScale / 10.0;  // scaling for directional weight diagnostic line lengths = point weight / 10.....
  if (para.drawDirScale_flag) drawDirScale = para.drawDirScale;   // ... unless over-ridden (e.g. may want to change if using non-fixed weights)

  bool adjCamX = (para.adjCamX > 0);
  bool adjCamY = (para.adjCamY > 0);
  bool adjCamZ = (para.adjCamZ > 0);

  // Below are various sets of reference features for particular captured sequences we have, to simulate the effect of
  // an operator using a GUI to enter refer3ence lines/points on given frames

#ifdef REF_REATURES_100M_HD
  // points to use as world reference points - these are suitable for the '60m-fields' test sequence
  // frameNo, worldX,Y,Z, imX,Y
  // with -99 to indicate no more
  // NB must not be more than maxRefWorldPoints points specified here
  double refPoints[100] = {//0, 0.0, 0.0, 0.0, 507, 197, 
			   //0, 0.0, 0.0, 6.1, 211, 208,
			   //0, 2.0, 0.0, 0.0, 583, 207,   // no definitive marks at 2m - its just a guess
			   //0, 2.0, 0.0, 6.1, 285, 219,   // ditto - so best to ignore these two
			   //390, 60.0, 0.0, 0.0, 354, 162,
			   //390, 60.0, 0.0, 6.1, 353, 232,
			   -99 };

  // lines to use as world references:
  // frameNo, StartWorldX,Y,Z, EndWorldX,Y,Z, StartImageX,Y, EndImageX,Y
  // with -99 to indicate no more 
  // NB must not be more than maxRefWorldLines lines specified
  double refLines[500] = { 
            0,     0, 0, 0,     100, 0, 0,       1208, 186,  1914, 287,//inside line
			   0,     0, 0, 0,    0, 0, 10.98,      1790, 270,  278, 285, // start line
			   //0,     0, 0, 4.88,   100, 0, 4.88,         917, 242,  1916, 404, // middle line on track
			   0,     0, 0, 10.98,  100, 0, 10.98,  9, 233,  1478, 523, //outside of lane 9
			  // 0,     10, 0, 0,    10, 0, 11.25,      1906, 475,  1280, 483, // 10m hurdle line?            
			   0,     -10, 0, 0,    -10, 0, 10.98,     1314, 203,  90, 215, // 110m hurdle start line?      

            //0,     0, 0, 7.32,  60, 0, 7.32, 153, 211,  495, 262,  // bottom line deliberately a bit wrong
			   /*--------
                           170,   0, 0, 0,     60, 0, 0,    334, 187,  658, 226, // back line on track
			   170,   0, 0, 0,    0, 0, 7.32,   144, 166,  18,  171, // start line
			   170,   0, 0, 3.66,  60, 0, 3.66, 112, 189,  616, 256, // middle line on track
                           170,   0, 0, 7.32,  60, 0, 7.32,  94, 222,  469, 279, // front line on track
                           270,   0, 0, 0,     60, 0, 0,    105, 148,  621, 193, // back line on track
			   270,   0, 0, 3.66,  60, 0, 3.66, 122, 182,  614, 231, // middle line on track
			   270,   0, 0, 7.32,  60, 0, 7.32, 115, 225,  480, 266, // front line on track
                           300,   0, 0, 0,     60, 0, 0,    135, 151,  680, 189, // back line on track
			   300,   0, 0, 3.66,  60, 0, 3.66,  81, 181,  668, 228, // middle line on track
			   300,   0, 0, 7.32,  60, 0, 7.32, 141, 230,  659, 279, // front line on track
                           310,   0, 0, 0,     60, 0, 0,    111, 152,  641, 185, // back line on track
			   310,   0, 0, 3.66,  60, 0, 3.66,  70, 184,  633, 224, // middle line on track
			   310,   0, 0, 7.32,  60, 0, 7.32,  66, 229,  548, 268, // front line on track
                           343,   0, 0, 0,     60, 0, 0,     28, 159,  682, 179, // back line on track
			   343,   0, 0, 3.66,  60, 0, 3.66,  70, 198,  635, 218, // middle line on track
			   343,   0, 0, 7.32,  60, 0, 7.32,  32, 247,  622, 271, // front line on track
			   350,   0, 0, 0,     60, 0, 0,     41, 162,  655, 176, // back line on track
			   350,   0, 0, 3.66,  60, 0, 3.66,  55, 201,  602, 215, // middle line on track
			   350,   0, 0, 7.32,  60, 0, 7.32,  63, 252,  576, 267, // front line on track
			   350,   55, 0, 0,    55, 0, 7.32,  421, 182, 334, 254, // 5m-from-end dashed line
                           386,   0, 0, 0,     60, 0, 0,     24, 165,  646, 161, // back line on track
			   386,   0, 0, 7.32,  60, 0, 7.32,  68, 255,  644, 251, // front line on track
			   386,   0, 0, 3.66,  60, 0, 3.66,  88, 203,  635, 200, // middle line on track
			   386,   60,0, 0,     60, 0, 7.32, 354, 162,  353, 251, // finish line
			   386,   57,0, 0,     57, 0, 7.32, 145, 167,  84, 249,  // dashed line 3m from end - added 21.11.09
			   ----------------*/


			   // duplicate those in frame 388....
            /*               388,   0, 0, 0,     60, 0, 0,     24, 165,  646, 161, // back line on track
			   388,   0, 0, 7.32,  60, 0, 7.32,  68, 255,  644, 251, // front line on track
			   388,   0, 0, 3.66,  60, 0, 3.66,  88, 203,  635, 200, // middle line on track
			   388,   60,0, 0,     60, 0, 7.32, 354, 162,  353, 251, // finish line
			   388,   57,0, 0,     57, 0, 7.32, 145, 167,  84, 249,  // dashed line 3m from end - added 21.11.09*/
                           -99 };


  // lines parallel to a given axis but in unknown positions
  // frameNo, axis (0=x, 1=y, 2=z),  StartImageX,Y, EndImageX,Y
  // with -99 to indicate no more
  // NB must not be more than maxRefParallelLines lines specified here
  double refParallelLines[100] = { //270, 2, 570, 200, 344, 233,
				   //310, 2, 560, 192, 349, 251,
				   //350, 2, 421, 182, 334, 254,
				   -99 };

#endif



#ifdef REF_REATURES_60M
  // points to use as world reference points - these are suitable for the '60m-fields' test sequence
  // frameNo, worldX,Y,Z, imX,Y
  // with -99 to indicate no more
  // NB must not be more than maxRefWorldPoints points specified here
  double refPoints[100] = {//0, 0.0, 0.0, 0.0, 507, 197,
                           //0, 0.0, 0.0, 6.1, 211, 208,
                           //0, 2.0, 0.0, 0.0, 583, 207,   // no definitive marks at 2m - its just a guess
                           //0, 2.0, 0.0, 6.1, 285, 219,   // ditto - so best to ignore these two
                           //390, 60.0, 0.0, 0.0, 354, 162,
                           //390, 60.0, 0.0, 6.1, 353, 232,
                           -99 };

  // lines to use as world references:
  // frameNo, StartWorldX,Y,Z, EndWorldX,Y,Z, StartImageX,Y, EndImageX,Y
  // with -99 to indicate no more
  // NB must not be more than maxRefWorldLines lines specified
  double refLines[500] = { 0,     0, 0, 0,     60, 0, 0,    507, 197,  693, 220,
			   0,     0, 0, 0,    0, 0, 7.32,   507, 197,  153, 211, // start line
			   0,     0, 0, 3.66,  60, 0, 3.66, 362, 207,  569, 237, // middle line on track
			   0,     0, 0, 7.32,  60, 0, 7.32, 153, 211,  495, 267,
            
            
            //0,     0, 0, 7.32,  60, 0, 7.32, 153, 211,  495, 262,  // bottom line deliberately a bit wrong
			   /*--------
                           170,   0, 0, 0,     60, 0, 0,    334, 187,  658, 226, // back line on track
                           170,   0, 0, 0,    0, 0, 7.32,   144, 166,  18,  171, // start line
                           170,   0, 0, 3.66,  60, 0, 3.66, 112, 189,  616, 256, // middle line on track
                           170,   0, 0, 7.32,  60, 0, 7.32,  94, 222,  469, 279, // front line on track
                           270,   0, 0, 0,     60, 0, 0,    105, 148,  621, 193, // back line on track
                           270,   0, 0, 3.66,  60, 0, 3.66, 122, 182,  614, 231, // middle line on track
                           270,   0, 0, 7.32,  60, 0, 7.32, 115, 225,  480, 266, // front line on track
                           300,   0, 0, 0,     60, 0, 0,    135, 151,  680, 189, // back line on track
                           300,   0, 0, 3.66,  60, 0, 3.66,  81, 181,  668, 228, // middle line on track
                           300,   0, 0, 7.32,  60, 0, 7.32, 141, 230,  659, 279, // front line on track
                           310,   0, 0, 0,     60, 0, 0,    111, 152,  641, 185, // back line on track
                           310,   0, 0, 3.66,  60, 0, 3.66,  70, 184,  633, 224, // middle line on track
                           310,   0, 0, 7.32,  60, 0, 7.32,  66, 229,  548, 268, // front line on track
                           343,   0, 0, 0,     60, 0, 0,     28, 159,  682, 179, // back line on track
                           343,   0, 0, 3.66,  60, 0, 3.66,  70, 198,  635, 218, // middle line on track
                           343,   0, 0, 7.32,  60, 0, 7.32,  32, 247,  622, 271, // front line on track
                           350,   0, 0, 0,     60, 0, 0,     41, 162,  655, 176, // back line on track
                           350,   0, 0, 3.66,  60, 0, 3.66,  55, 201,  602, 215, // middle line on track
                           350,   0, 0, 7.32,  60, 0, 7.32,  63, 252,  576, 267, // front line on track
                           350,   55, 0, 0,    55, 0, 7.32,  421, 182, 334, 254, // 5m-from-end dashed line
                           386,   0, 0, 0,     60, 0, 0,     24, 165,  646, 161, // back line on track
			   386,   0, 0, 7.32,  60, 0, 7.32,  68, 255,  644, 251, // front line on track
			   386,   0, 0, 3.66,  60, 0, 3.66,  88, 203,  635, 200, // middle line on track
			   386,   60,0, 0,     60, 0, 7.32, 354, 162,  353, 251, // finish line
			   386,   57,0, 0,     57, 0, 7.32, 145, 167,  84, 249,  // dashed line 3m from end - added 21.11.09
			   ----------------*/


			   // duplicate those in frame 388....
            /*               388,   0, 0, 0,     60, 0, 0,     24, 165,  646, 161, // back line on track
			   388,   0, 0, 7.32,  60, 0, 7.32,  68, 255,  644, 251, // front line on track
			   388,   0, 0, 3.66,  60, 0, 3.66,  88, 203,  635, 200, // middle line on track
			   388,   60,0, 0,     60, 0, 7.32, 354, 162,  353, 251, // finish line
			   388,   57,0, 0,     57, 0, 7.32, 145, 167,  84, 249,  // dashed line 3m from end - added 21.11.09*/
                           -99 };


  // lines parallel to a given axis but in unknown positions
  // frameNo, axis (0=x, 1=y, 2=z),  StartImageX,Y, EndImageX,Y
  // with -99 to indicate no more
  // NB must not be more than maxRefParallelLines lines specified here
  double refParallelLines[100] = { //270, 2, 570, 200, 344, 233,
                                   //310, 2, 560, 192, 349, 251,
                                   //350, 2, 421, 182, 334, 254,
                                   -99 };

#endif

#ifdef REF_REATURES_200M
// minimal set of ref features in frame 49, suitable for 200m race
  double refLines[500] = {  49,     0, 0, 0,     60, 0, 0,    507, 197,  693, 220, // back line on track
                            49,     0, 0, 0,    0, 0, 7.32,   507, 197,  153, 211, // start line
                            49,     0, 0, 3.66,  60, 0, 3.66, 362, 207,  569, 237, // middle line on track
                            49,     0, 0, 7.32,  60, 0, 7.32, 153, 211,  495, 267, // front line on track
                            -99 };
  double refParallelLines[100] = { -99 };
  double refPoints[100] = { -99 };

#endif

#ifdef REF_FEATURES_sprint_17_46_49_06
  // for Crystal Palace tape, around 17:46:49:06
  // Note that features are for bottom2top order and include borders:
#define FEATURES_BOTTOM2TOP_WITHBORDERS
  double refLines[500] = {  0,   0.00,  0.00, -4.88,    -110.00,  0.00, -4.88,     132.69, 134.50,    409.03, 134.00,  // line 2
                            0,   0.00,  0.00,  4.88,    -110.00,  0.00,  4.88,      48.34,  52.00,    408.34,  53.50,  // line 10
                            0,   0.00,  0.00, -4.88,       0.00,  0.00,  4.88,     408.34, 180.50,    407.66,  42.50,  // line 11
                            0,  -5.00,  0.00, -4.88,      -5.00,  0.00,  4.88,     197.83, 160.00,     44.91,  39.50,  // line 122
                            2,   0.00,  0.00,  0.00,    -110.00,  0.00,  0.00,      89.49, 101.50,    407.66,  99.50,  // line 6
                            //2,   0.00,  0.00,  0.00,    -110.00,  0.00,  0.00,      89.49, 111.50,    407.66, 109.50,  // line 6 -deliberately 10 field lines out
                            -99 };
  double refParallelLines[100] = { -99 };
  double refPoints[100] = { -99 };

#endif

#ifdef REF_FEATURES_PALINSEQ1
  // width of actual sandy part of pit pit at Birmingham Alexander is 2.89m.  Put origin in middle of takeoff board
  // assume frame 430 is the first one we'll see
  double refLines[500] = { 430, 4.00, 0.00, -1.445,   8.00, 0.00, -1.445,     43, 167,     484, 168,  // far side of sant pit, under ruler
                           430, 4.00, 0.00,  1.445,   8.00, 0.00,  1.445,     45, 251,     515, 250,  // near side of sant pit
                           430, 5.00, 0.00, -1.445,   5.00, 0.00,  1.445,     158, 168,    129, 249,   // 5m line across pit
                           430, 6.00, 0.00, -1.445,   6.00, 0.00,  1.445,     266, 168,    259, 250,   // 6m line across pit
                           430, 8.00, 0.00, -1.445,   8.00, 0.00,  1.445,     484, 168,    515, 250,   // 8m line across pit
                           // 740, -40.0, 0.0,  // TODO: put in some ref lines

                           -99 };

  double refParallelLines[100] = { -99 };
  double refPoints[100] = { -99 };

#endif

#ifdef REF_FEATURES_PALINSEQ2
  // width of actual sandy part of pit pit at Birmingham Alexander is 2.89m.  Put origin in middle of takeoff board
  // assume frame 430 is the first one we'll see
  double refLines[500] = { 400, 4.00, 0.00, -1.445,   8.00, 0.00, -1.445,     45, 160,     647, 162,  // far side of sant pit, under ruler
                           400, 4.00, 0.00,  1.445,   8.00, 0.00,  1.445,     40, 241,     549, 240,  // near side of sant pit
                           400, 5.00, 0.00, -1.445,   5.00, 0.00,  1.445,     241, 161,    213, 240,   // 5m line across pit
                           400, 6.00, 0.00, -1.445,   6.00, 0.00,  1.445,     347, 161,    340, 240,   // 6m line across pit
                           400, 8.00, 0.00, -1.445,   8.00, 0.00,  1.445,     562, 161,    594, 241,   // 8m line across pit
                           780, -60, 0.0,  0.65,      -50.0,  0.0,   0.65,      258, 146,    597, 225,   // far line at track at far end
                           780, -60, 0.0, -0.65,      -50.0,  0.0,  -0.65,      201, 183,    514, 261,   // near line at track at far end
                           -99 };

  double refParallelLines[100] = { -99 };
  double refPoints[100] = { -99 };

#endif

  // ---- values concerned with output of focal length as free-d data for use with a zfc lens file:
  double notionalPixHeight = 9.0e-6;            // must match value in zfc file
  int maxZoomForZFCOutput = 65000;           // must be less than 65535
  double ZFCCoeff0 = 4.0;          // chosen as biggest value for 1/f we'll ever get (so zoom=maxZoom => f=0.25=> fov=1.2 degrees)
  double ZFCCoeff1 = -0.005;         // chosen so that ZFCCoeff0 + (-65000*ZFCCoeff1) is smallest val of 1/f

#ifdef USING_DVS
  DVSCard *mycard;                                // a DVS card
#else
  // set up to read a sequence of numbered images using oGeM/VPbase library
  init_oGeM();
  o_CPicture<unsigned char> *in = new o_CPicture<unsigned char>( );
  o_CPicture<unsigned char> *lineDiag;
  o_PicReadFileSeq inputSeq;

  o_CPicture<unsigned char> *prev1;
  o_CPicture<unsigned char> *in2;
  o_CPicture<unsigned char> *prev2;
  o_CPicture<unsigned char> *prev1mask;
  o_CPicture<unsigned char> *prev2mask;
  o_CPicture<unsigned char> *prev3mask;
  o_CPicture<unsigned char> *prev4mask;
  o_CPicture<unsigned char> *prev5mask;
  o_CPicture<unsigned char> *prev6mask;
  o_CPicture<unsigned char> *prev7mask;
  o_CPicture<unsigned char> *huemask;
  o_CPicture<unsigned char> *huemap;
  o_CPicture<unsigned char> *greyscaleout3;
  o_CPicture<unsigned char> *inmask;
  o_CPicture<unsigned char> *inmaskreverse;
  o_CPicture<unsigned char> *prev2map;
  o_CPicture<unsigned char> *divermap;
  o_CPicture<unsigned char> *arsemask;
  o_CPicture<unsigned char> *arsemask2;
  o_CPicture<unsigned char> *arsemask3;
  o_CPicture<unsigned char> *arsemask4;
  o_CPicture<unsigned char> *arsemask5;
  o_CPicture<unsigned char> *arsemask6;
  o_CPicture<unsigned char> *arsemask7;
  o_CPicture<unsigned char> *arsemask8;
  o_CPicture<unsigned char> *arsemap;
  o_CPicture<unsigned char> *arsehue;
  o_CPicture<unsigned char> *arsehuefirst;
  o_CPicture<unsigned char> *xmarksthearse;
  o_CPicture<unsigned char> *hueverywide;
  o_CPicture<unsigned char> *houghness;
  o_CPicture<unsigned char> *arsemaskdiff;
  o_CPicture<unsigned char> *arsemaskdiff2;
  o_CPicture<unsigned char> *arsemaskdiff3;
  o_CPicture<unsigned char> *greyscaleout8;
  o_CPicture<unsigned char> *heap;
  o_CPicture<unsigned char> *boardmask;
  o_CPicture<unsigned char> *gaussianed;
  o_CPicture<unsigned char> *gauss;
  o_CPicture<unsigned char> *resizedmask;
  o_CPicture<unsigned char> *resizeddiff;
  o_CPicture<unsigned char> *boxblur;
  o_CPicture<unsigned char> *blurredmask;
  o_CPicture<unsigned char> *kneemask;
  o_CPicture<unsigned char> *shouldermask;
  o_CPicture<unsigned char> *footmask;
  o_CPicture<unsigned char> *kneemap;
  o_CPicture<unsigned char> *shouldermap;
  o_CPicture<unsigned char> *footmap;


    //++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
  //Some new images used to read from file so their contents can be shifted about on the current image.
  //Not needed if we have a array of images in memory instead.
  o_CPicture<unsigned char> *capturedImage;
  o_CPicture<unsigned char> *capturedImageMask;

  //Arrays to contain the current world position of the centre of the images.
  //These are our very simple method for relating the pictures together.
  double wx[300];
  double wy[300];
  double wz[300];
  //++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

   posProject *destinationPose;
   posProject *startPose; //Could be changed to arrays to avoid needless readings in of images
   
   
///////////////////////////////Frame storing Bit//////////////////////////////////////////////////////////////

      int numberOfFrames = para.out_pnt-para.in_pnt;

      printf("\n NUMBER OF FRAMES: %03d\n", numberOfFrames);

       //  o_CPicture<unsigned char> *picturearray[200];
      //   o_CPicture<unsigned char> *pictureinputarray[200];
         o_CPicture<unsigned char> *pictureoutputarray[200];
      //   o_CPicture<unsigned char> *picturemaskarray[200];
         o_CPicture<unsigned char> *blurredpicturemaskarray[200];
         int footdataarray[200];
         int maxFootXarray[200];
         double worldXarray[200];
         double worldYarray[200];
         double worldZarray[200];
         double bodyXarray[200];
         double bodyYarray[200];
         double bodyZarray[200];
         double realworldx[200];
         double realworldy[200];
         double parabola_array_x[200];
         double parabola_array_y[200];
         int jumpcounter = 0;
         int jumpFrameNumber = 0;
         int boardEndAtJumpFrameNumber = 0;
         int boardLevelAtJumpFrameNumber = 0;
         int diverdata[5];
         int prev_knee_x = 0;
         int prev_knee_y = 0;
         int prev_shoulder_x = 0;
         int prev_shoulder_y = 0;
         int prev_feet_x = 0;
         int prev_feet_y = 0;
         int prev_arse_x = 0;
         int prev_arse_y = 0;
         double kneelength = 0;
         double shoulderlength = 0;
         double feetlength = 0;
         double prev_knee_worldX = 0;
         double prev_knee_worldY = 0;
         double prev_knee_worldZ = 0;

/////////////////////////////////////////////////////////////////////////////////////////

                for (int i = 0; i < 5; i++)
                {  diverdata[i] = 0; }



  char buf[500];
  sprintf(buf,"-patt %s -start %d -end %d -inc 1", para.i, para.in_pnt, para.out_pnt );
  if (inputSeq.Open( buf )!= o_OK)
    { fprintf(stderr,"Error opening image sequence %s\n",para.i);   exit (-1); }
#endif

  PatchCorrespondenceGen *myCorrespGen;

  PoseEstPanTiltHead *myPoseEst;
  InitialPoseEstLines *myInitialPoseEstLines;  // for tracking from lines
  ChromaKeyer *mykeyer;                        // a ChromaKeyer for use by the line tracker
#ifdef TEST_TRISTRIP_KEY
  ChromaKeyer *keyerForGraphics = new ChromaKeyer();  // a chromakeyer for graphics overlay
  keyerForGraphics->clearChromaKey();        // clear key in case we're accumulating contributions or doing recursive filtering
#endif

// not using lines yet - any lines will be loaded in after we've created PatchCorrespondenceGen, which we can't do until we know the image size
  bool usingLines = false;
  int nLinesToTrack = 0;

  // loop for reading image
  bool first = true;

  // type of first image
  //int fieldType=-1;  // -1=all ims are progressive, 0 for 1st im is top field, 1 for 1st=bottom field
  int fieldType=0;  // -1=all ims are progressive, 0 for 1st im is top field, 1 for 1st=bottom field

  // optionally open a log file to write measured parameters to (e.g. for importing into Excel)
  FILE *logFile = (FILE*)NULL;
  if (para.logFile_flag)
    {
      if ( (logFile = fopen(para.logFile, "w")) == NULL)
        {
          printf("Can't open log file %s for writing\n",para.logFile);
          exit (-1);
        }
    }

  // open DVS card and start acquisition & output
#ifdef USING_DVScout << " I bet it brakes now" << endl;

  cout << "- Creating DVSCard: ";
  mycard = new DVSCard(0);
  cout << "done" << endl;
  if ( bottom2top ) {
    cout << "    video mode: PAL_FRAMES_RGBA_BOTTOM2TOP_NOAUDIO" << endl;
    mycard->set_VideoMode(DVSCard::VIDEOMODE_PAL_FRAMES_RGBA_BOTTOM2TOP_NOAUDIO);
  } else {
    cout << "    video mode: PAL_FRAMES_RGBA_NOAUDIO" << endl;
    mycard->set_VideoMode(DVSCard::VIDEOMODE_PAL_FRAMES_RGBA_NOAUDIO);
  }
  mycard->sync(SV_SYNC_EXTERNAL);
  cout << "    video sync: EXTERNAL" << endl;
  mycard->FIFO_StartDMAInput();
  mycard->FIFO_StartDMAOutput();

  int bufsize = mycard->get_FIFOBufferSizeReq();        // get number of bytes we need to hold a frame of video

  unsigned char *mybuf = (unsigned char*)memalign(16,bufsize);
  para.in_pnt=0;
  para.out_pnt=1<<30;  // effectively an infinite no. of frames if using DVS input

  int lenXFull = 720;  // the full dims of the image: these determine the packing of the image in the...
  int lenYFull = 576;  // ...frame buffer, and the height that the vertical field-of-view matches

  lenX = lenXFull - 2*sideBorder;
  incX = 4;  // as DVS card reads/writes RGBA
  if (fieldType==-1)  //if treating each image as progressive....
    {
      lenY = lenYFull - ( topBorder + bottomBorder );
      incY = 4 * lenXFull;
      lenYFullFrameField = lenYFull;
    }
  else
    {
      lenY = lenYFull/2 - ( topBorder + bottomBorder );
      incY = 4 * lenXFull * 2;  // the "*2" is because we are processing fields
      lenYFullFrameField = lenYFull / 2;
    }

    if ( bottom2top )
    {
      // fields start at bottom of image
      field1Offset = sideBorder*incX + topBorder*incY + (lenY-1)*incY + (incY/2);
      field2Offset = sideBorder*incX + topBorder*incY + (lenY-1)*incY;
    }
  else
    {
      // fields start at top of image
      field1Offset = sideBorder*incX + topBorder*incY;
      field2Offset = sideBorder*incX + topBorder*incY + (incY/2);
    }

// if automatically detecting range for init, set initial values to a 'zero' range:
  if (para.autoRange)
    {
      para.pMin = 180.0;
      para.pMax = -180.0;
      para.tMin = 180.0;
      para.rMax = -180.0;
      para.rMin = 180.0;
      para.rMax = -180.0;
      para.fMin = 170.0;
      para.fMax = 0.01;
    }

  // if doing free-d output, create the free-d output class and the sender class
#ifdef FREED_OUTPUT
  bbcvp::FreedDataDevice *freedDevice;
  bbcvp::FreedSender *freedSender;
  DVSHandle *dvsHandle = new DVSHandle(mycard);  // to pass to FreedSendeer
  sv_handle *cardHandle = (dvsHandle->getDVSHandle());  // for use with sv_vsyncwait

  bool useFreedSender = para.freedPort_flag;  // whether we want to do any free-d output

  // try to open output free-d port
  if (useFreedSender)
    {
      cout << "- Creating FreedDataDevice output: ";
      // create & configure
      freedDevice = new FreedDataDevice( );
      // open port
      useFreedSender = freedDevice->open( para.freedPort );
      if ( useFreedSender ) cout << "    opened " << para.freedPort << endl;
      else
        { cout << "    could not open " << para.freedPort << endl; exit (-1); }

      freedSender = new FreedSender(freedDevice, dvsHandle);
      freedSender->startSenderThread();

    }  // if using freed sender

#endif // if freed output
o_CPicture<unsigned char> *gaussianed;
  // create a simple text interface if using DVS interface
  bbcvp::UnixTerminal term;
  printf("Keypresses:\n");
  printf("q     Quit\n");
  printf("l     Look for new permanent patches while tracking\n");
  printf("s     Stop looking for new permanent patches while tracking\n");
  printf("f     Toggle looking for temporary features\n");
  printf("d     Toggle drawing feature points\n");
  printf("i     Re-initialise by doing exhaustive search\n");
  printf("t     Toggle tracking on/off\n");
  printf("w     Toggle weight scaling based on match error\n");
  printf("e     Send free-d mesages to simulate end-to-ending the lens\n");
  printf("r     Toggle rescaling of stored patches\n");
  printf("o     Toggle video output\n");
  printf("1..4  Load patch files 1-4; SHIFT-1..4 = save patch files 1..4\n");

#endif

  // things that can be changed via keypreses (when taking live video input)
  bool running = true;  // so loop can be stopped, e.g. by keypress
  bool lookForNewPermanentPatches = para.lookForPerm;
  bool lookForNewTemporaryPatches = para.lookForTemp;

  bool doExhaustiveSearch = false;
  bool doTracking = true;
  bool weightUsingMatchErr = true;
  bool rescalePatches = true;
  bool sendEndToEnd = false;
  bool sendEndToEndOnNextFieldZero = false;
  bool doVideoOutput = true;
  bool refineGlobally = para.refineGlobally;

  int droppedFrames=0;
  int nextRefPoint = 0;  // for reading world ref points out of
  int nextRefLine = 0;  // for reading world ref lines out of
  int nextRefParallelLine = 0;  // for reading world ref lines out of

  double pan=0.0, tilt=0.0, roll=0.0, fovy=40.0, focalLength=0.001;  // dummy values for first message

  // for measuring execution time of various stages:
  double loadImageTimeTotal=0.0, findCorrespondencesTimeTotal=0.0, findLinesTimeTotal=0.0, calcSolutionTimeTotal=0.0, findNewFeaturesTimeTotal=0.0;
  double loadImageTimeMax = 0.0, findCorrespondencesTimeMax=0.0, findLinesTimeMax=0.0, calcSolutionTimeMax=0.0, findNewFeaturesTimeMax=0.0;
  double calcFullSolutionTimeTotal=0.0, calcFullSolutionTimeMax=0.0;
  double ignoreNonCamMotionTimeTotal=0.0, ignoreNonCamMotionTimeMax=0.0;
  double keyCalcTimeTotal=0.0, keyCalcTimeMax=0.0;

  // for measuring the accumulated 2nd derivative of pan, tilt and field-of-view, to give a measure of tracking stability
  double panSecDerivSquaredTotal=0.0, tiltSecDerivSquaredTotal=0.0, fovSecDerivSquaredTotal=0.0;
  double prevPan=0.0, prevPanChange=0.0, panChange=0.0;
  double prevTilt=0.0, prevTiltChange=0.0, tiltChange=0.0;
  double prevFov=0.0, prevFovChange=0.0, fovChange=0.0;
  double prevRoll=9999.0; // used for temporal roll filter: large value will disable it on first frame

  int inliersTotal=0, searchedFeaturesTotal=0;
  int nFieldsProcessed=0;
  int interactiveAdjustAxis=0;
  double interactiveAdjustUnit=1.0;
  double prevFOV=99999;  // used for temporal filter of field-of-view: large value will cause filter to be disabled on first frame

  for(int i=0; i<200;i++)
         {
       //  picturearray[i] = new o_CPicture<unsigned char>(new_x , new_y ,3);
         footdataarray[i] = 0;
         maxFootXarray[i] = 0;
         worldXarray[i] = 0;
         worldYarray[i] = 0;
         worldZarray[i] = 0;
         bodyXarray[i] = 0;
         bodyYarray[i] = 0;
         bodyZarray[i] = 0;
         realworldx[i] = 0;
         realworldy[i] = 0;
         parabola_array_x[i] = 0;
         parabola_array_y[i] = 0;
         }

  double prevButOneFOV = 99999;  // for test using linear extrapolation of fov for filter

  double initial_time = clock();


  for (int frame=para.in_pnt; frame < para.out_pnt-2 && running; frame++)  //actually counts fields if working interlaced
  {
      timeval startTime, endTime;  // for timing various bits
      timespec time0, time1;       // alternative - for use with clock_gettime;
      double loadImageTime=0.0, findCorrespondencesTime=0.0, findLinesTime=0.0, calcSolutionTime=0.0, findNewFeaturesTime=0.0, calcFullSolutionTime=0.0;
      double ignoreNonCamMotionTime=0.0;
      double keyCalcTime=0.0;
      bool useFrameForGlobalSolve = false;  // not using image for global solution yet, as far as we know!
      int nFeaturesInCommon=0;              // (this is only looked at if we're keeping some images for global pose comp, and then it is set later)

#ifdef USING_DVS
      // load a new image unless we're processing f2 of a frame we already have
      if (fieldType != 1 )
        {
          mycard->FIFO_GetFrame(true, mybuf, bufsize, NULL, 0);
          imageR = mybuf +     field1Offset;
          imageG = mybuf + 1 + field1Offset;
          imageB = mybuf + 2 + field1Offset;
          lineDiagnosticImage = mybuf + 2 + field1Offset;  // put diag image from line finder in alpha channel
          droppedFrames = mycard->get_FIFODroppedOutputFrames();
        }
      else  // field 2 is already grabbed, but starts one line lower.....
        {
          imageR = mybuf +     field2Offset;
          imageG = mybuf + 1 + field2Offset;
          imageB = mybuf + 2 + field2Offset;
          lineDiagnosticImage = mybuf + 3 + field2Offset;
        }

      // make data from last field available for free-d output if compiled with this option and enabled:
#ifdef FREED_OUTPUT
      if (fieldType >= 0 && useFreedSender)       // no output if progresive mode (type=-1) or not doing o/p
        {
          if (para.lensFileEmulation == 0 || para.lensFileEmulation == 2)           // mode 0: zoom encoder = 100 * vert fov, mode 2: 300*fov
            {
              double scale = 100;  if (para.lensFileEmulation == 2) scale = 300.0;
            if (sendEndToEnd)
              {
                int zoom=0;
                if (fieldType == 1) zoom=180.0 * scale;           // send 0 on field "0" and 180 degrees on field "1"
                printf("\nEnd-to-ending: sending zoom=%d\n", zoom);
                freedSender->setData(fieldType,           // whether this is for field 0 or 1
                                     -pan+panOffset, tilt, -roll,   // signs changed for openGl-style to freed
                                     camX, camY, camZ,    // was 0.0, 0.0, 0.0 for  pos and height all zero
                                     zoom,                // zoom sent as int representing 100ths of a degree
                                     0,                   // focus set to zero
                                     frame,               // field count: so sender can check it sends in right order
                                     para.freedDelay);    // delay in microseconds
                if (fieldType == 1) sendEndToEnd = false; // stop after field 1 (always starts on field 0)
              }
            else
              freedSender->setData(fieldType,           // whether this is for field 0 or 1
                                   -pan+panOffset, tilt, -roll,   // signs changed for openGl-style to freed
                                   camX, camY, camZ,          // was 0.0, 0.0, 0.0 for  pos and height all zero
                                   (int)(fovy * scale + 0.5), // zoom sent as int representing 100ths of a degree
                                   0,                   // focus set to zero
                                   frame,              // field count: so sender can check it sends in right order
                                   para.freedDelay);    // delay in microseconds
          }
        else // zoomMode is non-zero: means reciprocal focal length
          {
            if (sendEndToEnd)
              {
                int zoom=0;
                if (fieldType == 1) zoom=maxZoomForZFCOutput;        // send 0 on field "0" and maxZoom on field "1"
                printf("\nEnd-to-ending: sending zoom=%d\n", zoom);
                freedSender->setData(fieldType,           // whether this is for field 0 or 1
                                     -pan+panOffset, tilt, -roll,   // signs changed for openGl-style to freed
                                     camX, camY, camZ,         // was 0.0, 0.0, 0.0 for  pos and height all zero
                                     zoom,                // zoom sent as int representing 100ths of a degree
                                     0,                   // focus set to zero
                                     frame,              // field count: so sender can check it sends in right order
                                     para.freedDelay);    // delay in microseconds
                if (fieldType == 1) sendEndToEnd = false; // stop after field 1 (always starts on field 0)
              }
            else
              {
                // invert calculation that zfc lens data decoding will do:
                // 1/f = k0 + k1*(z-MaxZoom)
                // where z is zoom value sent on serial interface, maxZoom is biggest value seen when end-to-ending,
                // k0 and k1 are the first two coefficients in the zfc file
                // so zoom value to send = (1/f-k0)/k1 + MaxZoom
                //
                double zoomOut = (double)maxZoomForZFCOutput + (1.0 / focalLength - ZFCCoeff0) / ZFCCoeff1;
                freedSender->setData(fieldType,           // whether this is for field 0 or 1
                                     -pan+panOffset, tilt, -roll,   // signs changed for openGl-style to freed
                                     camX, camY, camZ,         // was 0.0, 0.0, 0.0 for  pos and height all zero
                                     (int)(zoomOut + 0.5), // zoom value to send
                                     0,                   // focus set to zero
                                     frame,              // field count: so sender can check it sends in right order
                                     para.freedDelay);    // delay in microseconds
              } // if end-to-ending
          } // if zfc or ecf zoom output mode
        }  // if sending out free-d data

#endif  // if free-d output


      // process any keyboard input if using live video input
      int key;
      int key_was_pressed = false;
      while ( (key=term.readChrOrEscSeq(stdin)) != -1)
        {
          key_was_pressed = true;
          bool posChanged=false;
          switch (key)
            {
                case 'q': running=false; break;              // q=quit
                case 'g': refineGlobally = !refineGlobally ;  printf("Global refinement:  %s\n", refineGlobally? "On" : "Off"); break;
                case 'l': lookForNewPermanentPatches = true; printf("\nLearning patches\n"); break;   // l=look for new patches
                case 's': lookForNewPermanentPatches = false; printf("\nStopped learning patches\n"); break;  // s=stop looking for new patches
                case 'f': lookForNewTemporaryPatches = !lookForNewTemporaryPatches; printf("\nLooking for temp patches:%s\n", lookForNewTemporaryPatches? "On" : "Off"); break;
                case 'd': drawPoints=!drawPoints; break;     // d=toggle drawing points
                case 'm': drawMotionMask=!drawMotionMask; break;     // d=toggle drawing non-camera motion mask
                case ',': motionThresh=motionThresh>5?motionThresh-5:motionThresh;
                                        printf("threshold: %d\n",motionThresh);
                                        break;
                case '.': motionThresh=motionThresh<250?motionThresh+5:motionThresh;
                                        printf("threshold: %d\n",motionThresh);
                                        break;
                case 'b': motionDilateHalfWin=motionDilateHalfWin>1?motionDilateHalfWin-1:motionDilateHalfWin;
                                        break;
                case 'n': motionDilateHalfWin=motionDilateHalfWin<5?motionDilateHalfWin+1:motionDilateHalfWin;
                                        break;
                case 't': doTracking=!doTracking; break;     // t=toggle tracking on/off
                case 'i': doExhaustiveSearch = true; break;  // i=initialise by doing an exhaustive search
                case 'w': weightUsingMatchErr = !weightUsingMatchErr; printf("\nweightUsingMatchErr: %s\n", weightUsingMatchErr ? "On" : "Off"); break;
                case 'r': rescalePatches =!rescalePatches; printf("\nrescalePatches:%s\n",rescalePatches ? "On" : "Off"); break;
                case 'o': doVideoOutput =!doVideoOutput; printf("\ndoVideoOutput:%s\n",doVideoOutput ? "On" : "Off"); break;
                case 'e': sendEndToEndOnNextFieldZero = true; break;
                case '1': printf("Reading patches from file %s...\n", para.patchFileIO1); myCorrespGen->readPatches(para.patchFileIO1); break;
                case '2': printf("Reading patches from file %s...\n", para.patchFileIO2); myCorrespGen->readPatches(para.patchFileIO2); break;
                case '3': printf("Reading patches from file %s...\n", para.patchFileIO3); myCorrespGen->readPatches(para.patchFileIO3); break;
                case '4': printf("Reading patches from file %s...\n", para.patchFileIO4); myCorrespGen->readPatches(para.patchFileIO4); break;
                case '!': printf("Writing patches to file %s...\n",   para.patchFileIO1); myCorrespGen->writePatches(para.patchFileIO1); break;
                case '"': printf("Writing patches to file %s...\n",   para.patchFileIO2); myCorrespGen->writePatches(para.patchFileIO2); break;
                case '£': printf("Writing patches to file %s...\n",   para.patchFileIO3); myCorrespGen->writePatches(para.patchFileIO3); break;
                case '$': printf("Writing patches to file %s...\n",   para.patchFileIO4); myCorrespGen->writePatches(para.patchFileIO4); break;
                case 'x':   interactiveAdjustAxis=0; break;
                case 'y':   interactiveAdjustAxis=1; break;
                case 'z':   interactiveAdjustAxis=2; break;
                case 'p':   interactiveAdjustAxis=3; break;
                case '{': if (interactiveAdjustAxis==0) camX+=1.0; else if (interactiveAdjustAxis==1) camY+=1.0; else if (interactiveAdjustAxis==2) camZ+=1.0; else if (interactiveAdjustAxis==3) panOffset+=10.0; posChanged=true; break;
                case '}': if (interactiveAdjustAxis==0) camX-=1.0; else if (interactiveAdjustAxis==1) camY-=1.0; else if (interactiveAdjustAxis==2) camZ-=1.0; else if (interactiveAdjustAxis==3) panOffset-=10.0; posChanged=true; break;
                case '[': if (interactiveAdjustAxis==0) camX+=0.1; else if (interactiveAdjustAxis==1) camY+=0.1; else if (interactiveAdjustAxis==2) camZ+=0.1; else if (interactiveAdjustAxis==3) panOffset+=2.0; posChanged=true; break;
                case ']': if (interactiveAdjustAxis==0) camX-=0.1; else if (interactiveAdjustAxis==1) camY-=0.1; else if (interactiveAdjustAxis==2) camZ-=0.1;  else if (interactiveAdjustAxis==3) panOffset-=2.0;posChanged=true; break;
                case '-': if (interactiveAdjustAxis==0) camX+=0.01; else if (interactiveAdjustAxis==1) camY+=0.01; else if (interactiveAdjustAxis==2) camZ+=0.01; else if (interactiveAdjustAxis==3) panOffset+=0.1; posChanged=true; break;
                case '=': if (interactiveAdjustAxis==0) camX-=0.01; else if (interactiveAdjustAxis==1) camY-=0.01; else if (interactiveAdjustAxis==2) camZ-=0.01; else if (interactiveAdjustAxis==3) panOffset-=0.1; posChanged=true; break;

                if (posChanged) printf("\n-initPanOffset %7.3f -initX %7.3f -initY %7.3f -initZ %7.3f\n", panOffset, camX, camY, camZ);

            }  // end of switch
        }  // end of while loop reading keypresses

      // only start end-to-ending on a field 0 (as min & max are sent on fields 0 and 1)
      // (next field to output will be 0 if current field is 1, as output happens before this point)
      if (sendEndToEndOnNextFieldZero && fieldType == 1)
        {
          sendEndToEndOnNextFieldZero = false;
          sendEndToEnd = true;
        }

#else  // if not using DVS but reading from file.....
      //printf("lineDiagLoading frame %d...\n", frame);
      if (inputSeq.LoadNextPicture()!= o_OK)
        { fprintf(stderr,"Error reading fg image\n");   exit (-1); }

      //printf("Calling getPicture...\n");
      *in = inputSeq.GetPicture();

      //printf("Got picture!\n");
#endif
      if (first)  // initialise everything that needs to know image dimensions (as we couldn't do this earlier)
        {

    prev1 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    prev2 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);




    *prev1 = *in;
    *prev2 = *in;

 //   bbcvp::BilinearInterpolator *bc = new BilinearInterpolator();


#ifndef USING_DVS
          printf("dims are %dx%d with %d components\n",in->GetNx(), in->GetNy(), in->GetNz());

          if (in->GetNz() != 3) { printf("An RGB image is needed!!!!\n"); exit(-1); }

          // all coordinates, searching/writing test output, etc. is w.r.t. imageR/G/B and the lengths here....
          lenX = in->GetNx() - 2*sideBorder;
          lenY = in->GetNy() - topBorder - bottomBorder;
          lenYFullFrameField = in->GetNy();
          incX = in->GetElementPtr(1,0,0) - in->GetElementPtr(0,0,0);
          incY = in->GetElementPtr(0,1,0) - in->GetElementPtr(0,0,0);
          imageR = in->GetElementPtr(0,0,0) + sideBorder*incX + topBorder*incY;
          imageG = in->GetElementPtr(0,0,1) + sideBorder*incX + topBorder*incY;
          imageB = in->GetElementPtr(0,0,2) + sideBorder*incX + topBorder*incY;
#endif  // if not using DVS




#ifdef USING_DVS
      // if progressive or just done f2, write the result to the DVS card
      if (fieldType != 0 && doVideoOutput) mycard->FIFO_PutFrame(mybuf, bufsize, NULL, 0);  // write immediately instead of starting new thread
#else
      //printf("Writing image...\n");

// flip image upside down (to put it back the right way up) if reading from file but emulating the bottom2top ordering
      if (bottom2top)
      {
          //printf("Flipping image read from file...\n");
          for (int y1=0; y1<lenY/2; y1++)
          {
              int y2=lenY-1-y1;  // exchange lines y1 and y2
              //printf("Swapping lines %d and %d...\n", y1, y2);
              for (int x=0; x<lenX; x++)
              {
                  int pixAdr1=x*incX + y1*incY;
                  int pixAdr2=x*incX + y2*incY;
                  unsigned char temp;
                  temp=imageR[pixAdr1]; imageR[pixAdr1] = imageR[pixAdr2]; imageR[pixAdr2]=temp;
                  temp=imageG[pixAdr1]; imageG[pixAdr1] = imageG[pixAdr2]; imageG[pixAdr2]=temp;
                  temp=imageB[pixAdr1]; imageB[pixAdr1] = imageB[pixAdr2]; imageB[pixAdr2]=temp;
              }
          }
      }
  }




      orig_x = in->GetNx();
      orig_y = in->GetNy();

      new_x = orig_x/para.scalefactor;
      new_y = orig_y/para.scalefactor;

      in2 = new o_CPicture<unsigned char>(new_x, new_y,3);

      bbcvp::BilinearInterpolator *bc = new BilinearInterpolator();

      bc->setNewInImage(*in);
      *in2 = bc->resize((double)new_x/orig_x, (double)new_y/orig_y);
     // *picturearray[frame] = *in2;
      cout << "orig x = " << orig_x << endl;


      sprintf(buf, para.o, (frame));
      bbcvp::WriteImage(*in2, buf);

      /*
      sprintf(buf, "seq6/out/outmask/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev4mask, buf);
      sprintf(buf, "seq6/out/outmaskadjusted/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev5mask, buf);
      sprintf(buf, "seq6/out/outmaskadjusted2/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev6mask, buf);
      sprintf(buf, "seq6/out/region/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev7mask, buf);
      /*sprintf(buf, "seq6/out/hueborder/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*greyscaleout3, buf);*/

/*
      *prev2mask = *prev1mask;
      *prev1mask = *inmask;
      *prev2 = *prev1;
      *prev1 = *in;
*/

      //sprintf(buf, para.o, frame);
      //bbcvp::WriteImage(*in, buf);


    /*  int mx=lenX>>motionDiffResolution,my=lenY>>motionDiffResolution;
      o_Picture<unsigned char> mask(mx, my);
      for(int mxi=0;mxi<mx;mxi++)
          for(int myj=0;myj<my;myj++)
                  mask.SetPixel(myCorrespGen->getNonCameraMotion(mxi,myj)*255,mxi,myj);
      bbcvp::WriteImage(mask,buf);*/

      if (para.lineImOut_flag && para.lineFile_flag)  // if using lines and asked to write a diagnostic image...
          {
              sprintf(buf, para.lineImOut, frame);
              bbcvp::WriteImage(*lineDiag, buf);
          }
#endif

      if (para.pointFile_flag)  // if asked to write coords of points to a file.....
        {
          FILE *fp;
          char nameBuff[500];
          sprintf(nameBuff, para.pointFile, frame);
          if ( (fp = fopen(nameBuff, "w")) == NULL)
            {
              printf("Can't open file %s for writing list of observed points\n",nameBuff);
              return(-1);
            }
          else
            {
              /*
              for (int i=0; i<myCorrespGen->getNPatches(); i++)
                {
                  if (myPoseEst->pointWasAnInlier(i))           // only write inliers
                    {
                      double xx, yy;
                      int id = myPoseEst->getPointObservation(i, &xx, &yy);
                      fprintf(fp,"%7i  %6.2f  %6.2f\n", id, xx+sideBorder, yy+topBorder);  // PoseEst object only works on window into picture!!
                    }
                }

              fclose(fp);*/
            }
        }  // if writing observed points to a file

      // Delete the top image from the store according to the decision made earlier
      // (replaces previous code that also did outlier deletion and (disabled) code for new feature creation
 //     if (deleteLastImage)  myPoseEst->clearLastImage();

      if (fieldType != -1) fieldType = 1 - fieldType;  // which field type next time?

      first=false;
      nFieldsProcessed++;

    }  // loop for reading input frames

  cout << "orig x = " << orig_x << endl;

  double first_time = clock();

  sprintf(buf,"-patt %s -start %d -end %d -inc 1", para.o, para.in_pnt, para.out_pnt );
  if (inputSeq.Open( buf )!= o_OK)
    { fprintf(stderr,"Error opening image sequence %s\n",para.i);   exit (-1); }

  for (int frame=para.in_pnt; frame < para.out_pnt-2 && running; frame++)  //actually counts fields if working interlaced
  {
      timeval startTime, endTime;  // for timing various bits
      timespec time0, time1;       // alternative - for use with clock_gettime;
      double loadImageTime=0.0, findCorrespondencesTime=0.0, findLinesTime=0.0, calcSolutionTime=0.0, findNewFeaturesTime=0.0, calcFullSolutionTime=0.0;
      double ignoreNonCamMotionTime=0.0;
      double keyCalcTime=0.0;
      bool useFrameForGlobalSolve = false;  // not using image for global solution yet, as far as we know!
      int nFeaturesInCommon=0;              // (this is only looked at if we're keeping some images for global pose comp, and then it is set later)

#ifdef USING_DVS
      // load a new image unless we're processing f2 of a frame we already have
      if (fieldType != 1 )
        {
          mycard->FIFO_GetFrame(true, mybuf, bufsize, NULL, 0);
          imageR = mybuf +     field1Offset;
          imageG = mybuf + 1 + field1Offset;
          imageB = mybuf + 2 + field1Offset;
          lineDiagnosticImage = mybuf + 2 + field1Offset;  // put diag image from line finder in alpha channel
          droppedFrames = mycard->get_FIFODroppedOutputFrames();
        }
      else  // field 2 is already grabbed, but starts one line lower.....
        {
          imageR = mybuf +     field2Offset;
          imageG = mybuf + 1 + field2Offset;
          imageB = mybuf + 2 + field2Offset;
          lineDiagnosticImage = mybuf + 3 + field2Offset;
        }

      // make data from last field available for free-d output if compiled with this option and enabled:
#ifdef FREED_OUTPUT
      if (fieldType >= 0 && useFreedSender)       // no output if progresive mode (type=-1) or not doing o/p
        {
          if (para.lensFileEmulation == 0 || para.lensFileEmulation == 2)           // mode 0: zoom encoder = 100 * vert fov, mode 2: 300*fov
            {
              double scale = 100;  if (para.lensFileEmulation == 2) scale = 300.0;
            if (sendEndToEnd)
              {
                int zoom=0;
                if (fieldType == 1) zoom=180.0 * scale;           // send 0 on field "0" and 180 degrees on field "1"
                printf("\nEnd-to-ending: sending zoom=%d\n", zoom);
                freedSender->setData(fieldType,           // whether this is for field 0 or 1
                                     -pan+panOffset, tilt, -roll,   // signs changed for openGl-style to freed
                                     camX, camY, camZ,    // was 0.0, 0.0, 0.0 for  pos and height all zero
                                     zoom,                // zoom sent as int representing 100ths of a degree
                                     0,                   // focus set to zero
                                     frame,               // field count: so sender can check it sends in right order
                                     para.freedDelay);    // delay in microseconds
                if (fieldType == 1) sendEndToEnd = false; // stop after field 1 (always starts on field 0)
              }
            else
              freedSender->setData(fieldType,           // whether this is for field 0 or 1
                                   -pan+panOffset, tilt, -roll,   // signs changed for openGl-style to freed
                                   camX, camY, camZ,          // was 0.0, 0.0, 0.0 for  pos and height all zero
                                   (int)(fovy * scale + 0.5), // zoom sent as int representing 100ths of a degree
                                   0,                   // focus set to zero
                                   frame,              // field count: so sender can check it sends in right order
                                   para.freedDelay);    // delay in microseconds
          }
       * else // zoomMode is non-zero: means reciprocal focal length
          {
            if (sendEndToEnd)
              {
                int zoom=0;
                if (fieldType == 1) zoom=maxZoomForZFCOutput;        // send 0 on field "0" and maxZoom on field "1"
                printf("\nEnd-to-ending: sending zoom=%d\n", zoom);
                freedSender->setData(fieldType,           // whether this is for field 0 or 1
                                     -pan+panOffset, tilt, -roll,   // signs changed for openGl-style to freed
                                     camX, camY, camZ,         // was 0.0, 0.0, 0.0 for  pos and height all zero
                                     zoom,                // zoom sent as int representing 100ths of a degree
                                     0,                   // focus set to zero
                                     frame,              // field count: so sender can check it sends in right order
                                     para.freedDelay);    // delay in microseconds
                if (fieldType == 1) sendEndToEnd = false; // stop after field 1 (always starts on field 0)
              }
            else
              {
                // invert calculation that zfc lens data decoding will do:
                // 1/f = k0 + k1*(z-MaxZoom)
                // where z is zoom value sent on serial interface, maxZoom is biggest value seen when end-to-ending,
                // k0 and k1 are the first two coefficients in the zfc file
                // so zoom value to send = (1/f-k0)/k1 + MaxZoom
                //
                double zoomOut = (double)maxZoomForZFCOutput + (1.0 / focalLength - ZFCCoeff0) / ZFCCoeff1;
                freedSender->setData(fieldType,           // whether this is for field 0 or 1
                                     -pan+panOffset, tilt, -roll,   // signs changed for openGl-style to freed
                                     camX, camY, camZ,         // was 0.0, 0.0, 0.0 for  pos and height all zero
                                     (int)(zoomOut + 0.5), // zoom value to send
                                     0,                   // focus set to zero
                                     frame,              // field count: so sender can check it sends in right order
                                     para.freedDelay);    // delay in microseconds
              } // if end-to-ending
          } // if zfc or ecf zoom output mode
        }  // if sending out free-d data

#endif  // if free-d output


      // process any keyboard input if using live video input
      int key;
      int key_was_pressed = false;
      while ( (key=term.readChrOrEscSeq(stdin)) != -1)
        {
          key_was_pressed = true;
          bool posChanged=false;
          switch (key)
            {
                case 'q': running=false; break;              // q=quit
                case 'g': refineGlobally = !refineGlobally ;  printf("Global refinement:  %s\n", refineGlobally? "On" : "Off"); break;
                case 'l': lookForNewPermanentPatches = true; printf("\nLearning patches\n"); break;   // l=look for new patches
                case 's': lookForNewPermanentPatches = false; printf("\nStopped learning patches\n"); break;  // s=stop looking for new patches
                case 'f': lookForNewTemporaryPatches = !lookForNewTemporaryPatches; printf("\nLooking for temp patches:%s\n", lookForNewTemporaryPatches? "On" : "Off"); break;
                case 'd': drawPoints=!drawPoints; break;     // d=toggle drawing points
                case 'm': drawMotionMask=!drawMotionMask; break;     // d=toggle drawing non-camera motion mask
                case ',': motionThresh=motionThresh>5?motionThresh-5:motionThresh;
                                        printf("threshold: %d\n",motionThresh);
                                        break;
                case '.': motionThresh=motionThresh<250?motionThresh+5:motionThresh;
                                        printf("threshold: %d\n",motionThresh);
                                        break;
                case 'b': motionDilateHalfWin=motionDilateHalfWin>1?motionDilateHalfWin-1:motionDilateHalfWin;
                                        break;
                case 'n': motionDilateHalfWin=motionDilateHalfWin<5?motionDilateHalfWin+1:motionDilateHalfWin;
                                        break;
                case 't': doTracking=!doTracking; break;     // t=toggle tracking on/off
                case 'i': doExhaustiveSearch = true; break;  // i=initialise by doing an exhaustive search
                case 'w': weightUsingMatchErr = !weightUsingMatchErr; printf("\nweightUsingMatchErr: %s\n", weightUsingMatchErr ? "On" : "Off"); break;
                case 'r': rescalePatches =!rescalePatches; printf("\nrescalePatches:%s\n",rescalePatches ? "On" : "Off"); break;
                case 'o': doVideoOutput =!doVideoOutput; printf("\ndoVideoOutput:%s\n",doVideoOutput ? "On" : "Off"); break;
                case 'e': sendEndToEndOnNextFieldZero = true; break;
                case '1': printf("Reading patches from file %s...\n", para.patchFileIO1); myCorrespGen->readPatches(para.patchFileIO1); break;
                case '2': printf("Reading patches from file %s...\n", para.patchFileIO2); myCorrespGen->readPatches(para.patchFileIO2); break;
                case '3': printf("Reading patches from file %s...\n", para.patchFileIO3); myCorrespGen->readPatches(para.patchFileIO3); break;
                case '4': printf("Reading patches from file %s...\n", para.patchFileIO4); myCorrespGen->readPatches(para.patchFileIO4); break;
                case '!': printf("Writing patches to file %s...\n",   para.patchFileIO1); myCorrespGen->writePatches(para.patchFileIO1); break;
                case '"': printf("Writing patches to file %s...\n",   para.patchFileIO2); myCorrespGen->writePatches(para.patchFileIO2); break;
                case '£': printf("Writing patches to file %s...\n",   para.patchFileIO3); myCorrespGen->writePatches(para.patchFileIO3); break;
                case '$': printf("Writing patches to file %s...\n",   para.patchFileIO4); myCorrespGen->writePatches(para.patchFileIO4); break;
                case 'x':   interactiveAdjustAxis=0; break;
                case 'y':   interactiveAdjustAxis=1; break;
                case 'z':   interactiveAdjustAxis=2; break;
                case 'p':   interactiveAdjustAxis=3; break;
                case '{': if (interactiveAdjustAxis==0) camX+=1.0; else if (interactiveAdjustAxis==1) camY+=1.0; else if (interactiveAdjustAxis==2) camZ+=1.0; else if (interactiveAdjustAxis==3) panOffset+=10.0; posChanged=true; break;
                case '}': if (interactiveAdjustAxis==0) camX-=1.0; else if (interactiveAdjustAxis==1) camY-=1.0; else if (interactiveAdjustAxis==2) camZ-=1.0; else if (interactiveAdjustAxis==3) panOffset-=10.0; posChanged=true; break;
                case '[': if (interactiveAdjustAxis==0) camX+=0.1; else if (interactiveAdjustAxis==1) camY+=0.1; else if (interactiveAdjustAxis==2) camZ+=0.1; else if (interactiveAdjustAxis==3) panOffset+=2.0; posChanged=true; break;
                case ']': if (interactiveAdjustAxis==0) camX-=0.1; else if (interactiveAdjustAxis==1) camY-=0.1; else if (interactiveAdjustAxis==2) camZ-=0.1;  else if (interactiveAdjustAxis==3) panOffset-=2.0;posChanged=true; break;
                case '-': if (interactiveAdjustAxis==0) camX+=0.01; else if (interactiveAdjustAxis==1) camY+=0.01; else if (interactiveAdjustAxis==2) camZ+=0.01; else if (interactiveAdjustAxis==3) panOffset+=0.1; posChanged=true; break;
                case '=': if (interactiveAdjustAxis==0) camX-=0.01; else if (interactiveAdjustAxis==1) camY-=0.01; else if (interactiveAdjustAxis==2) camZ-=0.01; else if (interactiveAdjustAxis==3) panOffset-=0.1; posChanged=true; break;

                if (posChanged) printf("\n-initPanOffset %7.3f -initX %7.3f -initY %7.3f -initZ %7.3f\n", panOffset, camX, camY, camZ);

            }  // end of switch
        }  // end of while loop reading keypresses

      // only start end-to-ending on a field 0 (as min & max are sent on fields 0 and 1)
      // (next field to output will be 0 if current field is 1, as output happens before this point)
      if (sendEndToEndOnNextFieldZero && fieldType == 1)
        {
          sendEndToEndOnNextFieldZero = false;
          sendEndToEnd = true;
        }

#else  // if not using DVS but reading from file.....


       if (inputSeq.LoadNextPicture()!= o_OK)
        { fprintf(stderr,"Error reading fg image\n");   exit (-1); }

      cout << " I bet it breaks now" << endl;

      //printf("Calling getPicture...\n");
      *in = inputSeq.GetPicture();

      cout << " see?" << endl;

#endif
      if (frame - para.in_pnt == 0)  // initialise everything that needs to know image dimensions (as we couldn't do this earlier)
        {

          cout << " see 1?" << endl;

    ///////////////////////////ORIGINAL SIZES///////////////////////////
    prev1 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    prev2 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    prev3mask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    prev1mask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    heap = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    blurredmask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);

    //////////////////STANDARD DEFINITION SIZES//////////////////////////////

    prev2mask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    prev4mask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    prev5mask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    prev6mask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    huemask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    prev7mask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    greyscaleout3 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    inmask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    inmaskreverse = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    prev2map = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    huemap = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    divermap = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemask2 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemask3 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemask4 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemask5 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemask6 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemask7 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemask8 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemap = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsehue = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsehuefirst = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    xmarksthearse = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    hueverywide = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    houghness = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    arsemaskdiff = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemaskdiff2 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    arsemaskdiff3 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    greyscaleout8 = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    gaussianed = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    gauss = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    boardmask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    resizedmask = new o_CPicture<unsigned char>(orig_x, orig_y,1);
    resizeddiff = new o_CPicture<unsigned char>(orig_x, orig_y,1);
    boxblur = new o_CPicture<unsigned char>(orig_x, orig_y,1);
    kneemask = new o_CPicture<unsigned char>(orig_x, orig_y,1);
    shouldermask = new o_CPicture<unsigned char>(orig_x, orig_y,1);
    footmask = new o_CPicture<unsigned char>(orig_x, orig_y,1);
    kneemap = new o_CPicture<unsigned char>(orig_x, orig_y,1);
    shouldermap = new o_CPicture<unsigned char>(orig_x, orig_y,1);
    footmap = new o_CPicture<unsigned char>(orig_x, orig_y,1);

        //++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    //Initialise images.
    capturedImage = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
    capturedImageMask = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
    //++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

    *prev1 = *in;
    *prev2 = *in;

    cout << " see 2?" << endl;

         for(int i=0; i<200;i++)
         {

      //   pictureinputarray[i] = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
         pictureoutputarray[i] = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),3);
      //   picturemaskarray[i] = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);
         blurredpicturemaskarray[i] = new o_CPicture<unsigned char>(in->GetNx(), in->GetNy(),1);

         }

#ifndef USING_DVS
          printf("dims are %dx%d with %d components\n",in->GetNx(), in->GetNy(), in->GetNz());

          if (in->GetNz() != 3) { printf("An RGB image is needed!!!!\n"); exit(-1); }

          // all coordinates, searching/writing test output, etc. is w.r.t. imageR/G/B and the lengths here....
          lenX = in->GetNx() - 2*sideBorder;
          lenY = in->GetNy() - topBorder - bottomBorder;
          lenYFullFrameField = in->GetNy();
          incX = in->GetElementPtr(1,0,0) - in->GetElementPtr(0,0,0);
          incY = in->GetElementPtr(0,1,0) - in->GetElementPtr(0,0,0);
          imageR = in->GetElementPtr(0,0,0) + sideBorder*incX + topBorder*incY;
          imageG = in->GetElementPtr(0,0,1) + sideBorder*incX + topBorder*incY;
          imageB = in->GetElementPtr(0,0,2) + sideBorder*incX + topBorder*incY;
#endif  // if not using DVS

          // 10-Apr-09: GAT: is there a bug below if we are processing progressive images, ie if ylen=576, won't aspect ratio be wrong?
          if ( para.aspect == 0 ) {
/**/        printf( "< Video Aspect 16:9\n" );
            aspect =  (16.0 * (double)lenX / 702.0) / (9.0 * (double)lenY / 288.0);  // aspect ratio of part of image used (702x288 will have aspect= 16/9)
          } else {
/**/        printf( "< Video Aspect 4:3\n" );
            aspect =  (4.0 * (double)lenX / 702.0) / (3.0 * (double)lenY / 288.0);  // aspect ratio of part of image used (702x288 will have aspect= 16/9)
          }

          int fullLenY = lenY;
          if ( fieldType!=-1)  fullLenY = lenY * 2;  // value passed to PoseEstPanTiltHead constructor must be frame size even if interlaced

          printf("Building PoseEstPanTiltHead with lenX=%d  lenY=%d  aspect=%6.2f...\n", lenX, fullLenY, aspect);
          myPoseEst = new PoseEstPanTiltHead(maxRefWorldLines,  // max number of lines on reference objects
                                             maxCameras,        // max number of images used to calibrate a camera position
                                             maxPoints+maxRefParallelLines+1,  // maxObjects = max patches we'll find, plus max parallel ref lines plus one for points in the fixed ref frame
                                             lenX, fullLenY, aspect,  // image dims and full aspect ratio
                                             maxPointsPerLine,        // allocate storage for this number of points on each line (usually 2 unless using all points)
                                             1,  // max positions - we only consider one camera location
                                             maxRefWorldPoints,      // max points on a reference object: determined by the max 'fixed' world points we'll have
                                             maxRefParallelLines+1);  // max number of reference objects (that can have lines on them) = 1 plus any lines with part-unknown coords

          myPoseEst->setVerbosity(para.verbose);

          myPoseEst->setTerminationConditions( 0.1,              // rmsLimit: Stop iterating when rms error changes by less than this (default in PoseEstimator is 0.001)
                                               para.maxIterPose, // The maximum number of iterations to perform (usually set to 100 within PoseEstimator;
                                               0.01,             // mLimit: The smallest length of the update vector allowed before iterations are stopped. (PoseEstimator default is 0.01)
                                               0.0);             // MaxRmsErrorIncrease (The max increase in RMS error allowed before solution vector is scaled down) default to 0.0
          myPoseEst->setDownweightOutlierFract(para.downweightOutlierFract);
          
          
    //++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    destinationPose = new posProject(myPoseEst);
    startPose = new posProject(maxRefWorldLines,  // max number of lines on reference objects
                       maxCameras,        // max number of images used to calibrate a camera position
                       maxPoints+maxRefParallelLines+1,  // maxObjects = max patches we'll find, plus max parallel ref lines plus one for points in the fixed ref frame
                       lenX, (lenY*2), aspect,  // image dims and full aspect ratio
                       2,  // pointsperline
                       1,  // max positions - we only consider one camera location
                       maxRefWorldPoints,      // max points on a reference object: determined by the max 'fixed' world points we'll have
                       maxRefParallelLines+1,  // max number of reference objects (that can have lines on them) = 1 plus any lines with part-unknown coords
                       fieldType, bottom2top, notionalPixHeight);
    //++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

          printf("Building PatchCorrespondenceGen...\n");
          myCorrespGen=new PatchCorrespondenceGen(myPoseEst,
                                                  patchLenX, patchLenY,
                                                  lenX, lenY,
                                                  spacingX, spacingY, nResolutions,
                                                  maxPatches, para.maxPatchesPerRegion,
                                                  maxRefWorldLines,  // this arg = number of lines to allow storage space for when checking prjected lines
                                                  forestSize, maxdepth, threshold, degree, motionDiffResolution);

          myCorrespGen->setFeatureDetectionWindowHalfWid(para.halfWidX, para.halfWidY);
          myCorrespGen->setFeatureFindSubsample(para.ssx, para.ssy);
          myCorrespGen->setFeatureDetectionIgnoreRegion(para.minIgnoreX, para.maxIgnoreX, para.minIgnoreY, para.maxIgnoreY);
          myCorrespGen->setKLTAccuracy(para.KLTAccuracy);
          myCorrespGen->setCostOfEigenvalueDiff(para.costOfEigenvalueDiff);
          myCorrespGen->setmaxIter(para.maxIterKLT);
          myCorrespGen->setIgnoreFeatureLines(para.minDistFromLine);
          myCorrespGen->setVelocityRangeForNoRelearning(para.relearnVelX, para.relearnVelY);
          myCorrespGen->setMaxPatchesToSearchPerRegion(para.maxPatchesToSearchPerRegion);
          myCorrespGen->setPatchPrefWeights(para.patchPrefVelWeight, para.patchPrefFoclenWeight);
          myCorrespGen->setFeatureFindLevel(para.featureFindLevel);
          myCorrespGen->setUseMotionMaskAsIgnoreRegion(ignoreNonCamMotion);
          myCorrespGen->setMaxFractionToDiscardUsingMotionMask(para.maxFractionToDiscardUsingMotionMask);

          // test triangle strip ignore region
#ifdef TEST_TRISTRIP_IGNORE
	  double triStrip1[12] = {0, 0, 0,    70, 0, 0,     0, 0, 7.32,    70, 0, 7.32 } ;  // x,y,z vertices in tri strip
	  double triStrip2[12] = {0, 0, 7.32,  60, 0, 7.32, 0, 0, 2000};  // test having one point behind camera - it should not use this triangle
	  double *triPoints[2] = {triStrip1, triStrip2};  // storage for up to 5 pointers to tri strips
	  int nTriPoints[2] = {4, 3 };
	  myCorrespGen->setIgnoreTriStrips(2, nTriPoints, triPoints); //, false);  // false at end to test using points within triangle
#endif

#ifdef TRACK_TRISTRIP_IGNORE
	  double triStrip1[21] = {0, 0, -0.5,    40, 0, -0.5,     0, 0, 11.5,    40, 0, 11.5,   100, 0, 11.5,   40,0,-0.5,   100,0,-0.5 } ;  // x,y,z vertices in tri strip
	  double *triPoints[1] = {triStrip1};  // storage for up to 5 pointers to tri strips
	  int nTriPoints[1] = {7};
	  myCorrespGen->setIgnoreTriStrips(1, nTriPoints, triPoints); //, false);  // false at end to test using points within triangle
#endif	



	  // test triangle strip region to specify a key colour
#ifdef TEST_TRISTRIP_KEY
          //double triStrip1[12] = {2.0, 0, -1.0,    2.0, 0, 1.0,     4.0, 0, -1.0,    4.0, 0, 1.0 } ;  // triangles to cover 2-4m into pit, within 40cm of edges
          double triStrip1[12] = {2.0, 0, -1.0,    2.0, 0, 1.0,     8.0, 0, -1.0,    8.0, 0, 1.0 } ;  // triangles to cover 2-4m into pit, within 40cm of edges
          double *triPoints[1] = {triStrip1};  // just one triangle strip (but can do multiple if needed)
          int nTriPoints[1] = {4};             // 4 points in the triangle strip
          myPoseEst->setChromaKeyerTriStrips(1, nTriPoints, triPoints);
#endif
          // ------------- set up camera to some initial pose/FOV -----------------------

          // first, need to add (and delete) an image, as we need to tell PoseEstPanTiltHead the pixel size in order
          // to use the set field-of-view methods
          myPoseEst->addNewImage(fieldType, bottom2top, notionalPixHeight);

        //  cout << "myPoseEst " << myPoseEst->addNewImage(fieldType, bottom2top, notionalPixHeight) << endl;

          myPoseEst->clearLastImage();

          // TESTING: set initial values as obtained from manual 2D-3D correspondences
          //printf("Setting initial PTR to values like those from 2D-3D corresps\n");
          //camPan=-2.001; camTilt=0.321; camRoll=0.032;

          printf("Setting cam vert FOV to %6.2f corresponding to %d lines\n", camFOV, lenYFullFrameField);
          myPoseEst->setCamPos(camX, camY, camZ);
          myPoseEst->setCamRotPTR(camPan, camTilt, camRoll);
          myPoseEst->setCamFOV(camFOV, lenYFullFrameField);  // specify full height in field lines if interlaced, as PoseEStPanTiltHead uses ylen & YP for a field internally
          myPoseEst->rollPitchNotCamera(para.rollCam == 0);  // must allow roll if pan axis not necessarily aligned with initial y
          myPoseEst->adjustCamPos(false);
          myPoseEst->adjustCentre(false);
          myPoseEst->adjustDistortion(false);
          myPoseEst->setPitchRot(para.initRX, para.initRY, para.initRZ);  // may want to specify this to reproduce starting pose as setermioend from a prev calib
          myPoseEst->setPlausibleFOVRange(para.maxFovY, para.minFovY);
          myPoseEst->setPlausibleRollRange(-para.rollRange, para.rollRange);  // roll range is given amount centred on zero - constrains things RANSAC will try
          myPoseEst->setNCoeffDistortionFromFoclen(para.nCoeffFD);
          myPoseEst->getCoeffFD()[0] = para.coeffFD0;
          myPoseEst->getCoeffFD()[1] = para.coeffFD1;
          myPoseEst->getCoeffFD()[2] = para.coeffFD2;
          
          

	  printf("Setting cam vert FOV to %6.2f corresponding to %d lines\n", camFOV, lenYFullFrameField);
	  myPoseEst->setCamPos(camX, camY, camZ);
	  myPoseEst->setCamRotPTR(camPan, camTilt, camRoll);
     printf("Pan3: %f %f\n", camPan, camTilt);
	  myPoseEst->setCamFOV(camFOV, lenYFullFrameField);  // specify full height in field lines if interlaced, as PoseEStPanTiltHead uses ylen & YP for a field internally
	  myPoseEst->rollPitchNotCamera(para.rollCam == 0);  // must allow roll if pan axis not necessarily aligned with initial y
	  myPoseEst->adjustCamPos(false);
	  myPoseEst->adjustCentre(false);
	  myPoseEst->adjustDistortion(false);
	  myPoseEst->setPitchRot(para.initRX, para.initRY, para.initRZ);  // may want to specify this to reproduce starting pose as setermioend from a prev calib
	  myPoseEst->setPlausibleFOVRange(para.maxFovY, para.minFovY);
	  myPoseEst->setPlausibleRollRange(-para.rollRange, para.rollRange);  // roll range is given amount centred on zero - constrains things RANSAC will try
	  myPoseEst->setNCoeffDistortionFromFoclen(para.nCoeffFD);
	  myPoseEst->getCoeffFD()[0] = para.coeffFD0;
	  myPoseEst->getCoeffFD()[1] = para.coeffFD1;
	  myPoseEst->getCoeffFD()[2] = para.coeffFD2;

          // if a filename was given for distortion polynomial data read it in, over-writing any command-lines values just set
          if (para.distFileIn_flag)
            if (myPoseEst->readDistortionPolynomial(para.distFileIn))
              printf("Read distortion polynomial from %s\n", para.distFileIn);
            else
              printf("Error reading distortion polynomial from %s\n", para.distFileIn);

          if(para.lineFile_flag)
          {
              PitchModel *myPitch = new PitchModelFile(para.lineFile);
              usingLines = true;
              list<LineFeature3D> pitch = myPitch->getPitch();
              // add all the pitch lines to the estimator
              list<LineFeature3D>::iterator it;
              for ( it = pitch.begin(); it != pitch.end(); it++ )
              {
                  printf("Adding line:  (%6.2f,%6.2f,%6.2f) to (%6.2f,%6.2f,%6.2f)\n",
                         it->getStartPointX(), it->getStartPointY(), it->getStartPointZ(),
                         it->getEndPointX(),   it->getEndPointY(),   it->getEndPointZ());
                  int lineIndex = myPoseEst->addLine(
                                                    it->getStartPointX(), it->getStartPointY(), it->getStartPointZ(),
                                                    it->getEndPointX(),   it->getEndPointY(),   it->getEndPointZ());
                  if (lineIndex < 0) { printf("Exceeded storage space for lines when adding a reference line - try incresing maxRefWorldLines!\n"); exit(-1); }
              }
              nLinesToTrack = myPitch->getNumberOfPitchLines();
              delete myPitch;

              // Create & set up an InitialPoseEstLines object
              myInitialPoseEstLines = new InitialPoseEstLines(myPoseEst, lenX, lenY);

              myInitialPoseEstLines->setSubsamplingFactors(para.lineSubsampleX, para.lineSubsampleY);        // any subsampling
              myInitialPoseEstLines->setVerbosity(0);                    // normally 0, set to 2 to get printout of weights for each tested pose

              // set parameters used in line finding and pose cpomputation (these are common to those used in main processing)
              myInitialPoseEstLines->setLineThresholds(para.pitchThresh, para.lineThreshZeroWeight, para.lineThreshFullWeight, para.lineThreshMotionBlurFactor);
              //myInitialPoseEstLines->setPixelAngleTolerance(1.0, 0.0);   //m_angleToleranceZeroWeight, m_angleToleranceFullWeight);
              myInitialPoseEstLines->setPixelAngleTolerance(2.0, 1.0);   //this should prevent any downweighting due to local line angle not matching expected line angle - can't reliably do angle when subsampling
              myInitialPoseEstLines->setSearchRange(10,                  //m_lineSearchRangeX/INIT_SUBSAMPLE_X/MAIN_SUBSAMPLE_X,
                                                    10,                  //m_lineSearchRangeY/INIT_SUBSAMPLE_Y/MAIN_SUBSAMPLE_Y,
                                                    3.0,                //m_outlier);
                                                    para.lineSearchRangeMotionBlurFactor);
              myInitialPoseEstLines->setLineWeights(0.0, 1.0,            //m_fractionPointsZeroWeight, m_fractionPointsFullWeight,
                                                    0,                   //m_nPointsZeroWeight/MIN(INIT_SUBSAMPLE_X*MAIN_SUBSAMPLE_X,INIT_SUBSAMPLE_Y*MAIN_SUBSAMPLE_Y),
                                                    1,                   //m_nPointsFullWeight/MIN(INIT_SUBSAMPLE_X*MAIN_SUBSAMPLE_X,INIT_SUBSAMPLE_Y*MAIN_SUBSAMPLE_Y),
                                                    0.98, 1.0);          //m_lineDotProdZeroWeight, m_lineDotProdFullWeight;
              myInitialPoseEstLines->setLineSize(para.lineWidth, 0.95,              //m_pitchLineWidth (0.2 in DefaultValuesv2.0, 0.15 for rugby, m_linescale;
                                                 para.lineWidthMotionBlurFactor);

              myInitialPoseEstLines->setRGBWeights(para.lineWeightR, para.lineWeightG, para.lineWeightB); // for making lines stand out - pick colour opposite to track
              myInitialPoseEstLines->setImageBorder(para.lineBorderX, para.lineBorderY);

              // create and setup a ChromaKeyer, which is needed by the linefinder:
              try
              {
                  cout << "- Creating ChromaKeyer: ";
                  mykeyer = new ChromaKeyer();
                  cout << "done" << endl;
                  mykeyer->enableChromaKey(true);
                  cout << "    chromakey: ON" << endl;
                  cout << "    key inverted: NO" << endl;
                  mykeyer->setChromaKey(KeyerParams(para.hue, para.acceptance,
                                                    para.minSaturation, para.maxSaturation,
                                                    50, 194,             // para.minLuminance, para.maxLuminance (from PieroLite DefaultSettingsv2.0)
                                                    1, true));       //m_severity, m_softness (from PieroLite DefaultSettingsv2.0)
              }
              catch (exception &e)
              {
                  cerr << "\nException thrown when creating ChromaKeyer: " << e.what() << endl;
                  exit(-1);
              }

              // storage for working arrays
#ifndef USING_DVS
              // line diagnostic image goes in a separate pictrue when using file-bsed I/O
              // (it's in the alpha channel of the DVS card if using DVS for I/O)
              lineDiag = new o_CPicture<unsigned char>( in->GetNx(), in->GetNy(), 3 );  // create an image of same size & packing as input image, for line finder diagnostics
              lineDiagnosticImage = lineDiag->GetElementPtr(0,0,0) + sideBorder*incX + topBorder*incY;
#endif
              hGrad = new unsigned char[lenX*lenY];
              vGrad = new unsigned char[lenX*lenY];
          }

          // read stored patches if file name given.  NB do this after setting cam position, because readPatches calls PoseEstPanTiltHead->addPoint,
          // which initialises each object's reference frame to match that of the reference object, which is set to minus the cam pos
          // byt the setCamPos method.
          if (para.patchFileIn_flag)
          {
              printf("Reading patches from file %s...\n", para.patchFileIn);
              myCorrespGen->readPatches(para.patchFileIn);
          }

          printf("frame drp tot  foun in%% rmserr    pan     tilt    roll    fovy  np  nt\n");

          if (logFile != (FILE*)NULL)
            fprintf(logFile, "frame ,Tpnt,Vpnt,Vlines,lineWt ,inliPt ,inliLn ,rmserr   ,pan     ,tilt    ,roll    ,fovy  ,xpos    ,ypos    ,zpos    ,np  ,nt ,loadIm,findPt,findLn,calcSo,fndNew\n");
        }

cout << " see 3?" << endl;

#ifndef USING_DVS
// flip image upside down if reading from file but emulating the bottom2top ordering
      if (bottom2top)
      {
          //printf("Flipping image read from file...\n");
          for (int y1=0; y1<lenY/2; y1++)
          {
              int y2=lenY-1-y1;  // exchange lines y1 and y2
              //printf("Swapping lines %d and %d...\n", y1, y2);
              for (int x=0; x<lenX; x++)
              {
                  int pixAdr1=x*incX + y1*incY;
                  int pixAdr2=x*incX + y2*incY;
                  unsigned char temp;
                  temp=imageR[pixAdr1]; imageR[pixAdr1] = imageR[pixAdr2]; imageR[pixAdr2]=temp;
                  temp=imageG[pixAdr1]; imageG[pixAdr1] = imageG[pixAdr2]; imageG[pixAdr2]=temp;
                  temp=imageB[pixAdr1]; imageB[pixAdr1] = imageB[pixAdr2]; imageB[pixAdr2]=temp;
              }
          }
      }

      cout << " see 4?" << endl;

      cout << "fieldType  " << fieldType << endl;
      cout << "bottom2top  " << bottom2top << endl;
      cout << "notionalPixHeight  " << notionalPixHeight << endl;

   //   cout << !myPoseEst->addNewImage(fieldType, bottom2top, notionalPixHeight) << endl;

#endif

      if (para.verbose) printf("calling addNewImage...\n");

       cout << " see 4a?" << endl;

      // create new data set to receive correspondences; will have pose as previously set.
      // Not bottom2top more; specify vert pix height as we want to use focal length in zfc free-d output
      if (!myPoseEst->addNewImage(fieldType, bottom2top, notionalPixHeight))
        printf("Run out of space for storing images: just overwrote top one stored!!\n");

   //   cout << " see 4a?" << endl;

      // ----------- process image --------------------
      gettimeofday(&startTime, 0);
      // the call below should give time for this process, but (a) I get an "undefined" error when linking, and (b) the man page
      // says it may give bogus answers on multi-processor systems if the process moves between CPUs, so stick to the
      // elapsed time measure for now, even if it sometimes gives values that look too high
      //clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &time0);
      if (para.verbose) printf("calling loadimage...\n");
      myCorrespGen->loadImage(imageR, imageG, imageB,
                              incX, incY, weightR, weightG, weightB);
      gettimeofday(&endTime, 0);
      cout << " see 4b?" << endl;
      //clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &time1);
      loadImageTime = ( (endTime.tv_sec - startTime.tv_sec) + (endTime.tv_usec - startTime.tv_usec) / 1000000.0);

      //loadImageTime = ( (time1.tv_sec - time0.tv_sec) + (time1.tv_nsec - time0.tv_nsec) / 1000000000.0);

      double rmsErr = -1;
      int nFinalPoints = 0;
      int nFinalLines = 0;
      int nPointsFound = 0;
      int nLinesFound = 0;
      double totalLineWeightUsed = 0.0;

      // (used to delete old patches befor search, but now delete them just before looking for new ones, so that
      // delted ones can be replaced immediately if needed)

      cout << " see 5?" << endl;


      // look for features & estimate pose, either exhaustively or using previous pose as a starting point
      if (doExhaustiveSearch)
      {
          int tempPatchesDeleted = myCorrespGen->deleteOldPatches(para.lifeTime + frame + 1);  // +1 to be on the safe side!
          printf("Deleted all %d temp patches and starting exhaustive search.....\n", tempPatchesDeleted);
          double result = myCorrespGen-> exhaustiveSearch(para.pMin, para.pMax, para.pStepPixels,
                                                          para.tMin, para.tMax, para.tStepPixels,
                                                          para.rMin, para.rMax, para.rNStep,
                                                          para.fMin, para.fMax, para.fStepPixels,
                                                          para.maxInlierDist,
                                                          para.minInlierFraction,
                                                          para.maxTries,
                                                          para.nInitialPoints, lenYFullFrameField);
          doExhaustiveSearch=false;
      }
      else
      {
          double cx, cy, cz;
          myPoseEst->getCamPos(&cx, &cy, &cz);
          //printf("About to look for correspondencies: cam pos=%6.2f,%6.2f,%6.2f\n", cx, cy, cz);

          if (para.verbose) printf("calling findCorrespondencies...\n");
          gettimeofday(&startTime, 0);
          nPointsFound = myCorrespGen->findCorrespondences(weightUsingMatchErr ? para.matchThresh : 99999,
                                                           para.usePrevIm,
                                                           para.useStoredPatches, para.stopIfWeightDrops, para.normaliseDC,
                                                           para.highestLevelStoredPatches,
                                                           para.lowestLevelStoredPatches,
                                                           para.lowestLevelPrevPatches,
                                                           para.maxDiscardFraction,
                                                           para.discardRadius,
                                                           rescalePatches ? para.rescaleChange: 9999999.0,
                                                           para.maxWeight,
                                                           para.useWeights,
                                                           para.pointWeightScale);

          gettimeofday(&endTime, 0);
          if (para.verbose) printf("finished findCorrespondencies\n");
          findCorrespondencesTime = ( (endTime.tv_sec - startTime.tv_sec) + (endTime.tv_usec - startTime.tv_usec) / 1000000.0);
          // if we're looking for lines too, then look for 'line-like' pixels in the predicted line positions and add them to the PoseEstPanTiltHead object
          // (NB don't do this for the first image we process, as we may be adding manual lines too and want to use lines
          // to do a rough estimate of the pose
          if (usingLines && !para.linesOnlyForSavedImages && !first)  // (but don't use lines if we're only added them in 'saved' frames - we do that later, afer the pose computation, so that they aren't used for frame-to-frame tracking)
          {
              // clear lineDiagnosticImage if you're going to look at it rather than just use it as working storage
              if (para.lineImOut_flag)
                  for (int yy=0; yy<lenY; yy++)
                  {
                      unsigned char *lineDiagnosticImageLine = lineDiagnosticImage + yy * incY;
                      for (int xx=0; xx<lenX; xx++)
                          for (int cc=0; cc<incX; cc++) lineDiagnosticImageLine[xx*incX+cc] = 0;
                  }

              // set line-finding parameters here: previously we set them right at the start but now we allow them to be
              // adapted to the estimated image velocity
              double curVelX, curVelY;
              myPoseEst->getCurrentImageVelocity(&curVelX, &curVelY);

              if (para.verbose) printf("calling addLinesFromImageUsingEstimatedPose...\n");
              gettimeofday(&startTime, 0);
              totalLineWeightUsed =
                  myInitialPoseEstLines->addLinesFromImageUsingEstimatedPose(imageR, imageG, imageB,      // input image
                                                                             lineDiagnosticImage,         // output for edge or key
                                                                             incX, incY,        // NB these are common for inuput RGB and output diagnostic
                                                                             mykeyer, hGrad, vGrad,
                                                                             &nLinesFound,
                                                                             nLinesToTrack,  // only use nLinesToTrack lines, which are the number in the model, excluding any manually-added calibration lines
                                                                             para.lineWeightScale,
                                                                             curVelX, curVelY,  // give it the image velocity in case we're compensaing for blur
                                                                             para.useAllLinePoints,
                                                                             para.subsampleFactorAlongLine);
              gettimeofday(&endTime, 0);
              if (para.verbose) printf("finished addLinesFromImageUsingEstimatedPose\n");
              findLinesTime = ( (endTime.tv_sec - startTime.tv_sec) + (endTime.tv_usec - startTime.tv_usec) / 1000000.0);
              // (NB this starts by calling myPoseEstPanTiltHead->clearAllLines() but that's OK as any manually-specified line observations for
              // calibration lines happen later)
              //printf(" Total weight from %d detected lines = %f\n", nLinesFound, totalLineWeightUsed);
          }

          //printf("Found %d correspondencies\n", nPointsFound);

          //printf("Point data:\n");
          //myPoseEst->printObservationData();

          cout << " see 6?" << endl;

          // Update pose using correspondences found
          //printf("Calculating camera pose...\n");
          if (doTracking)  // for testing, can disable tracking to see how correspondence finding manages with last pose
            {
                if (para.verbose) printf("calling calcSolution...\n");
              gettimeofday(&startTime, 0);
              if (para.errFiltFactor > 0.0)
                {
                  rmsErr=myPoseEst->calcLastSolutionWith2DCorrectionvectors(frame, // current timestamp
                                                                            para.maxResidErrAge,
                                                                            para.errFiltFactor,
                                                                            para.ransac,  // whether we're RANSACing
                                                                            para.maxInlierDist,
                                                                            para.minInlierFraction,
                                                                            para.maxTries,
                                                                            para.nInitialPoints,
                                                                            &nFinalPoints);
                  if (!para.ransac) { nFinalPoints = nPointsFound;  nFinalLines = nLinesFound; }  // all points & lines used if not ransac
                }  // if doing resid err filter
              else
                {
                  if (para.ransac)
                    {
                      //printf("Points data before calling calcLastSolutionRansac:\n");
                      //myPoseEst->printObservationData();
                      //printf("Calling calcLastSolutionRansac...\n");
                      rmsErr=myPoseEst->calcLastSolutionRansac(para.maxInlierDist,
                                                               para.minInlierFraction,
                                                               para.maxTries,
                                                               para.nInitialPoints,
                                                               &nFinalPoints,
                                                               para.nInitialLines,
                                                               &nFinalLines,
                                                               para.inlierDistLineScale);

                      // optionally do one or more additional tries, using just one guess equal to the previous inlier/outlise decision,
                      // to let things settle down
                      // (relies on setUseLastResultAsInlierGuess having been set true, or never called)
                      for (int i=0; i<para.ransacRepeat; i++)
                        {
                          if (i == para.ransacRepeat-1 && para.fovFilterFactor > 0)  // if on last repeat and applying a recursive temporal filter to the focal length......
                            {
                              double curFOV;
                              double predictedFOV=prevFOV;
                              if (para.fovFilterPredMode == 1) predictedFOV = 2.0*prevFOV-prevButOneFOV;  // pred mode 1 is linear extrap
                              myPoseEst->getCamFOV(&curFOV);
                              double fovChangeRatio = fabs(curFOV / predictedFOV - 1.0);
                              if ( fovChangeRatio < para.fovFilterRange)  // if not changed so much that filter has turned itself off...
                                {
                                  double filterFactor = para.fovFilterFactor * (0.5 + 0.5 * cos(3.14159*fovChangeRatio/para.fovFilterRange));
                                  double filteredFOV = filterFactor * predictedFOV + (1.0-filterFactor) * curFOV;
                                  myPoseEst->setCamFOV(filteredFOV);
                                  myPoseEst->adjustFoclen(false);  // force filtered value to be used
                                  //printf("Applying recursive filter to fov: factor=%6.2f fov before=%6.2f  after=%6.2f\n", filterFactor, curFOV, filteredFOV);
                                }
                            }

	      double curPan, curTilt, curRoll;
	      myPoseEst->getCamRotPTR(&curPan, &curTilt, &curRoll);
   //      printf("Pan4: %f %f\n", curPan, curTilt);
	      double rollChange = fabs(curRoll - prevRoll);
	      if ( rollChange < para.rollFilterRange)  // if not changed so much that filter has turned itself off...
		{
		  double filterFactor = para.rollFilterFactor * (0.5 + 0.5 * cos(3.14159*rollChange/para.rollFilterRange));
		  double filteredRoll = filterFactor * prevRoll + (1.0-filterFactor) * curRoll;
		  myPoseEst->setCamRotPTR(curPan, curTilt, filteredRoll);
    //     printf("Pan5: %f %f\n", curPan, curTilt);
      }

                          if (i == para.ransacRepeat-1 && para.fovFilterFactor > 0)
                            {
                              prevButOneFOV=prevFOV;           // update prevButOneFOV for use on next image
                              myPoseEst->getCamFOV(&prevFOV);  // update prevFOV for use on next image
                              myPoseEst->adjustFoclen(true);   // re-enable focal length computation for subsequent calls
                            }

                        }

                      //printf(" ransac used %d points (fraction=%4.2f)...", nFinalPoints, (float)nFinalPoints/(float)nPointsFound);
                    }
                  else
                    {
                      rmsErr = myPoseEst->calcLastSolution();
                      nFinalPoints = nPointsFound;
                      nFinalLines = nLinesFound;
                    }
                }  // no resid err filter



              // optionall apply a post-filter to roll
              // NB would ideally like to apply this in the same way as we do for FOV, so that it is forced to pick a set of values for pan & tilt that are
              // consistent with the filtered roll value, but as PoseEstPantiltHead works internally with OpenGL angles, and the only guaranteed relationship
              // between z and roll is that of one is zero then so is the other, we cannot do a solve with roll constrained to anything other than zero.
              // Thus we apply a post-filter.  TODO: put an option in the RANSAC solve method to limit the allowable range of roll values, e.g. to be within a small
              // range around zero, or even a smaller range around the previous roll value.

              double curPan, curTilt, curRoll;
              myPoseEst->getCamRotPTR(&curPan, &curTilt, &curRoll);
              double rollChange = fabs(curRoll - prevRoll);
              if ( rollChange < para.rollFilterRange)  // if not changed so much that filter has turned itself off...
                {
                  double filterFactor = para.rollFilterFactor * (0.5 + 0.5 * cos(3.14159*rollChange/para.rollFilterRange));
                  double filteredRoll = filterFactor * prevRoll + (1.0-filterFactor) * curRoll;
                  myPoseEst->setCamRotPTR(curPan, curTilt, filteredRoll);
                }

              // optionally refine these correspondencies by adjusting translation & scale change over all patches....
              if (refineGlobally)
              {
                  myCorrespGen->calcCorrespondenciesGlobally(para.useStoredPatches, para.normaliseDC,
                                                             para.useStoredPatches ? para.highestLevelStoredPatches : -1,
                                                             para.useStoredPatches ? para.lowestLevelStoredPatches : para.lowestLevelPrevPatches);
                  // (let interation-stopping things take default values for now)
                  rmsErr = myPoseEst->calcLastSolution();  // NB this relabels all points as inliers so they don't appear red in subsequent drawing operations
              }
              gettimeofday(&endTime, 0);
              calcSolutionTime =( (endTime.tv_sec - startTime.tv_sec) + (endTime.tv_usec - startTime.tv_usec) / 1000000.0);
            }  // if doTracking
        }  // if not doing exhaustive search

      // Update the patch reliability measure, based on the visibility determined by findCorrespondences() and the inlier/outlier
      // status from calcLastSolutionRansac
      // NB do this before deleting outliers, otherwise we won't count ones that were seen but not deemed good!
      myCorrespGen->updatePatchReliabilityMeasure();

      cout << " see 7?" << endl;

      // delete outliers before assessing features in common: should give more reliable choosing of images to save,
      // but will mean that outliers are drawn on diagnostic display without showing where they were found (will only show a projected red feature),
      // so only do this if multiple-image-solving is happening
      // (if outliers were always deleted at this point, there's no need to do any further outlier deletion further on)
      if (testMultipleImageSolving)
        {
          myPoseEst->deleteOutliers();

          // TEST: create perfect observations of the inlying points, to see whether calcFullSolution comes up with zero error
          if (para.perfectObs)
            {
              // printf("Creating perfect observations...\n");
              myPoseEst->createPerfectObservations();
            }
        }

      // optionally, simulate adding some absolute world points and/or lines
      // Best to do this before creating any features, so that features in frame 0 will allow the camera pose to be computed and thus
      // make sure the features are created in roughly the right place in space.  Can add more points/lines throughout sequence
      bool addedRefFeatures = false;
      bool deleteLastImage = true;  // always do this unless we decide not to in multiple image solving part below
      if (testMultipleImageSolving)
      {
          if (refPoints[nextRefPoint]> 0) while (frame > int(refPoints[nextRefPoint]+0.5)) nextRefPoint += 6;  // skip over any remaining reference features in frames before this one

        while (frame == int(refPoints[nextRefPoint]+0.5))  // while there's an abs ref point in this frame... (int & rounding because it's a double)
          {
            // if we're about to add our first ref point for this frame, first delete any outliers from the previous pose computation
            // (mustn't call deleteOutliers after adding abs ref points but before pose comp, as their inlier/outlier status
            // won't be set yet and they#ll be deleted as soon as they are added!)
            //  -> NB no need to do this now, as we've already deleted outliers if we're doing multiple image solving
            //if (!addedRefFeatures) myPoseEst->deleteOutliers();

         //   printf("Adding absolute point to frame %d: world point %6.2f,%6.2f,%6.2f  image point %5.1f,%5.1f\n",
        //           frame, refPoints[nextRefPoint+1],refPoints[nextRefPoint+2],refPoints[nextRefPoint+3],refPoints[nextRefPoint+4],refPoints[nextRefPoint+5]);
            int pointIndex;
            pointIndex = myPoseEst->addPoint(refPoints[nextRefPoint+1],
                                             refPoints[nextRefPoint+2],
                                             refPoints[nextRefPoint+3]);
            myPoseEst->addPointObservation(-1,
                                           refPoints[nextRefPoint+4]-sideBorder,
                                           bottom2top ? lenY-1 - (refPoints[nextRefPoint+5]-topBorder) : refPoints[nextRefPoint+5]-topBorder ,
                                           para.absRefWeight, (double *) 0, -1, pointIndex);
            addedRefFeatures = true;  // note that points were added, so we can do a global solve and save the frame
          nextRefPoint += 6;  // look at next ref point next time (there are 6 items of data in the array for each point)
          }


  // printf("Here's the next ref: %f\n", refLines[nextRefLine]);


	// as above but for reference lines:
	  if (refLines[nextRefLine]>0) while (frame > int(refLines[nextRefLine]+0.5)) nextRefLine += 11;  // skip over any reference features in frames before this one
	while (frame == int(refLines[nextRefLine]+0.5))  // while there's an abs ref point in this frame...
	  {
	    //  -> NB no need to do this now, as we've already deleted outliers if we're doing ultiple image solving
	    //if (!addedRefFeatures) myPoseEst->deleteOutliers();

         //   printf("Adding absolute line to frame %d: start of line at world point %6.2f,%6.2f,%6.2f  image point %5.1f,%5.1f\n",
         //          frame, refLines[nextRefLine+1],refLines[nextRefLine+2],refLines[nextRefLine+3],refLines[nextRefLine+7],refLines[nextRefLine+8]);
        //    printf("                                  end of line at world point %6.2f,%6.2f,%6.2f  image point %5.1f,%5.1f\n",
        //           frame, refLines[nextRefLine+4],refLines[nextRefLine+5],refLines[nextRefLine+6],refLines[nextRefLine+9],refLines[nextRefLine+10]);
            int lineIndex;
            lineIndex = myPoseEst->addLine(refLines[nextRefLine+1],
                                           refLines[nextRefLine+2],
                                           refLines[nextRefLine+3],
                                           refLines[nextRefLine+4],
                                           refLines[nextRefLine+5],
                                           refLines[nextRefLine+6]);
            if (lineIndex < 0) { printf("Exceeded storage space for lines when adding a reference line - try incresing maxRefWorldLines!\n"); exit(-1); }
            bool addLineObservation(int lineIndex, double x0, double y0, double x1, double y1, double weight=1.0, int cam=-1, int obj=-1);
#ifdef FEATURES_BOTTOM2TOP_WITHBORDERS   // if coords are for bottom2top and include borders (as from a .obs file)
            myPoseEst->addLineObservation(lineIndex,
                                          refLines[nextRefLine+7],
                                          !bottom2top ? lenY-1 - (refLines[nextRefLine+8]) : refLines[nextRefLine+8] ,
                                          refLines[nextRefLine+9],
                                          !bottom2top ? lenY-1 - (refLines[nextRefLine+10]) : refLines[nextRefLine+10] ,
                                          para.absRefWeight);
#else
            myPoseEst->addLineObservation(lineIndex,
                                          refLines[nextRefLine+7]-sideBorder,
                                          bottom2top ? lenY-1 - (refLines[nextRefLine+8]-topBorder) : refLines[nextRefLine+8]-topBorder ,
                                          refLines[nextRefLine+9]-sideBorder,
                                          bottom2top ? lenY-1 - (refLines[nextRefLine+10]-topBorder) : refLines[nextRefLine+10]-topBorder ,
                                          para.absRefWeight);
#endif

            addedRefFeatures = true;  // not that points were added, so we can do a global solve and save the frame
            nextRefLine+= 11;  // look at next ref point next time (11 items of data in array for each line)
          }
        // as above but for reference lines parallel to an axis but in unknown position:
        if (refParallelLines[nextRefParallelLine]>0) while (frame > int(refParallelLines[nextRefParallelLine]+0.5)) nextRefParallelLine += 6;  // skip over any reference features in frames before this one
        while (frame == int(refParallelLines[nextRefParallelLine]+0.5))  // while there's an abs ref point in this frame...
          {
            //  -> NB no need to do this now, as we've already deleted outliers if we're doing ultiple image solving
            //if (!addedRefFeatures) myPoseEst->deleteOutliers();

            int axis=(int)(refParallelLines[nextRefParallelLine+1]);

         //   printf("Adding line parallel to frame %d parallel to axis %d:  image points %5.1f,%5.1f  %5.1f,%5.1f\n",
        //           frame, axis,
        //           refParallelLines[nextRefParallelLine+2],refParallelLines[nextRefParallelLine+3],
         //          refParallelLines[nextRefParallelLine+4],refParallelLines[nextRefParallelLine+5]);

            int lineIndex = myPoseEst->addLineObservationWithKnownDirection(
                                                                            refParallelLines[nextRefParallelLine+2]-sideBorder,
//									    refParallelLines[nextRefParallelLine+3]-topBorder,
                                                                            bottom2top ? lenY-1 - (refParallelLines[nextRefParallelLine+3]-topBorder) : refParallelLines[nextRefParallelLine+3]-topBorder ,
                                                                            refParallelLines[nextRefParallelLine+4]-sideBorder,
//									    refParallelLines[nextRefParallelLine+5]-topBorder,
                                                                            bottom2top ? lenY-1 - (refParallelLines[nextRefParallelLine+5]-topBorder) : refParallelLines[nextRefParallelLine+5]-topBorder ,
                                                                            axis,
                                                                            para.absRefWeight);
            addedRefFeatures = true;  // not that points were added, so we can do a global solve and save the frame
            nextRefParallelLine+= 6;  // look at next ref point next time (6 items of data in array for each line)
          }


        cout << " see 8?" << endl;

        // -------------- start of main changes when introducing saving of safety images -------------
        // if lines are only to be used in saved images, add them now (after the frame-to-frame tracking): we may not use this frame but it could become a safety image later
        // (will need lines for this frame if useFrameForGlobalSolve and not got safety image (in which case it will be used right now),
        // or if not using it for global solve and not got a safety image, in which case it becomes a safety image, ie.
        // only don't need to do it if using frame for global solve and have a safety image, as in that case we're about to
        // delete it) - simplest to just do this every frame if only using lines for saved images
        // NB *do not* call this if line observations have been added manually, as it starts by deleting all line observations!!
        //  -> thus we only do this if addedRefFeatures is false
        // (The reason for wanting to have lines only on saved images is that, for these images, the world is allowed to rotate, effectively
        // allowing camera roll, because we're doing a global solution.  If lines are used without allowing some way of compensating for roll, then
        // the tracker tends to 'slide' along the lines, presumably in an attempt to get reasonable registration.
        if (usingLines && para.linesOnlyForSavedImages && !addedRefFeatures)
        {
            // clear lineDiagnosticImage if you're going to look at it rather than just use it as working storage
            if (para.lineImOut_flag)
                for (int yy=0; yy<lenY; yy++)
                {
                    unsigned char *lineDiagnosticImageLine = lineDiagnosticImage + yy * incY;
                    for (int xx=0; xx<lenX; xx++)
                        for (int cc=0; cc<incX; cc++) lineDiagnosticImageLine[xx*incX+cc] = 0;
                }

            // set line-finding parameters here: previously we set them right at the start but now we allow them to be
            // adapted to the estimated image velocity
            double curVelX, curVelY;
            myPoseEst->getCurrentImageVelocity(&curVelX, &curVelY);
            // search for & add line to this image, so they will be used for pose refinement without 'dragging' off intermediate
            // images
            gettimeofday(&startTime, 0);
            totalLineWeightUsed =
                myInitialPoseEstLines->addLinesFromImageUsingEstimatedPose(imageR, imageG, imageB,      // input image
                                                                           lineDiagnosticImage,         // output for edge or key
                                                                           incX, incY,        // NB these are common for inuput RGB and output diagnostic
                                                                           mykeyer, hGrad, vGrad,
                                                                           &nLinesFound,
                                                                           nLinesToTrack,  // only use nLinesToTrack lines, which are the number in the model, excluding any manually-added calibration lines
                                                                           para.lineWeightScale,
                                                                           curVelX, curVelY,
                                                                           para.useAllLinePoints);
              gettimeofday(&endTime, 0);
              findLinesTime += ( (endTime.tv_sec - startTime.tv_sec) + (endTime.tv_usec - startTime.tv_usec) / 1000000.0);
        }

	//if (frame != para.refFrame)  // TEST: don't actually call full solution in the specified ref frame     
	if (addedRefFeatures)  // if any absolute ref points or lines added..... we do a global solve using all currently-stored images
	{
	  // experiment: add a new image with a wide field-of-view to see most/all of the features
	  if (frame == para.virtualRefImage)
	    {
	      if (!myPoseEst->addNewImage(fieldType, bottom2top, notionalPixHeight))
        //	printf("Run out of space for storing images: just overwrote top one stored!!\n");
         //     printf("Creating a dummy camera and creating perfect observations for it...\n");
	      myPoseEst->setCamRotPTR(-40.0, -5.0, 0.0);  // values designed to be around the middle of the track
       //  printf("Pan6: set pan\n");
	      myPoseEst->setCamFOV(70.0, lenYFullFrameField);  // impractically-large fov
	      myPoseEst->createPerfectObservations();
	    }

        // Decide whether to keep current image as a safety image, whether to
        // delete the last image, and do any copy of latest image on top of
        // safety image if needed.  Then we can go on to do a global solve if
        // ref features were added (need to have deleted any unwanted safety
        // im before doing this), create new fetures (must have latest image
        // at top of image stack still when doing this so camera pose is still
        // relevant), and finally can delete top image if needed.
        int nFeaturesInCommon;  // for value returned - used to control deleteUNseenPatches as well as for printing
        int nUniqueFeatures;    // for diagnostic printout
        deleteLastImage=myPoseEst->manageStoredImages(addedRefFeatures, para.multiIm, &nFeaturesInCommon,
            para.maxUniqueFeatures, &nUniqueFeatures);  // whether we'll delete the last image after doing feature-finding
        //printf("  Unique features in the safety/latest im = %d\n", nUniqueFeatures);
        if (nFeaturesInCommon >= 0) printf("Saving an image with an overlap of %d features with the last saved one and %d unique features\n", nFeaturesInCommon, nUniqueFeatures);
        if (nFeaturesInCommon > 0 && nFeaturesInCommon < para.multiIm) printf("  **** NB fewer than the desired number of overlapping features ****\n");

       // ********* The following has been removed 25/8/11 by robertd and gat due to the problem mentioned below  *********
	    // fix camera roll to zero, effectively over-riding any
	    // rollPitchNotCamera(false) that may have been used to
	    // allow roll during tracking, e.g. to allow lines to stay
	    // aligned)
	    //myPoseEst->rollPitchNotCamera(true);  // 'roll' the ref frame, not individual camera poses
	    //double panEst, tiltEst, rollEst;
	    //myPoseEst->getCamRotPTR(&panEst, &tiltEst, &rollEst);
       //myPoseEst->setCamRotPTR(panEst, tiltEst, 0.0);  // always set roll to zero as we're going to roll the world

	    // if this is the first frame we've added ref features to, use the features to estimate the initial camera orientation and fov
	    if (first)
	    {
	      double panEst, tiltEst, rollEst, fovyEst;
	      myPoseEst->getCamRotPTR(&panEst, &tiltEst, &rollEst);
	      myPoseEst->getCamFOV(&fovyEst, lenYFullFrameField);
        //      printf("Before estimating camera orientation from line correspondencies  pan=%6.2f  tilt=%6.2f  roll=%6.2f, fovy=%6.2f\n", panEst, tiltEst, rollEst, fovyEst);
		   int nPointsUsed = myPoseEst->roughEstimateCameraOrientationFOVFromLineObservations();
      
         // ********* The following code has been added back in 25/8/11 because it's removal was breaking tracking from a calibration with rollCam=0 *********
         myPoseEst->getCamRotPTR(&panEst, &tiltEst, &rollEst);
         if (para.rollCam == 0) myPoseEst->setCamRotPTR(panEst, tiltEst, 0.0);  // if not allowing camera roll, set it to zero rather than estimated value

         myPoseEst->getCamFOV(&fovyEst, lenYFullFrameField);
       //  printf(" After estimating camera orientation from line correspondencies  pan=%6.2f  tilt=%6.2f  roll=%6.2f, fovy=%6.2f\n", panEst, tiltEst, rollEst, fovyEst);
       //  printf("used %d points (-1 means points were inconsistent)\n", nPointsUsed);
         // ********* End of code added back in *********

      //int nPointsUsed=0;  printf("TESTING: turned off roughEstimateCameraOrientationFOVFromLineObservations\n");
		//myPoseEst->getCamRotPTR(&panEst, &tiltEst, &rollEst);
		//myPoseEst->getCamFOV(&fovyEst, lenYFullFrameField);
		//printf(" After estimating camera orientation from line correspondencies  pan=%6.2f  tilt=%6.2f  roll=%6.2f, fovy=%6.2f\n", panEst, tiltEst, rollEst, fovyEst);
		//printf("used %d points (-1 means points were inconsistent)\n", nPointsUsed);
	    }

            cout << " see 9?" << endl;

            myPoseEst->expectPoseToJump();  // don't update info used for velocity computation: pose will jump just due to new ref features
            //if (useFrameForGlobalSolve) printf("WARNING: reference features added to a frame with fewer than desired features linking it to the previous frame!\n");

            // permanently delete any points not observed in any of the stored images we currently have
            // (as if they aren't observed, we can't refine their position)
            int unseenDeleted = myCorrespGen->deleteUnseenPatches();
        //    printf("Deleted %d features not seen in any stored reference image\n", unseenDeleted);
            // enable adjustment of patch positions and camera position on selected axes
            myPoseEst->adjustCamPos(adjCamX, adjCamY, adjCamZ);
            myPoseEst->adjustDistortionAsFnOfFoclen(para.adjCoeffFD);

            // fix camera roll to zero, effectively over-riding any
            // rollPitchNotCamera(false) that may have been used to
            // allow roll during tracking, e.g. to allow lines to stay
            // aligned)
            myPoseEst->rollPitchNotCamera(true);  // 'roll' the ref frame, not individual camera poses
            double panEst, tiltEst, rollEst;
            myPoseEst->getCamRotPTR(&panEst, &tiltEst, &rollEst);
            myPoseEst->setCamRotPTR(panEst, tiltEst, 0.0);  // always set roll to zero as we're going to roll the world

	    myPoseEst->adjustDistortionAsFnOfFoclen(false); // turn this off for normal calls to calcSolution
	    //myPoseEst->rollPitchNotCamera(para.rollCam == 0);  // restore original freedom to roll each frame separately if required // ********* Removed 25/8/11 as part of the problem mentioned above *********
	    myPoseEst->adjustCamPos(false);
	    double cx, cy, cz;
	    myPoseEst->getCamPos(&cx, &cy, &cz);  
        //    printf("  RMS error from full solution in frame %d = %f  camera position is now -initX %f -initY %f -initZ %f\n", frame, rmsErr, cx, cy, cz);
	    //double rx, ry, rz;
	    //myPoseEst->getPitchRot(&rx, &ry, &rz);     // rotation of pitch
	    //printf("                                                  pitch rotation is now -initRX %f -initRY %f -initRZ %f\n", rx, ry, rz);
	    if (para.adjCoeffFD)
	    {
        //	printf("      Coeffs for D as funct of foclen = ");
        //	for (int i=0; i<para.nCoeffFD; i++)
        //	    printf("%6.2f  ", myPoseEst->getCoeffFD()[i]);
	    }
	    // optionally create new permanent patches to make up for deleted ones: in theory this might be useful as
	    // the patches will appear in this saved frame and thus would help linkage between saved frames; in practice
	    // it never seems to need to create any
	    if (0)
	    {
        //	printf("Creating new permanent patches to make up for deleted ones and giving them perfect observations\n");
		int expiryTime = -1;  // by default, patches never expire
		myCorrespGen->setMinFeatureVal(para.minFeatureValTemp);  // params for permanent feature finding
		myCorrespGen->setMinFeatureValBigEigen(para.minFeatureValTempBigEigen);
		myCorrespGen->setMinDist(para.minDistTemp);
		int featureIndexToStartAt = myCorrespGen->getNPatches();
		int newCreated = myCorrespGen->createNewPatches(para.minPatchesPerRegion, para.nRegionsToSearch, expiryTime);
		myPoseEst->createPerfectObservations(1.0, -1, featureIndexToStartAt);  // weight of 1.0 as used in PatchCorrespGen, current cam, only new features
        //	printf("Created %d new points with perfect observations\n", newCreated);
	    }
	    
	  }
      }  // if testing multiple im solving


      // test the deletion of features that lie outside (or inside, depending on polarity) of region specified by triangle strips
      if (frame == para.triStripCleanup)
      {
      //    printf("Deleting features that now lie in regions outside those defined by triangle strips...\n");
          int nFeaturesCleanedUp = myCorrespGen->discardStoredPatchesUsingTriStripRegion();
      //    printf("Cleanup process deleted %d features\n", nFeaturesCleanedUp);
      }

      // Non-camera real-world motion detection - done by projecting the previous frame into this frame and thresholding the absolute difference
      // Note that this computes and displays a mask based on the frame that has just been processed, so if drawn on the current
      // image it should like up perfectly and be calculated even with rapid accelerations in camera parameters, and will thus
      // be correct for preventing the learning of new patches (which happens further on).  However, the mask
      // computed here will be also be used to prevent patches in motion areas being tracked for the following image in findCorrespondences(),
      // and will thus be one field too late and not perfectly lined-up.  However, as checks are made for samples surrounding (as well as at)
      // the block centre, and in many applications the camera will be roughly following moving foregrouns objects (so the mask position won't
      // change that much between successive images), this shouldn't be a big problem.  Just don't be surprised if a point is used for
      // tracking despite bein shown by the diagnostic output to lie in/very near a foreground motion region
      gettimeofday(&startTime, 0);
      if (ignoreNonCamMotion || drawMotionMask) {  // compute the mask if we've been asked to ignore non-cam motion or just draw it
        //printf("Determining non-camera motion between frames %d and %d\n",frame - 1, frame);
        if (addedRefFeatures)
   {
      myCorrespGen->invalidateCamMotionMask();  // can't generate a valid one if cam pos may have changed
   }
        else
   {
    //  printf("Detect\n");
      myCorrespGen->detectNonCameraMotion(motionThresh, para.motion_nProjX, para.motion_nProjY);
      myCorrespGen->detectNonCameraMotionReverse(motionThresh, para.motion_nProjX, para.motion_nProjY);
   }
      }
      gettimeofday(&endTime, 0);
      ignoreNonCamMotionTime =( (endTime.tv_sec - startTime.tv_sec) + (endTime.tv_usec - startTime.tv_usec) / 1000000.0);

      // draw diagnostics - do this after all computation used to compute pose for this frame (including any use of manually-added features, which must be
      // preceded by outlier deletion), but before creating new features that have not contributed to this pose
      if (doVideoOutput)  // only bother to draw if diagnostic image will be output
        {

#ifdef TEST_TRISTRIP_KEY
          // test the setting of key colours and use of the keyer
          //printf("Learning on current field...\n");
          gettimeofday(&startTime, 0);
          // no need to clear key as this method does it (except when para.keyMinSamples=0 and para.keyFilterFactor=0, in which case
          // the intention is to accumulate the key colours on top of what was learend before
          int nPixelsLearned = myPoseEst->setChromaKeyerFromTriStrip(keyerForGraphics,
                                                                     imageR, imageG, imageB, incX, incY, lenX, lenY,
                                                                     para.keySpread1, para.keySpread2,
                                                                     para.keySsx, para.keySsy,
                                                                     para.keyMinSamples, para.keyFilterFactor,
                                                                     para.keyAveragingDist,
                                                                     myCorrespGen->getNonCameraMotionMask(), motionDiffResolution, para.keyMotionIgnoreDist);
          gettimeofday(&endTime, 0);
          keyCalcTime =( (endTime.tv_sec - startTime.tv_sec) + (endTime.tv_usec - startTime.tv_usec) / 1000000.0);
          //printf("Learned key from %d pixels... now writing key into red channel...\n", nPixelsLearned);
          keyerForGraphics->chromaKey(imageR, imageG, imageB, imageR, incX, incY, lenX, lenY);
#endif

          // draw mask from the previous two frames to show the regions that were ignored during tracking on this frame
          if (drawMotionMask) {
       //     printf("Drawing non-camera motion between frames %d and %d\n",frame - 1, frame);
                        /*for(int i=0;i<in->GetNx();i++)
                                for(int j=0;j<in->GetNy();j++)
                                        for(int k=0;k<in->GetNz();k++)
                                                in->SetPixel_q(0,i,j,k);*/
                        myCorrespGen->drawNonCameraMotionMask(imageG, incX, incY,  lenX,  lenY, motionDilate, motionDilateHalfWin);
                }

	  // draw points that have been found in yellow, projected points in red (outliers) or green (inliers)
	  // (must do before deleting any points, as otherwise points we have just used won't all be shown)
	  if (drawPoints)
	    {
	      myPoseEst->drawPoints(imageR, imageG, imageB, incX, incY, lenX, lenY, patchLenX, patchLenY, drawDirScale);
	      myCorrespGen->drawPermanentPatches(imageG, incX, incY, lenX, lenY);  // boxes around permanent features
	//      myPoseEst->drawLines(imageR, imageG, imageB, incX, incY, lenX, lenY);  // show any reference lines we have - either model lines or calibration lines
	    }
	  
	  if (drawCuboid)
	  {
        //     printf("drawing cuboid...\n");
	      //	  double nGridBoxesVertically = 1.5;
	      double nGridBoxesVertically = 3.0;
	      double gwx=5.0, gwy=5.0, gwz=5.0;  // half-widths of cube on which grid is drawn
	      int nSquares = (int)(nGridBoxesVertically/tan(para.initLensAngle/2*3.141/180.0));  // to have about 3 lines in initial fov
	      //int nSquares = 20; 
	      double swx = 2.0*gwx / (double)nSquares;  // lengths of sides of each grid square
	      double swy = 2.0*gwy / (double)nSquares;
	      double swz = 2.0*gwz / (double)nSquares;
	      double cx, cy, cz;
	      myPoseEst->getCamPos(&cx, &cy, &cz);  
	      myPoseEst->drawCuboid(imageG, incX, incY, lenX, lenY,
				    -gwx+cx, -gwy+cy, -gwz+cz,  // corner of cube
				    swx, 0, 0,  // vector of grid spacing in u dir
				    0, swy, 0,  // ditto in v dir (usually normal to u dir)
				    0, 0, swz,  // ditton on third cube edge
				    nSquares, nSquares,nSquares );
	    }

          cout << " see 10?" << endl;

      myPoseEst->getCamRotPTR(&pan, &tilt, &roll);
    //  printf("pan10: %f %f\n", pan, tilt);
    //  myPoseEst->printObservationData(); // TEST: print data that was used

        /*  if (draw100mTrack)
     {
       printf("drawing track...\n");
       if (draw100mTrack)
       myPoseEst->drawGrid(imageG, incX, incY, lenX, lenY,
            0, 0,0,       // corner of grid
            1.0, 0, 0,     // vector of grid spacing in u dir (define this as along the track)
            0, 0, 1.22,    // ditto in v dir (usually normal to u dir)
            100, 9);    //  60x1m long, 6 x 1.22 wide
     }*/

	  if (draw60mTrack)
     {
     //  printf("drawing track...\n");
	    myPoseEst->drawGrid(imageG, incX, incY, lenX, lenY,
				0, 0, 0,       // corner of grid
				1.0, 0, 0,     // vector of grid spacing in u dir (define this as along the track)
				0, 0, 1.22,    // ditto in v dir (usually normal to u dir)
				60, 6);        //  60x1m long, 6 x 1.22 wide
     }
          if (drawCuboid)
          {
            // printf("drawing cuboid...\n");
              //	  double nGridBoxesVertically = 1.5;
              double nGridBoxesVertically = 3.0;
              double gwx=5.0, gwy=5.0, gwz=5.0;  // half-widths of cube on which grid is drawn
              int nSquares = (int)(nGridBoxesVertically/tan(para.initLensAngle/2*3.141/180.0));  // to have about 3 lines in initial fov
              //int nSquares = 20;
              double swx = 2.0*gwx / (double)nSquares;  // lengths of sides of each grid square
              double swy = 2.0*gwy / (double)nSquares;
              double swz = 2.0*gwz / (double)nSquares;
              double cx, cy, cz;
              myPoseEst->getCamPos(&cx, &cy, &cz);
              myPoseEst->drawCuboid(imageG, incX, incY, lenX, lenY,
                                    -gwx+cx, -gwy+cy, -gwz+cz,  // corner of cube
                                    swx, 0, 0,  // vector of grid spacing in u dir
                                    0, swy, 0,  // ditto in v dir (usually normal to u dir)
                                    0, 0, swz,  // ditton on third cube edge
                                    nSquares, nSquares,nSquares );
            }

          if (draw60mTrack)
            myPoseEst->drawGrid(imageG, incX, incY, lenX, lenY,
                                0, 0, 0,       // corner of grid
                                1.0, 0, 0,     // vector of grid spacing in u dir (define this as along the track)
                                0, 0, 1.22,    // ditto in v dir (usually normal to u dir)
                                60, 6);        //  60x1m long, 6 x 1.22 wide

          if (para.drawLongJump)
            {
              // draw distance lines across pit, from 1-8,
              myPoseEst->drawGrid(imageG, incX, incY, lenX, lenY,
                                1, 0, -1.445,       // corner of grid
                                1.0, 0, 0,     // vector of grid spacing in u dir (define this as along the track)
                                0, 0, 2.89,    // ditto in v dir (usually normal to u dir)
                                7, 1);        //  7m long, 1 lot of 2.89m wide
              // draw 1m-spaced lines on track, from 500m before takeoff to 1m after takeoff (track is 1.3m wide)
              myPoseEst->drawGrid(imageG, incX, incY, lenX, lenY,
                                -500, 0, -0.65,       // corner of grid - make it really long
                                1.0, 0, 0,     // vector of grid spacing in u dir (define this as along the track)
                                0, 0, 1.3,    // ditto in v dir (usually normal to u dir)
                                501, 1);        //  201 x 1m long, 1 x 1.3 wide
            }
          if (0)  // skip this - drawn by drawLines method now
          {
          if (usingLines) // draw lines if we are using them
          {
              //printf("Drawing model lines...\n");
              for (int l=0; l<nLinesToTrack; l++)
              {
                  double x0, y0, x1, y1;
                  if (myPoseEst->projectIntoImage(l, &x0, &y0, &x1, &y1) )  // projects for latest camera pose and reference object by default
                  {
                      //printf("Line %d projects to %f,%f ... %f,%f\n", l, x0, y0, x1, y1);
                      FittedLine lineToDraw(x0, y0, x1, y1);
                      lineToDraw.drawLine(imageG, incX, incY, lenX, lenY, 255, 2.0);  // draw model lines in green
                      // NB model lines are drawn in green here and red earlier, so appear yellow, whereas calibration lines are drawn only in red
                  }
              }
          }
          }
        } // if doing video output

      // remove 'dummy' image added for full solution calc
      // (TESTING: do this here rather than immediately after full solve so diagnostics will use the dummy pose)
      // NB use clearImage, not clearLastImage, to leave the right default values for addNewImage().
        if (addedRefFeatures && frame == para.virtualRefImage)
          myPoseEst->clearImage(myPoseEst->getNImages()-1);

      // try creating extra patches in areas that don't have enough yet
      // (patches will be assigned a pose based on the one just computed for this frame).
      // Permanent ones never expire; temporary ones have the given lifetime.
      // eg. first gather permanent ones with a high threshold, then disable permanent gathering
      // and create temporary ones only.  Ideally, permanent ones would be chosen with some hand-crafting
      // to make sure they are on fixed parts of the scene.  Could create temp ones while also creating
      // permanent ones, but temp ones might stop permanent ones being created if they are too close or
      // there are too many.  Create permanent ones first to minimise this problem.
      // Also, only do perm ones on one field and only do tems if no perms searched for, to
      // keep to only searching given number of patches per region

      // delete old patches that should expire before this frame number
      // (moved this to here 5.4.09 to make it work if all patches die at the same time)
      int patchesDeleted = myCorrespGen->deleteOldPatches(frame);
      //printf("Deleted %d old patches before doing searching for correspondencies\n", patchesDeleted);

      // permanently delete any patches that have only been inliers in a small proportion of images that they have been visible in
      patchesDeleted = myCorrespGen->deleteUnreliablePatches(para.minVisFraction, para.minVisTimes);
      //printf("Deleted %d patches that were not seen as inliers for a big enough proportion of the time\n", patchesDeleted);

      int newPermanentPatchesCreated=0;
      int newTemporaryPatchesCreated=0;

      gettimeofday(&startTime, 0);
      //if (lookForNewPermanentPatches && (frame % 2 == 1) )   // looking for new permanent patches?
      if (lookForNewPermanentPatches && (!lookForNewTemporaryPatches || (frame % 2 == 1)))  // search for perm unless f2 and doing temp
        {
          int expiryTime = -1;  // by default, patches never expire
          myCorrespGen->setMinFeatureVal(para.minFeatureVal);  // params for permanent feature finding
          myCorrespGen->setMinFeatureValBigEigen(para.minFeatureValBigEigen);
          myCorrespGen->setMinDist(para.minDist);
          newPermanentPatchesCreated = myCorrespGen->createNewPatches(para.minPatchesPerRegion, ( first ? -1 : para.nRegionsToSearch ), expiryTime);
          //printf(" \n...created %d new perm patches\n", newPermanentPatchesCreated);
        }
      //else if (lookForNewTemporaryPatches)  // looking for new temp patches?
      if (lookForNewTemporaryPatches && (!lookForNewPermanentPatches || (frame % 2 == 0)))  // search for temp unless f1 and doing perm
        {
          int expiryTime = -1;  // by default, patches never expire
          if (para.lifeTime > 0) expiryTime = para.lifeTime + frame;
          myCorrespGen->setMinFeatureVal(para.minFeatureValTemp);  // params for permanent feature finding
          myCorrespGen->setMinFeatureValBigEigen(para.minFeatureValTempBigEigen);
          myCorrespGen->setMinDist(para.minDistTemp);
          newTemporaryPatchesCreated = myCorrespGen->createNewPatches(para.minPatchesPerRegion, ( first ? -1 : para.nRegionsToSearch ), expiryTime);
        }
      gettimeofday(&endTime, 0);
      findNewFeaturesTime =( (endTime.tv_sec - startTime.tv_sec) + (endTime.tv_usec - startTime.tv_usec) / 1000000.0);
      // printf("Deleted %d patches and made %d new perm ones and %d new temp ones\n", patchesDeleted, newPermanentPatchesCreated, newTemporaryPatchesCreated);

      // if abs ref points added to first frame, we need to ensure there are some observed features in this frame to provide linkage
      // with following frames: we've created new features so let's simulate some observations of them
      if (addedRefFeatures && first)
        {
      //    printf("Creating perfect observations....\n");
          myPoseEst->createPerfectObservations(1.0);  // weight of 1 as used in PatchCorrespGen
        }

      myPoseEst->getCamRotPTR(&pan, &tilt, &roll);
    //  printf("pan1: %f %f\n", pan, tilt);
      myPoseEst->getCamFOV(&fovy, lenYFullFrameField);
      myPoseEst->getCamFocalLength(&focalLength);
      double cx, cy, cz;
      myPoseEst->getCamPos(&cx, &cy, &cz);

    //  printf(" HELLLLLOOOOOOOOOOOOO!!! %05d %03d %04d %04d %3.0f %6.2f %7.3f %7.3f %7.3f %7.3f %2d %2d",
    //         frame, droppedFrames, myCorrespGen->getNPatches(), nPointsFound, (float)nFinalPoints/(float)nPointsFound*100.0, rmsErr, pan, tilt, roll, fovy, newPermanentPatchesCreated, newTemporaryPatchesCreated );

      double currentDistort;  myPoseEst->getCamDistortion(&currentDistort);
    //  printf(" dist: %6.1f", currentDistort);

  //    printf(" times: %5.2f %5.2f %5.2f %5.2f %5.2f %5.2f %5.2f %5.2f\r", loadImageTime*1000, findCorrespondencesTime*1000, findLinesTime*1000, calcSolutionTime*1000, findNewFeaturesTime*1000, ignoreNonCamMotionTime*1000, calcFullSolutionTime*1000, keyCalcTime*1000)
;

   //   printf("Still workingline1754 \n");

      // compute first and second derivatives of pan, tilt, fov to provide a measure of tracking noise
      prevPanChange = panChange;
      if (!first) panChange = pan-prevPan;  // prevPan not valid on first frame
      prevPan = pan;
      if (!first) panSecDerivSquaredTotal += (panChange-prevPanChange) * (panChange-prevPanChange);

      prevTiltChange = tiltChange;
      if (!first) tiltChange = tilt-prevTilt;  // prevTilt not valid on first frame
      prevTilt = tilt;
      if (!first) tiltSecDerivSquaredTotal += (tiltChange-prevTiltChange) * (tiltChange-prevTiltChange);

      prevFovChange = fovChange;
      if (!first) fovChange = fovy-prevFov;  // prevFov not valid on first frame
      prevFov = fovy;
      if (!first) fovSecDerivSquaredTotal += (fovChange-prevFovChange) * (fovChange-prevFovChange);

      prevRoll = roll;

      // record key parameters to optional log file
      // (uncomment appropriate line for separators as commas or whitespace (excel prevers commas, gnuplot wants spaces)
      if (logFile != (FILE*)NULL)
        //fprintf(logFile, "%05d, %04d, %04d, %04d, %6.2f, %6.3f, %6.3f, %6.2f, %7.3f, %7.3f, %7.3f, %7.3f, %7.3f, %7.3f, %7.3f, %2d, %2d, %5.2f, %5.2f, %5.2f, %5.2f, %5.2f, %5.2f\n",
     //   fprintf(logFile, "%05d %04d %04d %04d %6.2f %6.3f %6.3f %6.2f %7.3f %7.3f %7.3f %7.3f %7.3f %7.3f %7.3f %2d %2d %5.2f %5.2f %5.2f %5.2f %5.2f %5.2f\n",
     //           frame,  myCorrespGen->getNPatches(), nPointsFound, nLinesFound, totalLineWeightUsed, (float)nFinalPoints/((float)nPointsFound+1e-10),
     //           (float)nFinalLines/((float)nLinesFound+1e-10),  rmsErr, pan, tilt, roll, fovy, cx, cy, cz,
     //           newPermanentPatchesCreated, newTemporaryPatchesCreated,
     //           loadImageTime*1000, findCorrespondencesTime*1000, findLinesTime*1000, calcSolutionTime*1000, findNewFeaturesTime*1000, calcFullSolutionTime*1000);
      fflush(logFile);  // so something is written even if prog exits via e.g. control-c

      // note totals of times for printing an average at the end
      loadImageTimeTotal += loadImageTime;  findCorrespondencesTimeTotal += findCorrespondencesTime;  findLinesTimeTotal += findLinesTime;
      calcSolutionTimeTotal += calcSolutionTime; findNewFeaturesTimeTotal += findNewFeaturesTime;
      calcFullSolutionTimeTotal += calcFullSolutionTime;
      ignoreNonCamMotionTimeTotal += ignoreNonCamMotionTime;
      keyCalcTimeTotal += keyCalcTime;
      if (loadImageTime > loadImageTimeMax) loadImageTimeMax = loadImageTime;
      if (findCorrespondencesTime > findCorrespondencesTimeMax) findCorrespondencesTimeMax = findCorrespondencesTime;
      if (findLinesTime > findLinesTimeMax) findLinesTimeMax = findLinesTime;
      if (calcSolutionTime > calcSolutionTimeMax) calcSolutionTimeMax = calcSolutionTime;
      if (findNewFeaturesTime > findNewFeaturesTimeMax) findNewFeaturesTimeMax = findNewFeaturesTime;
      if (calcFullSolutionTime > calcFullSolutionTimeMax) calcFullSolutionTimeMax = calcFullSolutionTime;
      if (ignoreNonCamMotionTime > ignoreNonCamMotionTimeMax) ignoreNonCamMotionTimeMax = ignoreNonCamMotionTime;
      if (keyCalcTime > keyCalcTimeMax) keyCalcTimeMax = keyCalcTime;
      inliersTotal+=nFinalPoints;  // total inliers so far (out of RANSAC)
      searchedFeaturesTotal+=nPointsFound;  // total features put into RANSAC so far

#ifndef USING_DVS
          printf("\n");
#endif

      // optionally update search range based on values just measured
      // Only do this when it is learning permanent features, as we assume this is in a controlled situation
      // where it is unlikely to get lost and thus the range is learned along with the features.
      if (lookForNewPermanentPatches && para.autoRange)
        {
          if (pan < para.pMin) para.pMin = pan;
          if (pan > para.pMax) para.pMax = pan;
          if (tilt < para.tMin) para.tMin = tilt;
          if (tilt > para.tMax) para.tMax = tilt;
          if (roll < para.rMin) para.rMin = roll;
          if (roll > para.pMax) para.rMax = roll;
          if (fovy < para.fMin) para.fMin = fovy;
          if (fovy > para.fMax) para.fMax = fovy;
        }


#ifdef USING_DVS
      // if progressive or just done f2, write the result to the DVS card
      if (fieldType != 0 && doVideoOutput) mycard->FIFO_PutFrame(mybuf, bufsize, NULL, 0);  // write immediately instead of starting new thread
#else
      //printf("Writing image...\n");

// flip image upside down (to put it back the right way up) if reading from file but emulating the bottom2top ordering
      if (bottom2top)
      {
          //printf("Flipping image read from file...\n");
          for (int y1=0; y1<lenY/2; y1++)
          {
              int y2=lenY-1-y1;  // exchange lines y1 and y2
              //printf("Swapping lines %d and %d...\n", y1, y2);
              for (int x=0; x<lenX; x++)
              {
                  int pixAdr1=x*incX + y1*incY;
                  int pixAdr2=x*incX + y2*incY;
                  unsigned char temp;
                  temp=imageR[pixAdr1]; imageR[pixAdr1] = imageR[pixAdr2]; imageR[pixAdr2]=temp;
                  temp=imageG[pixAdr1]; imageG[pixAdr1] = imageG[pixAdr2]; imageG[pixAdr2]=temp;
                  temp=imageB[pixAdr1]; imageB[pixAdr1] = imageB[pixAdr2]; imageB[pixAdr2]=temp;
              }
          }
      }




      double last_time = clock();

      cout << "Timing point 0: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();


      ////////////////////////////Robert's New Bit///////////////////////////////////////////////////////////////////
    int frameNumber = frame - para.in_pnt;

      ///////////////////////////////////////////////////////////////////////////////////////////////////////////////

      //This bit does the motion detection by looking 2 frames before and 2 frames after the frame in question.

      #define MAX_REGION 10000

      unsigned char tmp[3];
      ColourBGR *col = (ColourBGR *) tmp;

      for(int xm = 0;xm<lenX;xm++)
      {
         for(int ym = 0;ym<lenY;ym++)
         {

            inmaskreverse->SetPixel(0, xm, ym);
            inmask->SetPixel(0, xm, ym);
         }
      }

           int sinIncX = inmask->GetElementPtr(1,0,0) - inmask->GetElementPtr(0,0,0);
           int sinIncY = inmask->GetElementPtr(0,1,0) - inmask->GetElementPtr(0,0,0);
      unsigned char *imageMask = inmask->GetElementPtr(0,0,0) + sideBorder*sinIncX + topBorder*sinIncY;
      unsigned char *imageMaskReverse = inmaskreverse->GetElementPtr(0,0,0) + sideBorder*sinIncX + topBorder*sinIncY;

      myCorrespGen->drawNonCameraMotionMask(imageMask, sinIncX, sinIncY,  lenX,  lenY, motionDilate, motionDilateHalfWin);
      myCorrespGen->drawNonCameraMotionMaskReverse(imageMaskReverse, sinIncX, sinIncY,  lenX,  lenY, motionDilate, motionDilateHalfWin);

      int red = 255;
      int green = 255;
      int blue = 255;

      cout << "Timing point 1: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

      ////////////////////////////////motion detector logic////////////////////////////////////////

      //this bit gives you the first mask for the motion detection

      for(int xm = 0;xm<in->GetNx();xm++)
      {
         for(int ym = 0;ym<in->GetNy();ym++)
         {

            if ((prev2mask->GetPixel(xm, ym)== 255 )&&(inmaskreverse->GetPixel(xm, ym)==255))
             {
                prev2mask->SetPixel(255, xm, ym);
            }
            else
                prev2mask->SetPixel(0, xm, ym);
         }
     }

      cout << "Timing point 2: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

    //////////motion detector mask adaptor/////////////////////////////////////////////////////////

      //this bit broadens and smooths the blobs in the mask

      bbcvp::Erode(*prev2mask, *prev4mask, 4);

      //prev4mask = image_broadener(prev2mask, prev4mask, in->GetNx(), in->GetNy(), 5, 240, 1);

      cout << "Timing point 3: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

      /////////////////motion detector blob detection///////////////////////////////////////////

      //This bit looks at the motion detection output and attempts to detect the correct blob of the diver

       bbcvp::Region *region = new bbcvp::Region[MAX_REGION];
       int indexes[MAX_REGION];

       Point searchRegionPoint1(0,0);
       Point searchRegionPoint2(lenX-1,lenY-1);

      //store the number of regions found
       int num_regions;


       objectDetection(prev2mask->GetElementPtr(0,0,0),
                       prev2map->GetElementPtr(0,0,0),
                       prev2map->GetNx(),
                       prev2map->GetNy(),
                       region,
                       &num_regions,
                       indexes,
                       searchRegionPoint1,
                       searchRegionPoint2,
                       false);

     //  sprintf(buf, "scalednew2/out/prev2map/%04d.tiff", (frame-2));
     //  bbcvp::WriteImage(*prev2map, buf);

    int tot_pix_in_regions = 0;

    cout << "Timing point 4: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

      //////////////////////hue statistic gathering for each motion detected blob////////////////////////////////////////////////////

   // this bit gathers statistics about each blob, including the proportion of flesh tones in each blob

    int biggestregion = 0;
    int biggestregionnumber = 0;
    int ind;
    int fleshproportion[num_regions];
    int fleshprop = 0;
    int fleshiness[num_regions];
    int saturation[num_regions];
    int fleshSD[num_regions];
    int av_red[num_regions];
    int av_blue[num_regions];
    int av_green[num_regions];

    for (ind=0; ind<num_regions; ind++)
    {
       fleshproportion[ind] = 0;
       fleshiness[ind] = 0;
       saturation[ind] = 0;
       fleshSD[ind] = 0;
    /*   av_red[ind] = 0;
       av_blue[ind] = 0;
       av_green[ind] = 0;*/
    }

    int huehistogram[360];

    //initialize huehistogram
    for (int k=0; k<360; k++)
                 {
                  // printf("*");
                   huehistogram[k] = 0;
                 }


    for (ind=0; ind<num_regions; ind++)
    {
        int i = indexes[ind];

      //What proportion of the pixels in this region are flesh tone?
          int ticker = 0;
          int fleshtot = 0;

          int totred = 0;
          int totblue = 0;
          int totgreen = 0;

                for(int xm = 0;xm<in->GetNx();xm++)
                  {
                     for(int ym = 0;ym<in->GetNy();ym++)
                     {
                         ////FIND THE HUE///

                         int sat = 0;
                         int h = 0;

                            if (prev2map->GetPixel(xm, ym) == i)
                            {
                                ticker +=1;
                                if (IsSkin_RGB(*col))
                                fleshtot +=1;

                                red = (prev2->GetPixel(xm, ym, 0));
                                green = (prev2->GetPixel(xm, ym, 1));
                                blue = (prev2->GetPixel(xm, ym, 2));

                                totred += red;
                                totblue += blue;
                                totgreen += green;

                               h = flesh_hue_finder(red, green, blue);
                               huehistogram[h] +=1;
                            }

                            if (ticker !=0 )
                            fleshprop = 100*fleshtot/ticker;
                       }
                    }

            /*        if (fleshtot !=0 )
                    {
                    av_red[i] += totred/fleshtot;
                    av_green[i] += totgreen/fleshtot;
                    av_blue[i] += totblue/fleshtot;
                    }*/

                    fleshproportion[i] = fleshprop;

                    if (region[i].getNumberPixels() > biggestregion)
                    {
                    biggestregion = region[i].getNumberPixels();
                    biggestregionnumber = i;
                    }

                    int largesthue = 0;
                    int largesthuenumber = 0;
                    int hueFWHMupper = 0;
                    int hueFWHMlower = 0;

                  for (int k=0; k<360; k++)
                    {
                        if (largesthue < huehistogram[k])
                            {
                            largesthue = huehistogram[k];
                            largesthuenumber = k;
                            }
                    }

                  fleshiness[i] = largesthuenumber;

                  for (int k=0; k<360; k++)
                    {
                        if (huehistogram[k] > largesthue/2)
                            {
                            hueFWHMupper = k;
                            }
                    }

                  for (int k=359; k=0; k--)
                    {
                        if (huehistogram[k] > largesthue/2)
                            {
                            hueFWHMlower = k;
                            }
                    }
                  if(hueFWHMupper-hueFWHMlower != 0)
                  fleshSD[i]=(hueFWHMupper-hueFWHMlower)/2;

                  for (int k=0; k<360; k++)
                         {
                         //  printf("*");
                           huehistogram[k] = 0;
                         }
     }

    int centre_x = (region[biggestregionnumber].getMaxX()+region[biggestregionnumber].getMinX())/2;
    int centre_y = (region[biggestregionnumber].getMaxY()+region[biggestregionnumber].getMinY())/2;

      for(int xm = 0;xm<in->GetNx();xm++)
      {
         for(int ym = 0;ym<in->GetNy();ym++)
         {
                  if ((num_regions > 1 && num_regions!=0 && prev2map->GetPixel(xm, ym) != biggestregionnumber))
                     {
                        prev4mask->SetPixel(0, xm, ym);
                     }
                    else
                     {
                        prev4mask->SetPixel(prev4mask->GetPixel(xm, ym), xm, ym);
                     }
         }
      }

      cout << "Timing point 5: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();


      /////////////this obtains the hue mask///////////////////////////////////////////////

      for(int xm = 0;xm<in->GetNx();xm++)
      {
         for(int ym = 0;ym<in->GetNy();ym++)
         {
             //What is the hue of each pixel?
             int h = 0;

            red = (prev2->GetPixel(xm, ym, 0));
            green = (prev2->GetPixel(xm, ym, 1));
            blue = (prev2->GetPixel(xm, ym, 2));

            col->blue = blue;
            col->green = green;
            col->red = red;

            h = flesh_hue_finder(red, green, blue);

            if (IsSkin_RGB(*col))
                   {
                if(h < fleshiness[biggestregionnumber]+fleshSD[biggestregionnumber]+1 &&
                   h > fleshiness[biggestregionnumber]-fleshSD[biggestregionnumber]-1
                   )
                        {
                            prev7mask->SetPixel(prev2->GetPixel(xm, ym, 0), xm,ym, 0);
                            prev7mask->SetPixel(prev2->GetPixel(xm, ym, 1), xm,ym, 1);
                            prev7mask->SetPixel(prev2->GetPixel(xm, ym, 2), xm,ym, 2);
                            huemask->SetPixel(255, xm, ym);
                        }
                    }
            else
            {
                prev7mask->SetPixel(0, xm, ym, 0);
                prev7mask->SetPixel(1, xm, ym, 1);
                prev7mask->SetPixel(2, xm, ym, 2);
                huemask->SetPixel(0, xm, ym);
            }
         }
     }

      cout << "Timing point 6: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

  //    sprintf(buf, "scalednew2/out/mask/%04d.tiff", (frame-2));
  //    bbcvp::WriteImage(*prev7mask, buf);

   //   sprintf(buf, "scalednew2/out/satmask/%04d.tiff", (frame-2));
   //   bbcvp::WriteImage(*satmask, buf);

      cout << "Timing point 7: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

    /////////this broadens the hue mask, filling in blanks////////////////////////////////

      prev5mask = image_broadener(huemask, prev5mask, in->GetNx(), in->GetNy(), 2, 100, 1);

   //   sprintf(buf, "scalednew2/out/huemask/%04d.tiff", (frame-2));
   //    bbcvp::WriteImage(*huemask, buf);

       cout << "Timing point 8: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

    ////////////////////////hue blob detection///////////////////////////////////////////

      //This bit looks at the flesh finder output and attempts to detect the correct blob of the diver

       bbcvp::Region *fleshregion = new bbcvp::Region[MAX_REGION];

       Point searchRegionPoint1a(0,0);
       Point searchRegionPoint2a(in->GetNx()-1,in->GetNy()-1);

      //store the number of regions found
       int number_regions;

       objectDetection(prev5mask->GetElementPtr(0,0,0),
                       huemap->GetElementPtr(0,0,0),
                       huemap->GetNx(),
                       huemap->GetNy(),
                       fleshregion,
                       &number_regions,
                       indexes,
                       searchRegionPoint1a,
                       searchRegionPoint2a,
                       false);

   //    sprintf(buf, "scalednew2/out/huemap/%04d.tiff", (frame-2));
   //    bbcvp::WriteImage(*huemap, buf);

       cout << "Timing point 9: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

       /////////////////////////////////////////////////////////////////////////

       ////Board detector/////

       int boardend = 0;
       int gapcounter = 0;
       int gapticker = 0;
       int gapsize = 0;


       for(int ym = 0;ym<in->GetNy();ym++)
       {
         for(int xm = 0;xm<in->GetNx();xm++)
         {
             if((prev2->GetPixel(xm, ym, 0) + prev2->GetPixel(xm, ym, 1) + prev2->GetPixel(xm, ym, 2))/3 < 30)
                 boardmask->SetPixel(255,xm, ym);
             else
                 boardmask->SetPixel(0,xm, ym);         
         }
      }

      int boardlevel = 0;
      int noOfBoardLevels = 0;
      for(int ym = 0;ym<in->GetNy();ym++)
      {
          int boardpc = 0;
         for(int xm = 0;xm<in->GetNx();xm++)
         {
             if (boardmask->GetPixel(xm, ym) == 255 &&
                 xm < in->GetNx()/2 &&
                 ym > 5*in->GetNy()/6)
             {
                 boardpc += 1;
             }
         }
         if (boardpc > in->GetNx()/3)
         {
             boardlevel += ym;
             noOfBoardLevels += 1;
         }
     }

      if (noOfBoardLevels > 0)
      {
          boardlevel = boardlevel/noOfBoardLevels;
      }
      else
      {
          boardlevel = 9*in->GetNy()/10;
      }

      for(int xm = 13;xm<in->GetNx()-14;xm++)
         {
          if (boardmask->GetPixel(xm, boardlevel) == 255 &&
              boardmask->GetPixel(xm-1, boardlevel) == 255 &&
              boardmask->GetPixel(xm-2, boardlevel) == 255 &&
              boardmask->GetPixel(xm-3, boardlevel) == 255 &&
              boardmask->GetPixel(xm-4, boardlevel) == 255 &&
              boardmask->GetPixel(xm-5, boardlevel) == 255 &&
              boardmask->GetPixel(xm-6, boardlevel) == 255 &&
              boardmask->GetPixel(xm-7, boardlevel) == 255 &&
              boardmask->GetPixel(xm-8, boardlevel) == 255 &&
              boardmask->GetPixel(xm-9, boardlevel) == 255 &&
              boardmask->GetPixel(xm-10, boardlevel) == 255 &&
              boardmask->GetPixel(xm-11, boardlevel) == 255 &&
              boardmask->GetPixel(xm-12, boardlevel) == 255 &&
              boardmask->GetPixel(xm-13, boardlevel) == 255 &&
              boardmask->GetPixel(xm+14, boardlevel) == 255 &&
              xm > boardend
              )
              boardend = xm;
          if (boardmask->GetPixel(xm, boardlevel) == 255)
              gapcounter +=1;
          else
          {
                  if (gapcounter > 70 &&
                      boardmask->GetPixel(xm+1, boardlevel) == 255 &&
                      boardmask->GetPixel(xm-1, boardlevel) == 255)
                  gapcounter +=1;
                  else if(gapcounter > 70 &&
                          boardmask->GetPixel(xm+1, boardlevel) == 0 &&
                          boardmask->GetPixel(xm-1, boardlevel) == 0 &&
                          gapticker != 0)
                  {
                      gapticker +=1;
                      gapsize += gapcounter;
                      gapcounter = 0;
                  }
                  else if(gapcounter > 70 &&
                          boardmask->GetPixel(xm+1, boardlevel) == 0 &&
                          boardmask->GetPixel(xm-1, boardlevel) == 0 &&
                          gapticker == 0)
                  {
                      gapticker +=1;
                      gapcounter = 0;
                  }
                  else if(gapcounter < 70 &&
                          boardmask->GetPixel(xm+1, boardlevel) == 0 &&
                          boardmask->GetPixel(xm-1, boardlevel) == 0)
                      gapcounter = 0;

          }
      }

      if (gapticker > 1)
      gapsize = gapsize/(gapticker-1);


      for(int ym = 0;ym<in->GetNy();ym++)
      {
         for(int xm = 0;xm<in->GetNx();xm++)
         {
             boardmask->SetPixel(128, boardend, ym);
         }
      }

    //  printf("\n Board End: %03d\n", boardend);

    //   sprintf(buf, "scalednew2/out/board/%04d.tiff", (frame-2));
    //   bbcvp::WriteImage(*boardmask, buf);

       cout << "Timing point 9: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

      //////////////////////////////////////////////////////////////////////////

   //   sprintf(buf, "scalednew2/out/huemask/%04d.tiff", (frame-2));
   //   bbcvp::WriteImage(*huemask, buf);

   /////////////this detects the edges of the hue mask//////////////////////////////////////

   greyscaleout3 = mask_differentiator(huemask, greyscaleout3, in->GetNx(), in->GetNy(), 2);
 //  sprintf(buf, "scalednew2/out/hueborder/%04d.tiff", (frame-2));
 //     bbcvp::WriteImage(*greyscaleout3, buf);

      //void ContourFollower::contourFollower::setImage(*huemask,1,1,new_x, new_y);

      sprintf(buf, "scalednew2/out/arsemask2/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*arsemask2, buf);

      sprintf(buf, "scalednew2/out/arsemask3/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*arsemask3, buf);

      cout << "Timing point 10: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

   /////////////////Logic for combining motion detector and hue masks////////////////////////////////////////

   int totalDiverPixels = 0.025*in->GetNx()*in->GetNy();
   int pixelcount = 0;
   int secondaryarea = 0;
   int primaryarea = 0;

   for (int ind=0; ind<number_regions; ind++)
     {
        int i = indexes[ind];
        if ((fleshregion[i].getMinX() + fleshregion[i].getMaxX())/2 < 3*in->GetNx()/5 &&
            (fleshregion[i].getMinX() + fleshregion[i].getMaxX())/2 > 2*in->GetNx()/5 &&
             fleshregion[i].getNumberPixels() > 300 &&
             fleshregion[i].getNumberPixels() > pixelcount &&
             fleshregion[i].getMinX() > in->GetNx()/5 &&
             fleshregion[i].getMaxX() < 4*in->GetNx()/5 &&
             fleshregion[i].getMinY() > in->GetNy()/8 &&
             fleshregion[i].getMaxY() < 7*in->GetNy()/8
            )
        {
            pixelcount = fleshregion[i].getNumberPixels();
            primaryarea = i;
        }
    }

    pixelcount = 0;

     for (int ind=0; ind<number_regions; ind++)
     {
        int i = indexes[ind];
        if ((fleshregion[i].getMinX() + fleshregion[i].getMaxX())/2 < 3*in->GetNx()/5 &&
            (fleshregion[i].getMinX() + fleshregion[i].getMaxX())/2 > 2*in->GetNx()/5 &&
             fleshregion[i].getNumberPixels() > 300 &&
             fleshregion[i].getNumberPixels() > pixelcount &&
             fleshregion[i].getMinX() > in->GetNx()/5 &&
             fleshregion[i].getMaxX() < 4*in->GetNx()/5 &&
             fleshregion[i].getMinY() > in->GetNy()/12 &&
             fleshregion[i].getMaxY() < 11*in->GetNy()/12 &&
             i != primaryarea
            )
        {
            pixelcount = fleshregion[i].getNumberPixels();
            secondaryarea = i;
        }
    }
      if (primaryarea==0)
       primaryarea=indexes[0];

   if (fleshregion[primaryarea].getNumberPixels() < totalDiverPixels && secondaryarea != 0)
   {
      for(int xm = 0;xm<in->GetNx();xm++)
      {
      for(int ym = 0;ym<in->GetNy();ym++)
          {
            if (huemap->GetPixel(xm, ym) == primaryarea ||
                huemap->GetPixel(xm, ym) == secondaryarea ||
                prev4mask->GetPixel(xm, ym) == 255

                )
            {
                 prev6mask->SetPixel(255, xm, ym);
            }

         else
            {
             prev6mask->SetPixel(0, xm, ym);
            }
         }
      }
   }
   else
   {
     for(int xm = 0;xm<in->GetNx();xm++)
      {
      for(int ym = 0;ym<in->GetNy();ym++)
         {
            if (prev4mask->GetPixel(xm, ym) == 255 ||
                huemap->GetPixel(xm, ym) == primaryarea
                )
            {
                 prev6mask->SetPixel(255, xm, ym);
            }

         else
            {
             prev6mask->SetPixel(0, xm, ym);
            }
         }
      }
   }

   cout << "Timing point 11: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

     /////////////////blob detection of diver///////////////////////////////////////////

      //This bit looks at the flesh finder output and attempts to detect the correct blob of the diver

       bbcvp::Region *diverregion = new bbcvp::Region[MAX_REGION];

       Point searchRegionPoint1b(0,0);
       Point searchRegionPoint2b(in->GetNx()-1,in->GetNy()-1);

      //store the number of regions found
       int numberof_regions;

       objectDetection(prev6mask->GetElementPtr(0,0,0),
                       divermap->GetElementPtr(0,0,0),
                       divermap->GetNx(),
                       divermap->GetNy(),
                       diverregion,
                       &numberof_regions,
                       indexes,
                       searchRegionPoint1b,
                       searchRegionPoint2b,
                       false);

   //    sprintf(buf, "scalednew2/out/divermap/%04d.tiff", (frame-2));
   //    bbcvp::WriteImage(*divermap, buf);



       int diverregionnumber = 0;
       int centredifference_min = 1000000;
       int centredifference_secondmin = 1000000;
       int diversecondregionnumber = 0;
       int diverpixelstotal = 0.04*in->GetNx()*in->GetNy();
       bool secondregion = 0;
       int divermaxX = 0;
       int divermaxY = 0;
       int diverminX = 0;
       int diverminY = 0;
       int seconddiversize = 0;

       if (jumpcounter == 0)
       {
       for (ind=0; ind<numberof_regions; ind++)
        {
            int i = indexes[ind];

            int region_centre_x = (diverregion[i].getMaxX()+diverregion[i].getMinX())/2;
            int region_centre_y = (diverregion[i].getMaxY()+diverregion[i].getMinY())/2;
            int centre_difference = (region_centre_x-centre_x)*(region_centre_x-centre_x)+(region_centre_y-centre_y)*(region_centre_y-centre_y);

            if (centre_difference < centredifference_min &&
                region_centre_x < 3*in->GetNx()/4 &&
                region_centre_x > in->GetNx()/4 &&
                region_centre_y < 3*in->GetNy()/4 &&
                region_centre_y > in->GetNy()/4 )
            {
            centredifference_min = centre_difference;
            diverregionnumber = i;
            diverpixelstotal = diverregion[diverregionnumber].getNumberPixels();
            }
        }
                divermaxX = diverregion[diverregionnumber].getMaxX();
                diverminX = diverregion[diverregionnumber].getMinX();
                divermaxY = diverregion[diverregionnumber].getMaxY();
                diverminY = diverregion[diverregionnumber].getMinY();
       }
       else
       {
        for (ind=0; ind<numberof_regions; ind++)
        {
            int i = indexes[ind];

            int region_centre_x = (diverregion[i].getMaxX()+diverregion[i].getMinX())/2;
            int region_centre_y = (diverregion[i].getMaxY()+diverregion[i].getMinY())/2;
            int centre_difference = (region_centre_x-centre_x)*(region_centre_x-centre_x)+(region_centre_y-centre_y)*(region_centre_y-centre_y);

            if (centre_difference < centredifference_min &&
                region_centre_x < 3*in->GetNx()/4 &&
                region_centre_x > in->GetNx()/4 &&
                region_centre_y < 3*in->GetNy()/4 &&
                region_centre_y > in->GetNy()/4 &&
                diverregion[i].getNumberPixels() > diverdata[0]/10 &&
                diverregion[i].getNumberPixels() < 15000 &&
                diverregion[i].getMaxX() < 5*in->GetNx()/6 &&
                diverregion[i].getMinX() > in->GetNx()/6 &&
                region_centre_x < diverdata[1] &&
                region_centre_x > diverdata[2] &&
                region_centre_y < diverdata[3] &&
                region_centre_y > diverdata[4] &&
                (diverregion[i].getMaxX() - diverregion[i].getMinX())/(diverregion[i].getMaxY()-diverregion[i].getMinY()) < ((diverdata[1] - diverdata[2])/(diverdata[3] - diverdata[4]) + 2) &&
                (diverregion[i].getMaxX() - diverregion[i].getMinX())/(diverregion[i].getMaxY()-diverregion[i].getMinY()) > ((diverdata[1] - diverdata[2])/(diverdata[3] - diverdata[4]) - 2)

                )
            {
            diversecondregionnumber =  diverregionnumber;
            centredifference_min = centredifference_secondmin;
            centredifference_min = centre_difference;
            diverregionnumber = i;
            divermaxX = diverregion[diverregionnumber].getMaxX();
            diverminX = diverregion[diverregionnumber].getMinX();
            divermaxY = diverregion[diverregionnumber].getMaxY();
            diverminY = diverregion[diverregionnumber].getMinY();
            }
        }

        for (ind=0; ind<numberof_regions; ind++)
        {
            int ii = indexes[ind];

            int region_centre_x = (diverregion[ii].getMaxX()+diverregion[ii].getMinX())/2;
            int region_centre_y = (diverregion[ii].getMaxY()+diverregion[ii].getMinY())/2;
            int centre_difference2 = (region_centre_x-centre_x)*(region_centre_x-centre_x)+(region_centre_y-centre_y)*(region_centre_y-centre_y);
            int pixelnumber = diverregion[ii].getNumberPixels();
            if (//centre_difference2 < centredifference_secondmin &&
                seconddiversize < pixelnumber &&
                 region_centre_x < diverdata[1] &&
                region_centre_x > diverdata[2] &&
                region_centre_y < diverdata[3] &&
                region_centre_y > diverdata[4] &&
                ii != diverregionnumber

                )
            {
            diversecondregionnumber = ii;
            seconddiversize = pixelnumber;
            }
        }

        if (diverregion[diverregionnumber].getNumberPixels() < diverdata[0]/1.15 && (diverregion[diverregionnumber].getNumberPixels()+diverregion[diversecondregionnumber].getNumberPixels())<1.5*diverdata[0])
        {
            diverpixelstotal = diverregion[diverregionnumber].getNumberPixels() + diverregion[diversecondregionnumber].getNumberPixels();
            secondregion = 1;
            if(diverregion[diversecondregionnumber].getMaxX()>divermaxX)
                divermaxX = diverregion[diversecondregionnumber].getMaxX();
            if(diverregion[diversecondregionnumber].getMinX()<diverminX)
                diverminX = diverregion[diversecondregionnumber].getMinX();
            if(diverregion[diversecondregionnumber].getMaxY()>divermaxY)
                divermaxY = diverregion[diversecondregionnumber].getMaxY();
            if(diverregion[diversecondregionnumber].getMinY()<diverminY)
                diverminY = diverregion[diversecondregionnumber].getMinY();
        }
        else
        {  diverpixelstotal = diverregion[diverregionnumber].getNumberPixels();  }
        }

       if (diverregionnumber != 0)
       {
       diverdata[0] = diverpixelstotal;
       diverdata[1] = divermaxX;
       diverdata[2] = diverminX;
       diverdata[3] = divermaxY;
       diverdata[4] = diverminY;
       }

       cout << "Timing point 12: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

      //////////////////////////////histogrammer bit////////////////////////////////////////////

   int outputr = 0;
   int outputb = 0;
   int outputx = 0;
   int poolhue = 0;
   //int huehistogram[360];
   int smallestrgb = 0;
   int largestrgb = 0;
   int totalnumberofpixels = (in->GetNx())*(in->GetNx());

   int *pixeldataarray = new int[totalnumberofpixels];
   int *temparrayseg = new int[in->GetNy()*in->GetNx()];

   // pixeldataarray is and array which can store data about each pixel
   for (int k=0; k<totalnumberofpixels; k++)
         {
         pixeldataarray[k] = 0;
         }

   for (int y=0; y<in->GetNy() ; y++)                         //
   {
       for (int x=0; x<in->GetNx() ; x++)                        //
       {
           poolhue = hue_finder(prev2->GetPixel(x, y, 0), prev2->GetPixel(x, y, 1), prev2->GetPixel(x, y, 2));
           pixeldataarray[x+y*in->GetNx()]=poolhue;
           huehistogram[poolhue] += 1;
       }
   }

   int largesthue = 0;
   int largesthuenumber = 0;
   int huemax = 0;
   int huemin = 0;
   cout << endl;
   cout << "POOL HISTOGRAM" << endl;
   for (int k=0; k<360; k++)
   {

       cout << huehistogram[k] << endl;

        if (largesthue < huehistogram[k])
           {
            largesthue = huehistogram[k];
            largesthuenumber = k;
           }
   }
   cout << endl;

   for (int k=largesthuenumber; k<largesthuenumber+30; k++)
   {
        if (huehistogram[k]>huehistogram[k+1]+100)
           {
            huemax = k;
           }
   }

   for (int k=largesthuenumber-30; k<largesthuenumber; k++)
   {
        if (huehistogram[k]+100>huehistogram[k+1])
           {
            huemin = k;
           }
   }

   int blueness[in->GetNy()];

   for (int k=0; k<in->GetNy(); k++)
        {
         blueness[k] = 0;
        }

   for (int y=0; y<in->GetNy() ; y++)                         //
   {
       for (int x=0; x<in->GetNx() ; x++)                        //
       {
           int m = pixeldataarray[x+y*in->GetNx()];
           if (m>huemin && m<huemax)  // (h>0 && h<50)
               {
               blueness[y] += 1;//greyscale.GetElement(x,y);
               }
       }
   }

   //printf("hue  %3d, huemax  %3d, huemin  %3d\n", largesthuenumber, huemax, huemin);


   cout << "Timing point 13: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

   ///////////////////////////Logic for printing final segmented diver picture//////////////////////////

   int corrector = 50*(40-frameNumber);
  // printf("\n corrector: %03d\n", corrector);

    for(int ym = 0;ym<in->GetNy();ym++)
      {
       //poolpc gives you the percentage of pixels in a line [y] containing the swimming pool
       int poolpc = 100*blueness[ym]/in->GetNx();
       //printf("poolpc %3d\n", poolpc);
       if (poolpc < 85)
        {
        for(int xm = 0;xm<in->GetNx();xm++)
          {
                if (jumpcounter == 0)
                {
                    if (prev6mask->GetPixel(xm, ym) == 255 &&
                        xm > in->GetNx()/12 &&
                        xm < 11*in->GetNx()/12 &&
                        ym > in->GetNy()/12 &&
                        ym < 11*in->GetNy()/12 )
                     {
                     prev3mask->SetPixel((prev2->GetPixel(xm, ym, 0)), xm, ym, 0);
                     prev3mask->SetPixel((prev2->GetPixel(xm, ym, 1)), xm, ym, 1);
                     prev3mask->SetPixel((prev2->GetPixel(xm, ym, 2)), xm, ym, 2);
                     arsemask5->SetPixel(255, xm, ym);
                     footdataarray[frameNumber] = ym;
                     }
                    else
                    {
                    prev3mask->SetPixel(0, xm, ym, 0);
                    prev3mask->SetPixel(0, xm, ym, 1);
                    prev3mask->SetPixel(0, xm, ym, 2);
                    arsemask5->SetPixel(0, xm, ym);
                    }
                }
                else
                {
                    if ((divermap->GetPixel(xm, ym) == diverregionnumber ||
                        (secondregion == 1 && diversecondregionnumber != 0 && divermap->GetPixel(xm, ym) == diversecondregionnumber)) &&
                        diverregionnumber != 0 &&

                        ym > in->GetNy()/8 &&
                        xm > in->GetNx()/12 &&
                        xm < 11*in->GetNx()/12 &&
                        ym > in->GetNy()/12 &&
                        ym < 11*in->GetNy()/12
                        )
                    {
                        if(
                        prev5mask->GetPixel(xm, ym) == 0 ||
                  (pixeldataarray[xm+ym*in->GetNx()] < 300 &&
                    pixeldataarray[xm+ym*in->GetNx()] > 60)
                            )
                        {
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 0)), xm, ym, 0);
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 1)), xm, ym, 1);
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 2)), xm, ym, 2);
                         arsemask5->SetPixel(255, xm, ym);
                         footdataarray[frameNumber] = ym;
                        }
                        else
                        {
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 0)), xm, ym, 0);
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 1)), xm, ym, 1);
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 2)), xm, ym, 2);
                         arsemask5->SetPixel(255, xm, ym);
                         footdataarray[frameNumber] = ym;
                        }
                    }
                    else if (jumpcounter == 1  && prev4mask->GetPixel(xm, ym) == 255 &&
                             xm > in->GetNx()/12 &&
                        xm < 11*in->GetNx()/12 &&
                        ym > in->GetNy()/12 &&
                        ym < 11*in->GetNy()/12
                             )
                    {
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 0)), xm, ym, 0);
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 1)), xm, ym, 1);
                         prev3mask->SetPixel((prev2->GetPixel(xm, ym, 2)), xm, ym, 2);
                         arsemask5->SetPixel(255, xm, ym);
                         footdataarray[frameNumber] = ym;
                    }

                    else
                    {
                        if(frameNumber<41)
                        {

                            
                         prev3mask->SetPixel(((prev2->GetPixel(xm, ym, 0))*corrector/1000), xm, ym, 0);
                         prev3mask->SetPixel(((prev2->GetPixel(xm, ym, 1))*corrector/1000), xm, ym, 1);
                         prev3mask->SetPixel(((prev2->GetPixel(xm, ym, 2))*corrector/1000), xm, ym, 2);
                         arsemask5->SetPixel(0, xm, ym);
                        }
                        else
                        {
                         prev3mask->SetPixel(0, xm, ym, 0);
                         prev3mask->SetPixel(0, xm, ym, 1);
                         prev3mask->SetPixel(0, xm, ym, 2);
                         arsemask5->SetPixel(0, xm, ym);
                        }
                    }
             }
          }
       }
       else
          for(int xm = 0;xm<in->GetNx();xm++)
          {
           if ((pixeldataarray[xm+ym*in->GetNx()] < huemax &&
               pixeldataarray[xm+ym*in->GetNx()] > huemin) ||
               prev6mask->GetPixel(xm, ym) != 255
               )
                {
                 prev3mask->SetPixel(0, xm, ym, 0);
                 prev3mask->SetPixel(0, xm, ym, 1);
                 prev3mask->SetPixel(0, xm, ym, 2);
                 arsemask5->SetPixel(0, xm, ym);
                }
           else
                    {
                     prev3mask->SetPixel((prev2->GetPixel(xm, ym, 0)), xm, ym, 0);
                     prev3mask->SetPixel((prev2->GetPixel(xm, ym, 1)), xm, ym, 1);
                     prev3mask->SetPixel((prev2->GetPixel(xm, ym, 2)), xm, ym, 2);
                     arsemask5->SetPixel(255, xm, ym);
                    }
           }

      }

    cout << "Timing point 14: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

//*picturemaskarray[frame-2] = *arsemask5;


delete pixeldataarray;
delete temparrayseg;

int maxfoot = 0;
int maxFootFrameNumber = 0;
int maxFootFrameNumber2 = 0;
int footDifference = new_x;

for (int i = 0; i < 200; i++)
{
    if(footdataarray[i]>maxfoot)
    {
        maxfoot =  footdataarray[i];
        maxFootFrameNumber = i;
    }
    if(footdataarray[i]<maxfoot)
    {
        maxfoot = 0;
    }
}

int maxFootX = 0;

for(int ym = 0;ym<in->GetNy();ym++)
      {
         for(int xm = 0;xm<in->GetNx();xm++)
          {
             if(prev6mask->GetPixel(xm, ym) == 255 &&
                ym > 3*in->GetNy()/4 &&
                xm > maxFootX)
             { maxFootX = xm; }
         }
     }

maxFootXarray[frameNumber] = maxFootX;

for (int i = 0; i < 200; i++)
{
    if(sqrt((maxFootXarray[i] - boardend)*(maxFootXarray[i] - boardend)) < footDifference && maxFootXarray[i] > 0)
    {
        footDifference =  sqrt((maxFootXarray[i] - boardend)*(maxFootXarray[i] - boardend));
        maxFootFrameNumber2 = i;    
    }
   // cout << maxFootXarray[i] << endl;
}


////////////////////TRIGGERING LOGIC & STATEMENTS///////////////////////////////////////////////////////

/*
cout << "boardend " << boardend << endl;
cout << "maxFootFrameNumber " << maxFootXarray[frameNumber] << endl;
cout << "foot difference " << footDifference << endl;
cout << "this difference " << sqrt((maxFootXarray[frameNumber] - boardend)*(maxFootXarray[frameNumber] - boardend)) << endl;
*/

int trigger =  para.trigger;

if((trigger == 1 &&
   footdataarray[maxFootFrameNumber]>footdataarray[frameNumber] &&
   maxFootFrameNumber + 1 == frameNumber &&
   boardend < 2*in->GetNx()/3 &&
   maxFootX-boardend > 0 &&
   maxFootX-boardend < 60 &&
   jumpcounter == 0) ||

   (trigger == 2 &&
   100*region[biggestregionnumber].getNumberPixels()/new_x/new_y > 1&&
   jumpcounter == 0) ||

   (trigger == 3 &&
   (sqrt((maxFootXarray[frameNumber-1] - boardend)*(maxFootXarray[frameNumber-1] - boardend)) == footDifference &&
   sqrt((maxFootXarray[frameNumber] - boardend)*(maxFootXarray[frameNumber] - boardend)) > frameNumber &&
   maxFootXarray[frameNumber] !=0 &&
   frameNumber > 10 &&
   jumpcounter == 0)))

{
    jumpcounter += 1;
    jumpFrameNumber = frame;
    boardEndAtJumpFrameNumber = boardend;
    boardLevelAtJumpFrameNumber = boardlevel;

    gapsize_final = gapsize;

    myPoseEst->getCamFOV(&fovy, lenYFullFrameField, 0);
/*
      cout << endl;
      cout << "****************************************************************" << endl;
      cout << endl;
      cout << "field of view " << fovy << endl;
      cout << endl;
      cout << "****************************************************************" << endl;
      cout << endl;

      cout << endl;
      cout << "****************************************************************" << endl;
      cout << endl;
      cout << "field of view " << fovy << endl;
      cout << endl;
      cout << "****************************************************************" << endl;
      cout << endl;

      cout << endl;
      cout << "****************************************************************" << endl;
      cout << endl;
      cout << "SCALING FACTOR " << gapsize_final << endl;
      cout << endl;
      cout << "****************************************************************" << endl;
      cout << endl;
*/

    for(int ym = 0;ym<in->GetNy();ym++)
      {
         for(int xm = 0;xm<in->GetNx();xm++)
          {
                     prev3mask->SetPixel(255, xm, ym, 0);
                     prev3mask->SetPixel(0, xm, ym, 1);
                     prev3mask->SetPixel(0, xm, ym, 2);
          }
     }
}



//printf("\nYMAX: %03d   FRAME: %03d   Boardend: %03d   maxFootX: %03d\n", maxfoot, maxFootFrameNumber, boardend, maxFootX);


cout << "Timing point 15: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();


           //*********************ARSE DETECTION***********************************//////////////

             for(int ym = 0;ym<in->GetNy();ym++)
              {
                 for(int xm = 0;xm<in->GetNx();xm++)
                  {
               //      arsemask->SetPixel(prev5mask->GetPixel(xm,ym), xm, ym);
                    if(arsemask5->GetPixel(xm, ym) == 255 && prev5mask->GetPixel(xm,ym) == 0 && greyscaleout3->GetPixel(xm,ym) != 0 && prev2->GetPixel(xm, ym, 0)+prev2->GetPixel(xm, ym, 2)+prev2->GetPixel(xm, ym, 2)<180)
                     {
                        arsemask->SetPixel(255, xm, ym);
                    }
                    else
                    {
                        arsemask->SetPixel(0, xm, ym);
                    }
                }
             }

      //////BROADEN ARSE

      arsemask2 = image_broadener(arsemask, arsemask2, in->GetNx(), in->GetNy(), 2, 100, 1);

      //////DETECT ARSE BLOBS

      bbcvp::Region *arseregion = new bbcvp::Region[MAX_REGION];

       Point searchRegionPoint1c(0,0);
       Point searchRegionPoint2c(in->GetNx()-1,in->GetNy()-1);

      //store the number of regions found
       int nof_regions;

       objectDetection(arsemask2->GetElementPtr(0,0,0),
                       arsemap->GetElementPtr(0,0,0),
                       arsemap->GetNx(),
                       arsemap->GetNy(),
                       arseregion,
                       &nof_regions,
                       indexes,
                       searchRegionPoint1c,
                       searchRegionPoint2c,
                       false);

       int arsearray_x[nof_regions];
       int arsearray_y[nof_regions];

       for (ind=0; ind<nof_regions; ind++)
        {
           arsearray_x[ind] = 0;
           arsearray_y[ind] = 0;
        }

       for (ind=0; ind<nof_regions; ind++)
        {
            int i = indexes[ind];

            arsearray_x[i] = (arseregion[i].getMaxX()+arseregion[i].getMinX())/2;
            arsearray_y[i] = (arseregion[i].getMaxY()+arseregion[i].getMinY())/2;
        }






     ///////////////////////////////StroMotion////////////////////////////////////////////

       int arsechoice = 0;
       double nx = 0;
       double ny = 0;
       double worldarseX = 0;
       double worldarseY = 0;
       double worldarseZ = 0;
       double prev_arse_worldX = 0;
       double prev_arse_worldY = 0;
       double prev_arse_worldZ = 0;

     //++++++++++++++++++++++++++++++ARSE++++++++++++++++++++++++++++++++++++++++++++++++
      int mode = 2;

      if (mode == 2)
      {

          cout << "Timing point 16: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

           //Get pose, this should be outside the loop.
         double pos_x, pos_y, pos_z;
         myPoseEst->getCamPos(&pos_x, &pos_y, &pos_z);
     //    printf("**************************** %f %f %f\n", pos_x, pos_y, pos_z);

         //Find the location in work terms of the centre of the image
         double pixelPosX = lenX/2;
         double pixelPosY = lenY/2;
         double wxl, wyl, wzl;
         myPoseEst->lineOfSight(pixelPosX, pixelPosY, &wxl, &wyl, &wzl);
     //    printf("**************************** %f %f\n", pixelPosX, pixelPosY);
     //    printf("**************************** %f %f %f\n", wxl, wyl, wzl);


        ///////////////////////////////////////////////////////////////////////////////////////////////////////////////

         destinationPose->setPlane(2, -1);

         startPose->setPlane(2, -1);

         double worldX, worldY, worldZ, CoM_X, CoM_Y;



         //double nx, ny;

         int captureFrame; // = 40;
         if ((frame-200) > 40)
         {
            captureFrame = (int)(floor((frame-200)/40)*40);
         }
       //  printf("------------captureFrame: %d (%d)\n", captureFrame, frame);
         for(captureFrame = frame; captureFrame<=frame; captureFrame=captureFrame+1)
         {
         //int captureFrame = frame - 40;
            if ((pixelPosX > 0)&&(pixelPosY>0) && jumpcounter ==1 && jumpFrameNumber !=0)
            {
      //         printf("PROJECTING!!!!!!!!!!!!!!!!!!!!!!!!!\n");

               //--- Read in the files and the cam file
               char camFileName[50];
                sprintf(camFileName, "scalednew2/out/cams/%05d.cam", (captureFrame - jumpFrameNumber));


                startPose->setPoseFromCam(camFileName);
               //Lets read in the appropriate frame from file
               //POSSIBLE DEVELOPMENT: instead of reading in from file, we could perhaps have the image held in memory
               sprintf(buf, "scalednew2/out/cross/0000.tiff", (captureFrame-jumpFrameNumber));
               bbcvp::ReadImage(*capturedImage, buf);


               //Because we're reading in the original image we also need to read in the mask
               //POSSIBLE DEVELOPMENT: we should instead be using the segmented image and, as above, have it stored in memory.
               sprintf(buf, "scalednew2/out/crossmask/0000.tiff", (captureFrame-2- jumpFrameNumber));
               bbcvp::ReadImage(*capturedImageMask, buf);
               //--- Finish reading in files and the cam file - this could perhaps be done as one but process at the start?


               //Run through all pixels and copy them as appropriate
      /*         for(int xm = 0;xm<in->GetNx();xm++)
               {
                  for(int ym = 0;ym<in->GetNy();ym++)
                  {
                      if (capturedImageMask->GetPixel((int)xm, (int)ym) > 0)
                      {
                             //if suitable pixel

                             double xscalefactor = 0;
                             double yscalefactor = 0;
/*
                             startPose->lineOfSightWorld(lenX/2, lenY/2, &worldX, &worldY, &worldZ);
                             CoM_X -= 76.41117 + (101.3111-76.41117)*(frame-69)/44;//worldY;
                             CoM_Y -= 22.0615 + (2.94*(frame-69)/25 -4.9*(frame-69)*(frame-69)/625)*6.67683;
                             destinationPose->worldToPixel(worldX, worldY, worldZ, &xscalefactor, &yscalefactor);

                             int arse_difference = (arse_centre_x-centre_x)*(region_centre_x-centre_x)+(region_centre_y-centre_y)*(region_centre_y-centre_y);

                             cout << "SCALEFACTOR x " << xscalefactor << endl;
                             cout << "SCALEFACTOR y " << yscalefactor << endl;

                             int newxm = xm + (diverregion[diverregionnumber].getMaxX() + diverregion[diverregionnumber].getMinX())/2 - lenX/2;// +  shiftX;//*(int)othercameradata[5]/gapsize_final ;
                             int newym = ym + (diverregion[diverregionnumber].getMaxY() + diverregion[diverregionnumber].getMinY())/2 - lenY/2;// +  shiftY;//*(int)othercameradata[5]/gapsize_final ;

                             //Project to real world
                             startPose->lineOfSightWorld(newxm, newym, &worldX, &worldY, &worldZ);

                             worldXarray[frame] = worldX;//76.41117 + (101.3111-76.41117)*(frame-69)/44;//worldY;//array[frame]
                             worldYarray[frame] = worldY;//22.0615 + (2.94*(frame-69)/25 -4.9*(frame-69)*(frame-69)/625)*6.67683;//worldX;
                             worldZarray[frame] = worldZ;
//                             cout << "worldX " << worldX << endl;
  //                           cout << "worldY " << worldY<< endl;
    //                           cout << "worldZ " << worldZ<< endl;

                             //project back from real word to camera image
                             destinationPose->worldToPixel(worldXarray[frame], worldYarray[frame], worldZarray[frame], &nx, &ny);
/*
                             if (nx != -1 && ny != -1)
                             {
                             cout << "nx " << nx << endl;
                             cout << "ny " << ny << endl;
                         }

                             //Make sure we haven't shifted off the image
                             //Only look at pixels inside the mask (again, this would be better done my using a segmented image)
                             //Use the prev2mask to make sure the current image of the diver stays "on top"
                             //We probably want it to be semi-transparent and with soft edges, again it would be better if these could be implied in the segmented image.
                             if ((nx>0)&&(ny>0)&&(nx<lenX)&&(ny<lenY))
                             {
                             prev2->SetPixel(255, (int)nx, (int)ny, 0);
                             prev2->SetPixel(255, (int)nx, (int)ny, 1);
                             prev2->SetPixel(0, (int)nx, (int)ny, 2);
                             }
                            /*if ((nx>50)&&(ny>50)&&(nx<lenX-50)&&(ny<lenY-50))//&&(prev2mask->GetPixel((int)nx, (int)ny)!=255))
                        {           
                        prev2->SetPixel(((((255-(capturedImageMask->GetPixel((int)nx, (int)ny)))*(prev2->GetPixel(xm, ym, 0))) + (capturedImageMask->GetPixel((int)nx, (int)ny)*(capturedImage->GetPixel((int)nx, (int)ny, 0))))/255), xm, ym, 0);
                        prev2->SetPixel(((((255-(capturedImageMask->GetPixel((int)nx, (int)ny)))*(prev2->GetPixel(xm, ym, 1))) + (capturedImageMask->GetPixel((int)nx, (int)ny)*(capturedImage->GetPixel((int)nx, (int)ny, 1))))/255), xm, ym, 1);
                        prev2->SetPixel(((((255-(capturedImageMask->GetPixel((int)nx, (int)ny)))*(prev2->GetPixel(xm, ym, 2))) + (capturedImageMask->GetPixel((int)nx, (int)ny)*(capturedImage->GetPixel((int)nx, (int)ny, 2))))/255), xm, ym, 2);
                        }
                    }
                  }
               }
      */

               double arseDifference = 1000000;




               if(prev_arse_x != 0 && prev_arse_y != 0)
               {
                             startPose->lineOfSightWorld(prev_arse_x, prev_arse_y, &prev_arse_worldX, &prev_arse_worldY, &prev_arse_worldZ);
                             cout << "World FINAL X " << prev_arse_worldX << endl;
                             cout << "World FINAL Y " << prev_arse_worldY << endl;
                             cout << "FRAME " << frame << endl;
               }



               for (ind=0; ind<nof_regions; ind++)
               {
              int i = indexes[ind];




                             //Project to real world
                             startPose->lineOfSightWorld(arsearray_x[i], arsearray_y[i], &worldX, &worldY, &worldZ);



                             double properx = 65.516 + (80.6563-65.516)*(frame-69)/44;
                             double propery = 12.7337 + (2.94*(frame-69)/25 -4.9*(frame-69)*(frame-69)/625)*47/6.85;
                            // cout << "properx" << properx << endl;

                             realworldx[frame] = (properx-65.516)/47*6.85;
                             realworldy[frame] = (propery-12.7337)/47*6.85;

                             destinationPose->worldToPixel(properx, propery, worldZ, &nx, &ny);

                         //    cout << "World Z " << worldZ << " versus nowt" <<endl;

                             worldXarray[frame] = properx;//-properx;//array[frame]
                             worldYarray[frame] = propery;//-propery;
                             worldZarray[frame] = worldZ;

                             double diffo = 0;
                             if (prev_arse_x == 0 && prev_arse_y == 0)
                             {
                             diffo = sqrt((worldXarray[frame]-worldX)*(worldXarray[frame]-worldX)+(worldYarray[frame]-worldY)*(worldYarray[frame]-worldY));
                             }
                             else
                             {
                             diffo = sqrt((worldXarray[frame]-worldX)*(worldXarray[frame]-worldX)+(worldYarray[frame]-worldY)*(worldYarray[frame]-worldY)+(worldX-prev_arse_worldX)*(worldX-prev_arse_worldX)+(worldY-prev_arse_worldY)*(worldY-prev_arse_worldY));
                             }

                             cout << "Ind " << ind << " i " << i << " World X " << worldX << " versus " << properx << " difference " << diffo << endl;
                             cout << "Ind " << ind << " i " << i << " World Y " << worldY << " versus " << propery << " difference " << diffo << endl;

                             if (diffo < arseDifference && arseregion[i].getNumberPixels()>5 && arseregion[i].getNumberPixels()< 1000)
                             {
                                 arsechoice = i;
                                 arseDifference = diffo;
                             }

                  }
               }
            }                  
         }



      for (int i = jumpFrameNumber ; i < frame + 1 ; i++)
      {
          double xx, yy = 0;
          destinationPose->worldToPixel(worldXarray[i], worldYarray[i], worldZarray[i], &xx, &yy);
          parabola_array_x[i] = xx;
          parabola_array_y[i] = yy;
      }

      for (int i = 0 ; i < frame + 1 ; i++)
      {
      cout << "parabola_array_x[i]" << parabola_array_x[i] << endl;
      cout << "parabola_array_y[i]" << parabola_array_y[i] << endl;
      }
      cout << endl;

      cout << "realworldx[frame]" << realworldx[frame] << endl;

      for (int i = 0; i < 200 ; i++)
     {
         cout << "Frame[" << i << "] x,y = " << realworldx[i] << "," << realworldy[i] << endl;
     }

      prev_arse_x = arsearray_x[arsechoice];
      prev_arse_y = arsearray_y[arsechoice];

      if(prev_arse_x != 0 && prev_arse_y != 0)
               {
                             startPose->lineOfSightWorld(prev_arse_x, prev_arse_y, &prev_arse_worldX, &prev_arse_worldY, &prev_arse_worldZ);
                             cout << "World FINAL X " << prev_arse_worldX << endl;
                             cout << "World FINAL Y " << prev_arse_worldY << endl;
               }


      cout << " I AM PRINTING ZONE: " << arsechoice << endl;

            for(int ym = 0;ym<in->GetNy();ym++)
              {
                 for(int xm = 0;xm<in->GetNx();xm++)
                  {
               //      arsemask->SetPixel(prev5mask->GetPixel(xm,ym), xm, ym);
                    if(arsemap->GetPixel(xm, ym) == arsechoice)
                    {
                        prev2->SetPixel(255, xm, ym, 0);
                        prev2->SetPixel(0, xm, ym, 1);
                        prev2->SetPixel(0, xm, ym, 2);
                    }
                 /*   if(arsemask2->GetPixel(xm, ym) == 0)
                    {
                     prev2->SetPixel(prev2->GetPixel(xm, ym ,0)/2, xm, ym, 0);
                     prev2->SetPixel(prev2->GetPixel(xm, ym, 1)/2, xm, ym, 1);
                     prev2->SetPixel(prev2->GetPixel(xm, ym, 2)/2, xm, ym, 2);
                    }*/
                    for (int i = jumpFrameNumber + 1; i < frame + 1 ; i++)
                    {
                        double m = (parabola_array_y[i]-parabola_array_y[i-1])/(parabola_array_x[i]-parabola_array_x[i-1]);
                        double c = parabola_array_y[i] - m*parabola_array_x[i];
                        int x_max, x_min, y_max, y_min = 0;
                        if (parabola_array_x[i] > parabola_array_x[i-1])
                        {
                            x_max = parabola_array_x[i];
                            x_min = parabola_array_x[i-1];
                        }
                        else
                        {
                            x_max = parabola_array_x[i-1];
                            x_min = parabola_array_x[i];
                        }
                        if (parabola_array_y[i] > parabola_array_y[i-1])
                        {
                            y_max = parabola_array_y[i];
                            y_min = parabola_array_y[i-1];
                        }
                        else
                        {
                            y_max = parabola_array_y[i-1];
                            y_min = parabola_array_y[i];
                        }
                    if(((xm < ((int)parabola_array_x[i]+3) && ym < ((int)parabola_array_y[i]+3) && xm > ((int)parabola_array_x[i]-3) && ym > ((int)parabola_array_y[i] - 3))
                        || ((sqrt((ym - int(m*xm + c))*(ym - int(m*xm + c)) + (xm - (int)(ym -c)/m)*(xm - (int)(ym -c)/m)) <= 8 )
                            && xm < x_max && xm > x_min && ym > y_min && ym < y_max && (int)parabola_array_x[i] > 0
                            && (int)parabola_array_y[i] > 0 && (int)parabola_array_x[i-1] > 0 && (int)parabola_array_y[i-1] > 0)) && arsemask5->GetPixel(xm, ym) == 0)
                    {
                     prev2->SetPixel(255, xm, ym, 0);
                     prev2->SetPixel(255, xm, ym, 1);
                     prev2->SetPixel(0, xm, ym, 2);
                    }

                    }
                }
             }



      cout << " init x " << worldXarray[78] << endl;
      cout << " init y " << worldYarray[78] << endl;
      cout << " final x " << worldXarray[122] << endl;
      cout << " final y " << worldYarray[122] << endl;
      cout << " mid x " << worldXarray[116] << endl;
      cout << " mid y " << worldYarray[116] << endl;


      cout << "***************************"<< endl;
   /*   if(jumpFrameNumber !=0)
      {
      for (int captureFrame = jumpFrameNumber; captureFrame<=frame; captureFrame=captureFrame+1)
      {
          cout << "coord[ " << captureFrame << "] = " << worldXarray[captureFrame] << "," << worldYarray[captureFrame] << endl;
      }
      cout << "***************************"<< endl;
      }
*/
      cout << "Timing point 17: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();



//++++++++++++++++++++++++++++++++++KNEE++++++++++++++++++++++++++++++++++++++++++++

     if (frame == 69)
     {
          int kneecounter = 0;
          for (int xm = (int)arsearray_x[arsechoice]-65; xm < (int)arsearray_x[arsechoice]+ 61; xm++)
          {
              for (int ym = (int)arsearray_y[arsechoice]; ym < (int)arsearray_y[arsechoice]+ 61; ym++)
              {
                  if (sqrt((xm-arsearray_x[arsechoice])*(xm-arsearray_x[arsechoice])+(ym-arsearray_y[arsechoice])*(ym-arsearray_y[arsechoice])) < 58
                      && sqrt((xm-arsearray_x[arsechoice])*(xm-arsearray_x[arsechoice])+(ym-arsearray_y[arsechoice])*(ym-arsearray_y[arsechoice])) > 55
                      && arsemask5->GetPixel(xm, ym) == 255
                      && prev5mask->GetPixel(xm, ym) == 255)
                  {

                      prev_knee_x += xm;
                      prev_knee_y += ym;
                      kneecounter += 1;


                      cout << "xm,ym " << xm << "," << ym << endl;

                  }
              }
          }
          prev_knee_x /= kneecounter;
          prev_knee_y /= kneecounter;

          double kneeworldX = 0;
          double kneeworldY = 0;
          double kneeworldZ = 0;

          startPose->lineOfSightWorld(prev_knee_x, prev_knee_y, &kneeworldX, &kneeworldY, &kneeworldZ);
          kneelength = sqrt((prev_arse_worldX-kneeworldX)*(prev_arse_worldX-kneeworldX)+(prev_arse_worldY-kneeworldY)*(prev_arse_worldY-kneeworldY));

          prev_knee_worldX = kneeworldX;
          prev_knee_worldY = kneeworldY;
          prev_knee_worldZ = kneeworldZ;

          cout << "prev_knee_x,prev_knee_y " << prev_knee_x << "," << prev_knee_y << endl;

          for (int i = prev_knee_x - 2; i <= prev_knee_x + 2; i++)
                      {
                          for (int j = prev_knee_y - 2; j <= prev_knee_y + 2; j++)
                          {
                          prev2->SetPixel(0, i, j, 0);
                          prev2->SetPixel(255, i, j, 1);
                          prev2->SetPixel(0, i, j, 2);
                          }
                      }
     }

     if (frame > 69)
     {
          int kneedistance = 100000;
          double knee_x_holder = 0;
          double knee_y_holder = 0;

          double kneeworldX = prev_arse_worldX + kneelength;

          destinationPose->worldToPixel(kneeworldX, prev_arse_worldY, prev_arse_worldZ, &knee_x_holder, &knee_y_holder);


          int kneeradius =  sqrt(((int)knee_x_holder-prev_arse_x)*((int)knee_x_holder-prev_arse_x)+((int)knee_y_holder-prev_arse_y)*((int)knee_y_holder-prev_arse_y));



          for (int xm = (int)arsearray_x[arsechoice]-kneeradius-2; xm < (int)arsearray_x[arsechoice]+ kneeradius + 3; xm++)
          {
              for (int ym = (int)arsearray_y[arsechoice]-kneeradius -2; ym < (int)arsearray_y[arsechoice]+ kneeradius + 3; ym++)
              {
                  if (sqrt((xm-arsearray_x[arsechoice])*(xm-arsearray_x[arsechoice])+(ym-arsearray_y[arsechoice])*(ym-arsearray_y[arsechoice])) < kneeradius + 2
                      && sqrt((xm-arsearray_x[arsechoice])*(xm-arsearray_x[arsechoice])+(ym-arsearray_y[arsechoice])*(ym-arsearray_y[arsechoice])) > kneeradius - 2
                      && arsemask5->GetPixel(xm, ym) == 255
                      && prev5mask->GetPixel(xm, ym) == 255
                      )
                  {
                      prev2->SetPixel(0, xm, ym, 0);
                      prev2->SetPixel(255, xm, ym, 1);
                      prev2->SetPixel(0, xm, ym, 2);
                      kneemask->SetPixel(255,xm,ym);



                      if(sqrt((xm-prev_knee_x)*(xm-prev_knee_x)+(ym-prev_knee_y)*(ym-prev_knee_y))<kneedistance)
                      {
                          kneedistance = sqrt((xm-prev_knee_x)*(xm-prev_knee_x)+(ym-prev_knee_y)*(ym-prev_knee_y));
                          knee_x_holder = xm;
                          knee_y_holder = ym;
                      }


                      cout << "xm,ym " << xm << "," << ym << endl;

                  }
                  else
                  {
                      kneemask->SetPixel(0,xm,ym);
                  }
              }
          }
          if(knee_x_holder !=0 || knee_y_holder !=0)
          {
          prev_knee_x = knee_x_holder;
          prev_knee_y = knee_y_holder;
          }

          startPose->lineOfSightWorld(prev_knee_x, prev_knee_y, &prev_knee_worldX, &prev_knee_worldY, &prev_knee_worldZ);


          cout << "prev_knee_x,prev_knee_y " << prev_knee_x << "," << prev_knee_y << endl;

          for (int i = prev_knee_x - 2; i <= prev_knee_x + 2; i++)
                      {
                          for (int j = prev_knee_y - 2; j <= prev_knee_y + 2; j++)
                          {
                          prev2->SetPixel(255, i, j, 0);
                          prev2->SetPixel(255, i, j, 1);
                          prev2->SetPixel(255, i, j, 2);
                          }
                      }
     }

       bbcvp::Region *kneeregion = new bbcvp::Region[MAX_REGION];

       Point searchRegionPoint1d(0,0);
       Point searchRegionPoint2d(in->GetNx()-1,in->GetNy()-1);

      //store the number of regions found
       int knee_regions;

       objectDetection(kneemask->GetElementPtr(0,0,0),
                       kneemap->GetElementPtr(0,0,0),
                       kneemap->GetNx(),
                       kneemap->GetNy(),
                       arseregion,
                       &knee_regions,
                       indexes,
                       searchRegionPoint1d,
                       searchRegionPoint2d,
                       false);

       int kneearray_x[nof_regions];
       int kneearray_y[nof_regions];

       for (ind=0; ind<nof_regions; ind++)
        {
           kneearray_x[ind] = 0;
           kneearray_y[ind] = 0;
       }


       for (ind=0; ind<nof_regions; ind++)
        {
            int i = indexes[ind];

            kneearray_x[i] = (kneeregion[i].getMaxX()+kneeregion[i].getMinX())/2;
            kneearray_y[i] = (kneeregion[i].getMaxY()+kneeregion[i].getMinY())/2;
        }

     //++++++++++++++++++++++++++++++++++SHOULDER+++++++++++++++++++++++++++++++++++++++++++


     if (frame == 69)
     {
          int shouldercounter = 0;
          for (int xm = (int)arsearray_x[arsechoice]-72; xm < (int)arsearray_x[arsechoice]+ 73; xm++)
          {
              for (int ym = (int)arsearray_y[arsechoice]-72; ym < (int)arsearray_y[arsechoice]; ym++)
              {
                  if (sqrt((xm-arsearray_x[arsechoice])*(xm-arsearray_x[arsechoice])+(ym-arsearray_y[arsechoice])*(ym-arsearray_y[arsechoice])) < 72
                      && sqrt((xm-arsearray_x[arsechoice])*(xm-arsearray_x[arsechoice])+(ym-arsearray_y[arsechoice])*(ym-arsearray_y[arsechoice])) > 68
                      && arsemask5->GetPixel(xm, ym) == 255
                      && prev5mask->GetPixel(xm, ym) == 255)
                  {

                      prev_shoulder_x += xm;
                      prev_shoulder_y += ym;
                      shouldercounter += 1;

                      cout << "xm,ym " << xm << "," << ym << endl;

                  }
              }
          }
          prev_shoulder_x /= shouldercounter;
          prev_shoulder_y /= shouldercounter;

          double shoulderworldX = 0;
          double shoulderworldY = 0;
          double shoulderworldZ = 0;

          startPose->lineOfSightWorld(prev_shoulder_x, prev_shoulder_y, &shoulderworldX, &shoulderworldY, &shoulderworldZ);
          shoulderlength = sqrt((prev_arse_worldX-shoulderworldX)*(prev_arse_worldX-shoulderworldX)+(prev_arse_worldY-shoulderworldY)*(prev_arse_worldY-shoulderworldY));


          cout << "prev_shoulder_x,prev_shoulder_y " << prev_shoulder_x << "," << prev_shoulder_y << endl;

          for (int i = prev_shoulder_x - 2; i <= prev_shoulder_x + 2; i++)
                      {
                          for (int j = prev_shoulder_y - 2; j <= prev_shoulder_y + 2; j++)
                          {
                          prev2->SetPixel(0, i, j, 0);
                          prev2->SetPixel(255, i, j, 1);
                          prev2->SetPixel(255, i, j, 2);
                          }
                      }
     }

     if (frame > 69)
     {
          int shoulderdistance = 100000;
          double shoulder_x_holder = 0;
          double shoulder_y_holder = 0;

          double shoulderworldX = prev_arse_worldX + shoulderlength;

          destinationPose->worldToPixel(shoulderworldX, prev_arse_worldY, prev_arse_worldZ, &shoulder_x_holder, &shoulder_y_holder);

          int shoulderradius =  sqrt(((int)shoulder_x_holder-prev_arse_x)*((int)shoulder_x_holder-prev_arse_x)+((int)shoulder_y_holder-prev_arse_y)*((int)shoulder_y_holder-prev_arse_y));



          for (int xm = (int)arsearray_x[arsechoice]-shoulderradius-2; xm < (int)arsearray_x[arsechoice]+ shoulderradius + 3; xm++)
          {
              for (int ym = (int)arsearray_y[arsechoice]-shoulderradius -2; ym < (int)arsearray_y[arsechoice]+ shoulderradius + 3; ym++)
              {
                  if (sqrt((xm-arsearray_x[arsechoice])*(xm-arsearray_x[arsechoice])+(ym-arsearray_y[arsechoice])*(ym-arsearray_y[arsechoice])) < shoulderradius + 2
                      && sqrt((xm-arsearray_x[arsechoice])*(xm-arsearray_x[arsechoice])+(ym-arsearray_y[arsechoice])*(ym-arsearray_y[arsechoice])) > shoulderradius - 2
                      && arsemask5->GetPixel(xm, ym) == 255
                      && prev5mask->GetPixel(xm, ym) == 255
                      )
                  {
                      prev2->SetPixel(255, xm, ym, 0);
                      prev2->SetPixel(0, xm, ym, 1);
                      prev2->SetPixel(255, xm, ym, 2);



                      if(sqrt((xm-prev_shoulder_x)*(xm-prev_shoulder_x)+(ym-prev_shoulder_y)*(ym-prev_shoulder_y))<shoulderdistance)
                      {
                          shoulderdistance = sqrt((xm-prev_shoulder_x)*(xm-prev_shoulder_x)+(ym-prev_shoulder_y)*(ym-prev_shoulder_y));
                          shoulder_x_holder = xm;
                          shoulder_y_holder = ym;
                      }


                      cout << "xm,ym " << xm << "," << ym << endl;

                  }
              }
          }
          if(shoulder_x_holder !=0 || shoulder_y_holder !=0)
          {
          prev_shoulder_x = shoulder_x_holder;
          prev_shoulder_y = shoulder_y_holder;
          }

          cout << "prev_shoulder_x,prev_shoulder_y " << prev_shoulder_x << "," << prev_shoulder_y << endl;

          for (int i = prev_shoulder_x - 2; i <= prev_shoulder_x + 2; i++)
                      {
                          for (int j = prev_shoulder_y - 2; j <= prev_shoulder_y + 2; j++)
                          {
                          prev2->SetPixel(255, i, j, 0);
                          prev2->SetPixel(255, i, j, 1);
                          prev2->SetPixel(255, i, j, 2);
                          }
                      }
     }


 //++++++++++++++++++++++++++++++++++FEET+++++++++++++++++++++++++++++++++++++++++++


     if (frame == 69)
     {
          int feetcounter = 0;
          for (int xm = prev_knee_x-50; xm < prev_knee_x+ 51; xm++)
          {
              for (int ym = prev_knee_y; ym < prev_knee_y + 51; ym++)
              {
                  if (sqrt((xm-prev_knee_x)*(xm-prev_knee_x)+(ym-prev_knee_y)*(ym-prev_knee_y)) < 50
                      && sqrt((xm-prev_knee_x)*(xm-prev_knee_x)+(ym-prev_knee_y)*(ym-prev_knee_y)) > 47
                      && arsemask5->GetPixel(xm, ym) == 255
                      && prev5mask->GetPixel(xm, ym) == 255)
                  {

                      prev_feet_x += xm;
                      prev_feet_y += ym;
                      feetcounter += 1;

                      cout << "xm,ym " << xm << "," << ym << endl;

                  }
              }
          }
          prev_feet_x /= feetcounter;
          prev_feet_y /= feetcounter;

          double feetworldX = 0;
          double feetworldY = 0;
          double feetworldZ = 0;
          
          double kneeworldX = 0;
          double kneeworldY = 0;
          double kneeworldZ = 0;

          startPose->lineOfSightWorld(prev_feet_x, prev_feet_y, &feetworldX, &feetworldY, &feetworldZ);
          startPose->lineOfSightWorld(prev_knee_x, prev_knee_y, &kneeworldX, &kneeworldY, &kneeworldZ);
          feetlength = sqrt((kneeworldX-feetworldX)*(kneeworldX-feetworldX)+(kneeworldY-feetworldY)*(kneeworldY-feetworldY));
          



          cout << "prev_feet_x,prev_feet_y " << prev_feet_x << "," << prev_feet_y << endl;

          for (int i = prev_feet_x - 2; i <= prev_feet_x + 2; i++)
                      {
                          for (int j = prev_feet_y - 2; j <= prev_feet_y + 2; j++)
                          {
                          prev2->SetPixel(0, i, j, 0);
                          prev2->SetPixel(255, i, j, 1);
                          prev2->SetPixel(255, i, j, 2);
                          }
                      }
     }

     if (frame > 69)
     {
          int feetdistance = 100000;
          double feet_x_holder = 0;
          double feet_y_holder = 0;

          double feetworldX = prev_knee_worldX + feetlength;

          destinationPose->worldToPixel(feetworldX, prev_knee_worldY, prev_knee_worldZ, &feet_x_holder, &feet_y_holder);

          int feetradius =  sqrt(((int)feet_x_holder-prev_knee_x)*((int)feet_x_holder-prev_knee_x)+((int)feet_y_holder-prev_knee_y)*((int)feet_y_holder-prev_knee_y));



          for (int xm = prev_knee_x-feetradius-2; xm < prev_knee_x+ feetradius + 3; xm++)
          {
              for (int ym = prev_knee_y-feetradius -2; ym < prev_knee_y+ feetradius + 3; ym++)
              {
                  if (sqrt((xm-prev_knee_x)*(xm-prev_knee_x)+(ym-prev_knee_y)*(ym-prev_knee_y)) < feetradius + 2
                      && sqrt((xm-prev_knee_x)*(xm-prev_knee_x)+(ym-prev_knee_y)*(ym-prev_knee_y)) > feetradius - 2
                      && arsemask5->GetPixel(xm, ym) == 255
                      && prev5mask->GetPixel(xm, ym) == 255
                      )
                  {
                      prev2->SetPixel(255, xm, ym, 0);
                      prev2->SetPixel(255, xm, ym, 1);
                      prev2->SetPixel(0, xm, ym, 2);



                      if(sqrt((xm-prev_feet_x)*(xm-prev_feet_x)+(ym-prev_feet_y)*(ym-prev_feet_y))<feetdistance)
                      {
                          feetdistance = sqrt((xm-prev_feet_x)*(xm-prev_feet_x)+(ym-prev_feet_y)*(ym-prev_feet_y));
                          feet_x_holder = xm;
                          feet_y_holder = ym;
                      }


                      cout << "xm,ym " << xm << "," << ym << endl;

                  }
              }
          }
          if(feet_x_holder !=0 || feet_y_holder !=0)
          {
          prev_feet_x = feet_x_holder;
          prev_feet_y = feet_y_holder;
          }

          cout << "prev_feet_x,prev_feet_y " << prev_feet_x << "," << prev_feet_y << endl;

          for (int i = prev_feet_x - 2; i <= prev_feet_x + 2; i++)
                      {
                          for (int j = prev_feet_y - 2; j <= prev_feet_y + 2; j++)
                          {
                          prev2->SetPixel(255, i, j, 0);
                          prev2->SetPixel(255, i, j, 1);
                          prev2->SetPixel(255, i, j, 2);
                          }
                      }
     }





     ////////////////////////////////////////////////////////////////////////

      sprintf(buf, para.o, (frame-2));
      bbcvp::WriteImage(*prev2, buf);
      sprintf(buf, "scalednew2/out/mask/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev2mask, buf);
      sprintf(buf, "scalednew2/out/outmask/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev4mask, buf);
      sprintf(buf, "scalednew2/out/outmaskadjusted/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev5mask, buf);
      sprintf(buf, "scalednew2/out/hueborder/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*greyscaleout3, buf);
      sprintf(buf, "scalednew2/out/out/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev3mask, buf);
      sprintf(buf, "scalednew2/out/arsemask5/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*arsemask5, buf);
      sprintf(buf, "scalednew2/out/prev6mask/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*prev6mask, buf);
      sprintf(buf, "scalednew2/out/arsemask/%04d.tiff", (frame-2));
      bbcvp::WriteImage(*arsemask2, buf);

    //  sprintf(buf, "scalednew2/out/input/%04d.tiff", (frame));
    //  bbcvp::WriteImage(*heap, buf);

      cout << "Timing point 17a: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

      //cout << "FINAL TIME: " << double(double(clock() - initial_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
/*
      if(para.numbering == 1 && jumpFrameNumber !=0)
      {
            sprintf(buf, "scalednew2/out/heap/%04d.tiff", (frame-jumpFrameNumber-2));
            bbcvp::WriteImage(*prev2, buf);

            bbcvp::BilinearInterpolator *grow = new BilinearInterpolator();
            
            grow->setNewInImage(*arsemask5);
            *resizedmask = grow->resize((double)orig_x/new_x, (double)orig_y/new_y);

            if(isGaussian)
            {

            sprintf(buf, "scalednew2/out/heapmask/%04d.tiff", (frame-jumpFrameNumber-2));
            bbcvp::WriteImage(*resizedmask, buf);

            o_RGBPicture<unsigned char> bg;

            sprintf(buf, "scalednew2/out/heapmask/%04d.tiff", (frame-jumpFrameNumber-2));
            bbcvp::ReadImage(bg, buf);

            o_RGBPicture<unsigned char> bgBlur(bg.GetNx(), bg.GetNy());

            GaussianFilter *gf = new GaussianFilter(&bg, &bgBlur, 10.0);

            sprintf(buf, para.o, (frame-jumpFrameNumber-2));
            bbcvp::WriteImage(bgBlur, buf);
            }

            else
            {
            resizeddiff = mask_differentiator(resizedmask, resizeddiff, in->GetNx(), in->GetNy(), 2);

            double gf_mat[25] = {0.001, 0.007, 0.013, 0.007, 0.001,
                                 0.007, 0.055, 0.111, 0.055, 0.007,
                                 0.013, 0.111, 0.225, 0.111, 0.013,
                                 0.007, 0.055, 0.111, 0.055, 0.007,
                                 0.001, 0.007, 0.013, 0.007, 0.001};

            for(int ym = 0;ym<orig_y;ym++)
              {
                 for(int xm = 0;xm<orig_x;xm++)
                  {
                     if((resizeddiff->GetPixel(xm,ym) == 0 ||
                         resizeddiff->GetPixel(xm + 1,ym) == 0 ||
                         resizeddiff->GetPixel(xm + 2,ym) == 0 ||
                         resizeddiff->GetPixel(xm - 1,ym) == 0 ||
                         resizeddiff->GetPixel(xm - 2,ym) == 0 ||
                         resizeddiff->GetPixel(xm,ym + 1) == 0 ||
                         resizeddiff->GetPixel(xm,ym + 2) == 0 ||
                         resizeddiff->GetPixel(xm,ym - 1) == 0 ||
                         resizeddiff->GetPixel(xm,ym - 2) == 0
                         ) &&
                        xm > 10 &&
                        xm < orig_x -10 &&
                        ym > 10 &&
                        ym < orig_y - 10)
                     {
                      double gauss_tot = 0;
                      for (int i = 0; i < 5; i++)
                         {
                          for (int j = 0; j < 5; j++)
                          {
                              gauss_tot += (double)resizedmask->GetPixel(xm-2+i, ym-2+j)*(gf_mat[i+5*j]);
                          }
                         }
                          boxblur->SetPixel(int(gauss_tot),xm, ym);
                        int z_tot = 0;
                         for (int k = 0; k < 7; k++)
                         {
                             z_tot += resizedmask->GetPixel(xm-3+k, ym-3+k);
                         }
                         int w_tot = 0;
                         for (int l = 0; l < 7; l++)
                         {
                             w_tot += resizedmask->GetPixel(xm+3-l, ym-3+l);
                         }
                         boxblur->SetPixel((z_tot+w_tot)/14,xm, ym);
                     }
                     else
                         boxblur->SetPixel((resizedmask->GetPixel(xm, ym)), xm, ym);
                 }
             }


            sprintf(buf, para.o, (frame-jumpFrameNumber-2));
            bbcvp::WriteImage(*boxblur, buf);
            }

            if(para.segmentedoutput)
            {
            o_CPicture<unsigned char> *finalmask;
            o_CPicture<unsigned char> *inness;
            o_CPicture<unsigned char> *gauss2;

            finalmask = new o_CPicture<unsigned char>(orig_x, orig_y,1);
            inness = new o_CPicture<unsigned char>(orig_x, orig_y,3);
            gauss2 = new o_CPicture<unsigned char>(orig_x, orig_y,3);

            sprintf(buf, para.o, (frame-jumpFrameNumber-2));
            bbcvp::ReadImage(*finalmask, buf);

            sprintf(buf, para.i, (frame-2));
            bbcvp::ReadImage(*inness, buf);


            for(int ym = 0;ym<orig_y;ym++)
             {
                 for(int xm = 0;xm<orig_x;xm++)
                 {
                     int benny =  inness->GetPixel(xm,ym,0);
                     int terry =  inness->GetPixel(xm,ym,1);
                     int sheila =  inness->GetPixel(xm,ym,2);
                     int dave = finalmask->GetPixel(xm,ym);

                     gauss2->SetPixel(benny*dave/255, xm, ym, 0);
                     gauss2->SetPixel(terry*dave/255, xm, ym, 1);
                     gauss2->SetPixel(sheila*dave/255, xm, ym, 2);
                 }
             }

            sprintf(buf, para.segmentedoutputlocation, (frame-jumpFrameNumber-2));
            bbcvp::WriteImage(*gauss2, buf);
             }


        }

      else if (para.numbering == 0)
      {
            bbcvp::BilinearInterpolator *grow = new BilinearInterpolator();

            grow->setNewInImage(*arsemask5);
            *resizedmask = grow->resize((double)orig_x/new_x, (double)orig_y/new_y);

            if(isGaussian)
            {

            sprintf(buf, "scalednew2/out/heapmask/%04d.tiff", (frame-2));
            bbcvp::WriteImage(*resizedmask, buf);

            o_RGBPicture<unsigned char> bg;

            sprintf(buf, "scalednew2/out/heapmask/%04d.tiff", (frame-2));
            bbcvp::ReadImage(bg, buf);

            o_RGBPicture<unsigned char> bgBlur(bg.GetNx(), bg.GetNy());

            GaussianFilter *gf = new GaussianFilter(&bg, &bgBlur, 10.0);

            sprintf(buf, para.o, (frame-2));
            bbcvp::WriteImage(bgBlur, buf);
            }

            else
            {
            resizeddiff = mask_differentiator(resizedmask, resizeddiff, in->GetNx(), in->GetNy(), 2);

            double gf_mat[25] = {0.001, 0.007, 0.013, 0.007, 0.001,
                                 0.007, 0.055, 0.111, 0.055, 0.007,
                                 0.013, 0.111, 0.225, 0.111, 0.013,
                                 0.007, 0.055, 0.111, 0.055, 0.007,
                                 0.001, 0.007, 0.013, 0.007, 0.001};

            for(int ym = 0;ym<orig_y;ym++)
              {
                 for(int xm = 0;xm<orig_x;xm++)
                  {
                     if((resizeddiff->GetPixel(xm,ym) == 0 ||
                         resizeddiff->GetPixel(xm + 1,ym) == 0 ||
                         resizeddiff->GetPixel(xm + 2,ym) == 0 ||
                         resizeddiff->GetPixel(xm - 1,ym) == 0 ||
                         resizeddiff->GetPixel(xm - 2,ym) == 0 ||
                         resizeddiff->GetPixel(xm,ym + 1) == 0 ||
                         resizeddiff->GetPixel(xm,ym + 2) == 0 ||
                         resizeddiff->GetPixel(xm,ym - 1) == 0 ||
                         resizeddiff->GetPixel(xm,ym - 2) == 0
                         ) &&
                        xm > 10 &&
                        xm < orig_x -10 &&
                        ym > 10 &&
                        ym < orig_y - 10)
                     {
                      double gauss_tot = 0;
                      for (int i = 0; i < 5; i++)
                         {
                          for (int j = 0; j < 5; j++)
                          {
                              gauss_tot += (double)resizedmask->GetPixel(xm-2+i, ym-2+j)*(gf_mat[i+5*j]);
                          }
                         }
                          boxblur->SetPixel(int(gauss_tot),xm, ym);
                        int z_tot = 0;
                         for (int k = 0; k < 7; k++)
                         {
                             z_tot += resizedmask->GetPixel(xm-3+k, ym-3+k);
                         }
                         int w_tot = 0;
                         for (int l = 0; l < 7; l++)
                         {
                             w_tot += resizedmask->GetPixel(xm+3-l, ym-3+l);
                         }
                         boxblur->SetPixel((z_tot+w_tot)/14,xm, ym);
                     }
                     else
                         boxblur->SetPixel((resizedmask->GetPixel(xm, ym)), xm, ym);
                 }
             }

            sprintf(buf, para.o, (frame-2));
            bbcvp::WriteImage(*boxblur, buf);
            }

            if(para.segmentedoutput)
            {
            o_CPicture<unsigned char> *finalmask;
            o_CPicture<unsigned char> *inness;
            o_CPicture<unsigned char> *gauss2;

            finalmask = new o_CPicture<unsigned char>(orig_x, orig_y,1);
            inness = new o_CPicture<unsigned char>(orig_x, orig_y,3);
            gauss2 = new o_CPicture<unsigned char>(orig_x, orig_y,3);

            sprintf(buf, para.o, (frame-2));
            bbcvp::ReadImage(*finalmask, buf);

            sprintf(buf, para.i, (frame-2));
            bbcvp::ReadImage(*inness, buf);


            for(int ym = 0;ym<orig_y;ym++)
             {
                 for(int xm = 0;xm<orig_x;xm++)
                 {
                     int benny =  inness->GetPixel(xm,ym,0);
                     int terry =  inness->GetPixel(xm,ym,1);
                     int sheila =  inness->GetPixel(xm,ym,2);
                     int dave = finalmask->GetPixel(xm,ym);

                     gauss2->SetPixel(benny*dave/255, xm, ym, 0);
                     gauss2->SetPixel(terry*dave/255, xm, ym, 1);
                     gauss2->SetPixel(sheila*dave/255, xm, ym, 2);
                 }
             }

            sprintf(buf, para.segmentedoutputlocation, (frame-2));
            bbcvp::WriteImage(*gauss2, buf);
             }


        }
*/

            cout << "Timing point 18: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
            last_time = clock();





      *prev2mask = *prev1mask;
      *prev1mask = *inmask;

      *prev2 = *prev1;
      *prev1 = *in;

   //   printf("\n FRAME: %03d \n", frameNumber);

     // bool writeOutCams = true;
     // if (writeOutCams &&  para.numbering == 1) //jumpFrameNumber !=0 &&
     // {
         char camFileName[50];
         sprintf(camFileName, "scalednew2/out/cams/%05d.cam", (frame));
         double camX, camY, camZ;
         myPoseEst->getCamPos(&camX, &camY, &camZ);
         printf("%s\n", camFileName);
         double pixX, pixY;
         myPoseEst->getCamPixelSize(&pixX, &pixY);
         double pan, tilt, roll;
         myPoseEst->getCamRotPTR(&pan, &tilt, &roll);

         writeOutCam(camFileName, frame, camX, camY, camZ, pan, tilt, roll,
                                   focalLength, in->GetNx(), (in->GetNy()*2), notionalPixHeight, 1.31282e-05);
    //  }
/*
      else if (writeOutCams && para.numbering == 0)
      {
         char camFileName[50];
         sprintf(camFileName, "scalednew2/out/cams/%05d.cam", (frame));
         double camX, camY, camZ;
         myPoseEst->getCamPos(&camX, &camY, &camZ);
         printf("%s\n", camFileName);
         double pixX, pixY;
         myPoseEst->getCamPixelSize(&pixX, &pixY);
         double pan, tilt, roll;
         myPoseEst->getCamRotPTR(&pan, &tilt, &roll);

    //     writeOutCam(camFileName, frame, camX, camY, camZ, pan, tilt, roll,
    //                               focalLength, in->GetNx(), (in->GetNy()*2), notionalPixHeight, 1.31282e-05);
      }


*/



      cout << "Timing point 19: " << double(double(clock() - last_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      last_time = clock();

      printf("\n FRAME: %03d \n", frameNumber);

      cout << "Total Time: " << double(double(clock() - first_time)/(double)CLOCKS_PER_SEC) << " seconds." << endl;
      first_time = clock();



      if (para.lineImOut_flag && para.lineFile_flag)  // if using lines and asked to write a diagnostic image...
          {
              sprintf(buf, para.lineImOut, frame);
              bbcvp::WriteImage(*lineDiag, buf);
          }
#endif

      if (para.pointFile_flag)  // if asked to write coords of points to a file.....
        {
          FILE *fp;
          char nameBuff[500];
          sprintf(nameBuff, para.pointFile, frame);
          if ( (fp = fopen(nameBuff, "w")) == NULL)
            {
              printf("Can't open file %s for writing list of observed points\n",nameBuff);
              return(-1);
            }
          else
            {
              for (int i=0; i<myCorrespGen->getNPatches(); i++)
                {
                  if (myPoseEst->pointWasAnInlier(i))           // only write inliers
                    {
                      double xx, yy;
                      int id = myPoseEst->getPointObservation(i, &xx, &yy);
                      fprintf(fp,"%7i  %6.2f  %6.2f\n", id, xx+sideBorder, yy+topBorder);  // PoseEst object only works on window into picture!!
                    }
                }
              fclose(fp);
            }
        }  // if writing observed points to a file

      // Delete the top image from the store according to the decision made earlier
      // (replaces previous code that also did outlier deletion and (disabled) code for new feature creation
      if (deleteLastImage)  myPoseEst->clearLastImage();

      if (fieldType != -1) fieldType = 1 - fieldType;  // which field type next time?

      first=false;
      nFieldsProcessed++;

    }  // loop for reading input frames

  printf(" Average times: load=%5.2f findCor=%5.2f findLines=%5.2f calcSoln=%5.2f findNew=%5.2f  ignoreNonCamMotionTime=%5.2f keyCalcTime=%5.2f total=%5.2f\n",
         loadImageTimeTotal/nFieldsProcessed*1000, findCorrespondencesTimeTotal/nFieldsProcessed*1000, findLinesTimeTotal/nFieldsProcessed*1000, calcSolutionTimeTotal/nFieldsProcessed*1000, findNewFeaturesTimeTotal/nFieldsProcessed*1000,ignoreNonCamMotionTimeTotal/nFieldsProcessed*1000,keyCalcTimeTotal/nFieldsProcessed*1000,
         (loadImageTimeTotal+findCorrespondencesTimeTotal+findLinesTimeTotal+calcSolutionTimeTotal+findNewFeaturesTimeTotal+ignoreNonCamMotionTimeTotal+keyCalcTimeTotal)/nFieldsProcessed*1000);

  printf("     Max times: load=%5.2f findCor=%5.2f findLines=%5.2f calcSoln=%5.2f findNew=%5.2f calcFull=%5.2f keyCalc=%5.2f\n",
         loadImageTimeMax*1000, findCorrespondencesTimeMax*1000, findLinesTimeMax*1000, calcSolutionTimeMax*1000, findNewFeaturesTimeMax*1000, calcFullSolutionTimeMax*1000, keyCalcTimeMax*1000);
  printf("     Total time for calcFullSolution = %5.2f\n", calcFullSolutionTimeTotal*1000);

  // print out the key papameters in a form easy to cut & paste into a spreadsheet:
  printf("RMS 2nd deriv pan      tilt     fov    totFeat  avFeatFnd   avInlier  finalPan\n");
  printf("            %7.3f, %7.3f, %7.3f,%7d, %7.3f,   %7.3f,  %7.3f\n",
         sqrt(panSecDerivSquaredTotal/(nFieldsProcessed-1)),
         sqrt(tiltSecDerivSquaredTotal/(nFieldsProcessed-1)),
         sqrt(fovSecDerivSquaredTotal/(nFieldsProcessed-1)),
         myCorrespGen->getNPatches(),                            // total features
         (double)searchedFeaturesTotal/(double)nFieldsProcessed, // avFeaturesFound
         (double)inliersTotal/(double)searchedFeaturesTotal,     // av inlier fraction
         pan);                                                   // final pan

  if (para.autoRange)
      {
          printf("To re-run using the same search range as seen when learning patches, append this to the command line:\n");
          printf("-autoRange 0 -pMin %6.2f -pMax %6.2f -tMin %6.2f -tMax %6.2f -rMin %6.2f -rMax %6.2f -fMin %6.2f -fMax %6.2f\n",
                 para.pMin, para.pMax, para.tMin, para.tMax, para.rMin, para.rMax, para.fMin, para.fMax);
      }


#ifdef FREED_OUTPUT
  if (useFreedSender)
    {
      printf("Pan offset and position for free-d output:\n");
      printf("-initPanOffset %7.3f -initX %7.3f -initY %7.3f -initZ %7.3f\n", panOffset, camX, camY, camZ);
    }
#endif

  if (para.patchFileOut_flag)
  {
      printf("Writing patches to file %s...\n", para.patchFileOut);
      myCorrespGen->writePatches(para.patchFileOut);
  }

  if (para.distFileOut_flag)
  {
      printf("Writing distortion polynomial to file %s...\n", para.distFileOut);
      myPoseEst->writeDistortionPolynomial(para.distFileOut);
  }


  if (logFile != (FILE*)NULL) fclose(logFile);

  myPoseEst->getCamRotPTR(&pan, &tilt, &roll, 0);
  printf("Pan2: %f %f\n", pan, tilt);
  myPoseEst->getCamFOV(&fovy, lenYFullFrameField, 0);
  printf("To set cam params for first ref frame when running using patch file, use these options:\n");
  printf("-initPan %f -initTilt %f  -initRoll %f  -initLensAngle %f \\ \n", pan, tilt, roll, fovy);

  printf("To use the focalLength-to-distortion mapping (if this was computed here), use:\n");
  double minDistortFoclen, maxDistortFoclen;
  myPoseEst->getDistortFoclenRange(&minDistortFoclen, &maxDistortFoclen);
  printf("-nCoeffFD %d -coeffFD0 %f -coeffFD1 %f -coeffFD2 %f -minDistortFoclen %f -maxDistortFoclen %f\n",
         myPoseEst->getNCoeffFD(), myPoseEst->getCoeffFD()[0], myPoseEst->getCoeffFD()[1], myPoseEst->getCoeffFD()[2], minDistortFoclen, maxDistortFoclen);

  printf("Deleting PatchCorrespondenceGen...\n");
  delete myCorrespGen;
  printf("Deleting PoseEstPanTiltHead...\n");
  delete myPoseEst;
  printf("PoseEstPanTiltHead deleted\n");

  if (usingLines)
  {
      printf("Deleting arrays associated with lines...\n");
      delete[] hGrad;
      delete[] vGrad;
#ifndef USING_DVS
      delete lineDiag;  // CPicture for holding line diagnostic image
#endif
      printf("...line arrays deleted\n");
  }

#ifdef TEST_TRISTRIP_KEY
  delete keyerForGraphics;
#endif

#ifdef USING_DVS

#ifdef FREED_OUTPUT
  if (useFreedSender)
    {
      freedSender->stopSenderThread();
      delete freedSender;
      delete freedDevice;
    }
  delete dvsHandle;
#endif

  cout << "- Destroying DVSCard: ";
  delete mycard;
  cout << "done" << endl;

#else
  delete in;            // CPicture for inages read from file
#endif

  return (0);



}


int
main(int argc, char *argv[] )
{
  _test_PatchCorrespondenceGen_parameter        para;
  int        i;
  FILE        *fp;


  for(i=1; i<argc; ) {
    i += para.ParseArg(  argc-i, argv+i );
  }
  if(para.help_flg) return 0;


  //
  //      read config file
  //        a config file can contains all parameters that possible
  //        on the command line
  //
  if(para.cfn) {
    fp=fopen(para.cfn,"r");
    if(fp) {
      para.ReadConfig(fp);
    } else {
      cerr << "Couldn't read config file: "<<para.cfn<<"\n";
    }
  }

  //
  //      second pass: read command line args and overwrite args
  //
  for(i=1; i<argc; ) {
    i += para.ParseArg( argc-i, argv+i );
  }
  //para.Print(stdout);

  return ltest_PatchCorrespondenceGen(para);
}

